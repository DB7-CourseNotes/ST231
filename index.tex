% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod,
  oneside]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[left=1in,marginparwidth=2.0666666666667in,textwidth=4.1333333333333in,marginparsep=0.3in]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{2}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{sidenotes}{}{\usepackage{sidenotes}}
\@ifpackageloaded{marginnote}{}{\usepackage{marginnote}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Statistics for Life Sciences},
  pdfauthor={Dr.~Devan Becker},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Statistics for Life Sciences}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Course Notes for ST231, Updated for Winter 2024}
\author{Dr.~Devan Becker}
\date{2023-06-20}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[frame hidden, interior hidden, sharp corners, breakable, enhanced, borderline west={3pt}{0pt}{shadecolor}, boxrule=0pt]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{introduction}{%
\chapter*{Introduction}\label{introduction}}
\addcontentsline{toc}{chapter}{Introduction}

\markboth{Introduction}{Introduction}

These course notes are self-contained and provided as an Open
Educational Resources. In doing so, I will also borrow from OpenIntro
Statistics for the Biomedical and Life Sciences, with attribution. As
such, these resources have the same license (see the end of this page),
except for those elements that are still present from Baldi \& Moore
(mainly exercises, which are being removed as I go).

\hypertarget{alternate-textbooks-for-extra-instruction}{%
\section*{Alternate Textbooks for Extra
Instruction}\label{alternate-textbooks-for-extra-instruction}}
\addcontentsline{toc}{section}{Alternate Textbooks for Extra
Instruction}

\markright{Alternate Textbooks for Extra Instruction}

\begin{itemize}
\tightlist
\item
  These course notes structured to coincide with Baldi and Moore's The
  Basic Practice of Statistics in the Life Sciences, 4th edition.
  However, I have made them self-contained in order to provide these
  notes as an Open Educational Resources.
\end{itemize}

\hypertarget{learning-outcomes}{%
\section*{Learning Outcomes}\label{learning-outcomes}}
\addcontentsline{toc}{section}{Learning Outcomes}

\markright{Learning Outcomes}

\begin{itemize}
\tightlist
\item
  Critically appraise \textbf{published articles} in health sciences
  research.\lspace
\item
  Use \textbf{industry standard tools} to apply \textbf{basic
  statistical concepts} to \textbf{real-world problems}.\lspace
\item
  Understand the use and application of \textbf{statistical techniques}
  such as descriptive and inferential statistics.
\end{itemize}

\hypertarget{accessing-materials}{%
\section*{Accessing Materials}\label{accessing-materials}}
\addcontentsline{toc}{section}{Accessing Materials}

\markright{Accessing Materials}

\begin{itemize}
\tightlist
\item
  Lectures posted on MyLS\lspace
\item
  \url{rdrr.io} allows running single R commands to caclulate
  probabilities
\item
  RStudio

  \begin{itemize}
  \tightlist
  \item
    Free, open-source interface to the R programming language.
  \item
    A free online cloud version is available - no need to install R on
    your own computer!\lspace
  \end{itemize}
\item
  Syzygy Jupyter Notebooks

  \begin{itemize}
  \tightlist
  \item
    Free, \textbf{web-based} service for WLU students
  \item
    No need to install R on your own computer!
  \end{itemize}
\end{itemize}

You can use either RStudio or Syzygy for this course, RStudio has many
fantastic bells and whistles that help you produce results and reports,
whereas Syzygy has an online interface and makes it easy to use without
installing R on your own computer. Note that Syzygy uses ``notebooks''
rather than the RMarkdown notebooks that RStudio prefers. L1abs will use
RStudio.

For lectures, I will be using VSCode, which I use because it works well
with python and R as well as other languages that I need. I will switch
to RStudio for many demonstrations just to show you how it works because
this is the program that most people who do statistics will use. I will
occasionally demonstrate some concepts using Jupyter notebooks because
this is another common way that people do statistics and data science.
You will not be tested on the features of Rtudio, VSCode or Jupyter
notebooks, but mastery of RStudio will be extremely helpful for all
future data analysis tasks beyond this course.

This work is licensed under a Creative Commons Attribution-ShareAlike
4.0 Unported License.

\part{Pre-Midterm}

\hypertarget{picturing-distributions-with-graphs}{%
\chapter{Picturing Distributions with
Graphs}\label{picturing-distributions-with-graphs}}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

\hypertarget{defining-statistics}{%
\subsection{Defining ``Statistics''}\label{defining-statistics}}

My definition: Statistics is the study of \textbf{variance} (or
uncertainty).

\begin{itemize}
\tightlist
\item
  The big question: is 1 \textbf{statistically different} from 100?

  \begin{itemize}
  \tightlist
  \item
    1 vs.~100 apples? Yes.
  \item
    1 vs.~100 atoms in an apple? No.
  \end{itemize}
\end{itemize}

Many people think of ``statistics'' as something along the lines of
``methods for dealing with data''. This completely misses out on
theoretical statistics, and makes it seem like statistics is a
collection of recipes stating ``if you have this data, use this
method''. I think a better definition of statistics is that it's the
study of variance, whether that means studying the theoretical
properties of variance or trying to ``explain'' variance\footnote{We'll
  talk about what ``explaining variance'' means, along with exact ways
  to calculate it, in a later lecture.} in a particular data set.

I like to ask the question: ``is 1 statistically different from 100''.
It may seem like they are obviously different numbers, but we can't know
that without the context. If you're comparing numbers of apples, then
yes, one apple is very different from 100 apples. However, if we're
looking at numbers of atoms per apple, then one and 100 are both
imperceptible numbers of atoms and thus we might say the the two apples
are basically the same size. The difference in these two examples is the
scale, and the variance is a fantastic way to measure the scales of
things. In my opinion, the main thing we will learn in this course is
how to tell whether two numbers are different \emph{given the scale of
those two numbers.} Another popular definition for statistics is
``putting numbers in context'', and by ``in context'' they mean
``relative to their variance''.

In my lecture notes, I use \textbf{bold font} for anything that you will
be expected to be able to explain or define. You won't necessarily see a
full definition the first time you see a word in bold, but by the
midterm/final it is something I expect you to know. A good way to study
in this course is to keep a glossary of all of the words I've put in
bold, with a definition file/note that you update as we learn more about
that concept. And, of course, write a description as if you're teaching
someone else!

\hypertarget{why-study-variance}{%
\subsection{Why study variance?}\label{why-study-variance}}

\begin{itemize}
\tightlist
\item
  Give context to different numbers.

  \begin{itemize}
  \tightlist
  \item
    The size of the difference depends on the context.
  \end{itemize}
\item
  We need to know \emph{how} and \emph{why} we were wrong.

  \begin{itemize}
  \tightlist
  \item
    \emph{How}: What is the magnitude/direction of the difference?
  \item
    \emph{Why}: Are we missing relationships? Bad sampling? Fundamental
    randomness?
  \end{itemize}
\end{itemize}

Variance is information!

Variance comes from many sources. We might just be doing something wrong
and missing out on important feature of our data, we might be collecting
the data in a biased or incorrect way, or there might be some
fundamental part of the problem that we will never be able to measure
perfectly, and so the variance that we calculated may actually be the
smallest possible variance for this problem.

Suppose we're trying to figure out the heights of undergraduate
students. We can calculate the average height, but I don't expect anyone
in the data to actually have this exact height. Exactly how far away
from this average do we expect the other heights to be? The measurement
of the expected distance to the mean is called the
\textbf{variance}.{\marginnote{\begin{footnotesize}The \textbf{variance}
is a measure of the ``usual'' distance to the mean - we'll have a
formula for this later.\end{footnotesize}}}

If our sample consisted of people walking out of the gym, and out of 50
people sampled we had 20 people who were on the basketball team, we
might know a little bit more about our variance. Specifically, we'll get
some students who may or may not be representative of the population as
well as some students who are unusually tall. These two groups are
fundamentally different, so including both in the same sample will
increase our variance. Put another way, the different groups in our data
\textbf{explain some of the variance} in our
data.{\marginnote{\begin{footnotesize}Different subgroups within a
sample can help \textbf{explain} why the variance is as large as it
is.\end{footnotesize}}}

This is why I say that the variance is information! More specifically,
the difference between a single value and the mean of the data is due to
some unexplained phenomena, and learning more about the problem will
reduce the variance.

\hypertarget{descriptive-versus-inferential-statistics}{%
\subsection{Descriptive Versus Inferential
Statistics}\label{descriptive-versus-inferential-statistics}}

\begin{itemize}
\tightlist
\item
  \textbf{Descriptive statistics} are used to explore the data.

  \begin{itemize}
  \tightlist
  \item
    Graphs/figures
  \item
    Numbers
  \end{itemize}
\item
  \textbf{Inferential statistics} relate our data to the
  \textbf{population}.

  \begin{itemize}
  \tightlist
  \item
    Must have a good \textbf{sample} first!
  \item
    Our sample has a mean. The population has a mean. How different do
    we expect them to be?

    \begin{itemize}
    \tightlist
    \item
      \textbf{how different}
    \end{itemize}
  \end{itemize}
\end{itemize}

In this course, we will learn about two classes of statistics.
\textbf{Descriptive statistics} are the ones that we used to describe
the sample that we obtained. This can include things like the
mean/median/mode, the variance or the interquartile range, as well as
bar charts, histograms box, plots, etc.
{\marginnote{\begin{footnotesize}\textbf{Descriptive Statistics}
describe the data that were acquired.\end{footnotesize}}}

\textbf{Inferential statistics} are numbers that we calculate because we
think they have a relationship to the population. For instance, if we
calculate the mean of our data and we trust that our sample is good,
then we expect this sample mean to be somewhat close to the population
mean. Any time in this course I talk about the difference between two
things, I will always mean ``with reference to a measure of variance''.
In this example, we have a sample mean as well as some measure of its
variance, and this variance tells us how similar we expect the sample
mean to be to the population mean. If we have a small sample variance,
it means that we have a lot of information about the population mean.
Variance contains information that we haven't learned
yet!\footnote{It is worth noting that there is also variance that isn't
  information, and there's information that we'll never have access to.
  Variance is an opportunity to learn, but there's almost always a limit
  to how much we can learn.}{\marginnote{\begin{footnotesize}\textbf{Inferential
Statistics} attempt to describe the population based on the data
acquired. This requires a \emph{good} sample, and it's why Statistics is
such a useful field of study.\end{footnotesize}}}

In this course, we're going to start by talking about descriptive
statistics and work our way to inferential statistics (with a detour
through probability to show why inferential statistics work so well).

\hypertarget{descriptive-statistics-plots-and-graphs}{%
\section{Descriptive Statistics: Plots and
Graphs}\label{descriptive-statistics-plots-and-graphs}}

\hypertarget{the-palmer-penguins-data}{%
\subsection{The Palmer Penguins Data}\label{the-palmer-penguins-data}}

Let me introduce you to a dataset that I'm going to be returning to
throughout the semester. This is called the Palmer penguins data, end it
contains information on penguins from several islands in Antarctica. In
the slides, I use some fancier code to only show some of the data, but
I'll display the full data set with simpler code below:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(palmerpenguins)}
\FunctionTok{head}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(penguins))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  species    island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
1  Adelie Torgersen           39.1          18.7               181        3750
2  Adelie Torgersen           39.5          17.4               186        3800
3  Adelie Torgersen           40.3          18.0               195        3250
4  Adelie Torgersen             NA            NA                NA          NA
5  Adelie Torgersen           36.7          19.3               193        3450
6  Adelie Torgersen           39.3          20.6               190        3650
     sex year
1   male 2007
2 female 2007
3 female 2007
4   <NA> 2007
5 female 2007
6   male 2007
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Species can be Adelie, Gentoo, or Chinstrap
\item
  Sex can be male or female\footnote{A note on gender/sexuality/biology:
    penguins, especially Chinstrap and Gentoo penguins, don't have
    particularly strong gender roles, and
    \href{https://sites.tufts.edu/museumstudents/2021/02/22/whats-with-all-the-gay-penguins/}{often
    form same-sex couples}. In this course, I will use the term ``sex''
    to mean ``biosex'', rather than ``gender'', to indicate that we're
    looking at morphological differences due to XX and XY chromosomes.}
\item
  Bill Length is measured in millimetres
\item
  Body Mass is measured in grams
\item
  Island (one of three)
\item
  Bill depth (mm)
\item
  Flipper length (mm)
\item
  Year that the penguin was observed.
\end{itemize}

These data are really nice for teaching statistics because we can look
at what factors contribute to body mass (since it's easier to measure
the length of a beak than it is to weigh a live penguin), or we can try
to determine biosex using these measurements (since penguins normally
have no external genitalia, but have other morphological differences).
We can also fit a model to determine the species of each penguin so that
we can get a full picture of what makes each species unique! All of
these are examples of statistical analyses that we will cover in this
course.

\hypertarget{types-of-variables}{%
\subsection{Types of Variables}\label{types-of-variables}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins[, }\FunctionTok{c}\NormalTok{(}\StringTok{"species"}\NormalTok{, }\StringTok{"sex"}\NormalTok{, }\StringTok{"body\_mass\_g"}\NormalTok{)] }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{head}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
\NormalTok{    knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}llr@{}}
\toprule\noalign{}
species & sex & body\_mass\_g \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Adelie & male & 3750 \\
Adelie & female & 3800 \\
Adelie & female & 3250 \\
Adelie & NA & NA \\
Adelie & female & 3450 \\
Adelie & male & 3650 \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  Species is \textbf{categorical}

  \begin{itemize}
  \tightlist
  \item
    Mutually exclusive categories.
  \end{itemize}
\item
  Sex is \textbf{binary}\footnote{Possibly categorical if there are any
    penguins with chromosomal abnormalities.}

  \begin{itemize}
  \tightlist
  \item
    One or the other
  \item
    Special case of categorical with 2 possibilities
  \end{itemize}
\item
  Body mass is \textbf{quantitative}

  \begin{itemize}
  \tightlist
  \item
    It's a number (quantity)
  \end{itemize}
\end{itemize}

The type of variable is extremely important for choosing the right
summary of the data.

\textbf{Categorical variables} consist of two or more mutually exclusive
categories, that is, each observation has a label and nothing has more
than one label. Categorical variables may be \textbf{ordered} (such as
``low'', ``medium'', and ``high'') or \textbf{unordered} (such as names
or student numbers; putting names in alphabetical order is not usually
meaningful for summarising the data or doing the
analysis).{\marginnote{\begin{footnotesize}\textbf{Categorical
variables} are categories. Be careful - some categories are
\emph{encoded} as numbers, such as ``group 1'' and ``group 2'',
etc.\end{footnotesize}}}

This distinction of ``\textbf{ordered}'' versus ``\textbf{unordered}''
matters to determine what visualization or model you might want to use
to compare data within categories. For instance, we might want to see
the change in response to a ``low'' treatment compared to a ``medium''
or ``high'' treatment, where we fully expect the response to the
treatment to be lower for ``low'' treatment and higher for ``high''. In
contrast, suppose we knew the patients' occupations. We have no
expectation that the treatment reponse in the ``electrician'' group is
lower or higher than any other group, because there's no logical
ordering to
occupation.\footnote{We may, however, know that factory workers have
  more exposure to a pathogen than those who work from home, but we
  would likely want to measure this directly rather than measuring it by
  proxy with occupation.}{\marginnote{\begin{footnotesize}\textbf{Ordered}
and \textbf{unordered} categorical variables.\end{footnotesize}}}

\textbf{Binary variables} are a special case of \textbf{categorical
variables}, which only have two categories. In this case, the ordering
is rarely important, and thus we don't really make the distinction
between ordered binary and unordered binary. It's a single difference
either way, so we can just look at the differences within the
categories.\footnote{We often encode on of the categories as 0 and the
  other as 1, but this is usually either clear (0 = no treatment, 1 =
  treatment) or completely arbitrary (0 = femala, 1 = male) and this
  arbitrariness is acknowledged. Neither of these cases affect the way
  we make plots or run analyses that are based on binary variables.}{\marginnote{\begin{footnotesize}\textbf{Binary}
variables.\end{footnotesize}}}

\textbf{Quantitative variables} are those that are measured with
numbers. Unlike ``low'' to ``medium'' versus ``medium'' to ``high'', we
know how big a step it is from 0 to 1 and then 1 to 2. Unlike
categorical variables, quantitative variables have a concept of
``in-between''; we have nothing between ``medium'' and ``high'', but
there are infinite numbers between 1 and
2.{\marginnote{\begin{footnotesize}\textbf{Quantitative variables} are
numbers.\end{footnotesize}}}

There are, however, cases where there \emph{aren't} possible
measurements between 1 and 2. These are called
``\textbf{discrete}''\footnote{Not discreet.} For instance, the number
of children that some has is either 0, 1, 2, etc. \textbf{Discrete}
variables are somewhere in between categorical and \textbf{continuous
variables} (variables that can take be number). Consider the following
two examples of discrete variables: the number of children that someone
has, and the number of cents in their bank account. In a study, we might
want to look at everyone who has no children, everyone who has 1 child,
everyone who has 2, etc. However, we would \emph{not} want to compare
everyon who has 0 cents in their bank account, everyone who has 1 cent
in their account, 2 cents, 3, cents, etc. In terms of modelling and
visualization, we will sometimes treat discrete variables as categorical
and sometimes as
continuous.\footnote{There are methods/visualizations that are specific
  to discrete variables, but they only apply in very specific
  circumstances and will not be taught in this course.}{\marginnote{\begin{footnotesize}\textbf{Discrete}
variables only allow for some numbers, such as the numbers of children
per family.\end{footnotesize}}}
{\marginnote{\begin{footnotesize}\textbf{Continuous} variables can take
any value in a range. For any two possible numbers, there's another
possible number in between them. Alternatively, they can be defined as
``any measurement you make could have been more
precise.''\end{footnotesize}}}

The distinction between categorical and quantitative isn't always this
obvious, but can be very helpful for choosing the right kind of plot or
numerical summary.

\hypertarget{grey-areas}{%
\subsection{Grey Areas}\label{grey-areas}}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Student Numbers}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

A student number looks like a quantitative variable, but it's actually
just a name (category)!

\end{tcolorbox}

There are a couple gray areas when talking about variable types. The
distinction between categorical and quantitative isn't always perfectly
clear. For example, student numbers are names, but they are completely
made up of numbers. However, you wouldn't treat these numbers as if one
student number comes after another in the same way that you wouldn't put
students in an order based on their names. You technically can do this
if you do it alphabetically or order the student numbers in order, but
this isn't a meaningful ordering. It's not like one student number is
larger than another student number, and taking the meaning of student
numbers wouldn't make any sense.

\hypertarget{individuals-subjects}{%
\subsection{Individuals (Subjects)}\label{individuals-subjects}}

An individual is the thing we are making measurements on. For example,
in the Palmer Penguins data set, a penguin is an individual and we
measure their flipper length, bill length, the island they were observed
on, etc. In other data sets, we may measure the GDP of countries
(countries are the individuals) or the cuteness of
dogs.{\marginnote{\begin{footnotesize}\textbf{Individual:} the unit of
study. We make measurements on individuals.\end{footnotesize}}}

\hypertarget{challenge-what-are-the-individuals}{%
\subsection{Challenge: What are the
individuals?}\label{challenge-what-are-the-individuals}}

The following data are from the ``Titanic'' dataset.

Each number defines the count of children who survived the Titanic's
sinking.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
& Male & Female \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1st class & 5 & 1 \\
2nd class & 11 & 13 \\
3rd class & 13 & 14 \\
Crew & 0 & 0 \\
\end{longtable}

There are a couple of ways to interpret this.

\begin{itemize}
\tightlist
\item
  People: We measured whether an individual survived (one measurement
  per person).
\item
  Class: We have two measurements per class - one for male children, one
  for female children.
\item
  Sex: We have four observations (class 1, 2, 3, or crew).
\item
  Finally, we could say we have one observation per class/sex
  combination.
\end{itemize}

There isn't one ``correct'' definition of individual here. However, the
way we define individual affects how we might visualize these data!

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{CO\(_2\) Measurements}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

If we measure the C0\(_2\) at a given location each month, then do the
months count as the individuals? This describes \emph{time series} data,
which we won't cover in this course. However, visualizations of data
that are measured over time can reveal a lot of
information!\footnotemark{}

\end{tcolorbox}

\footnotetext{Of course, by ``information'', I mean variance. If we
don't know the date that an observation was observed, we just have a
collection of different numbers. If we see that there's a pattern over
time, we know a little more about why each number is different from the
others!}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Paired Observations}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

\begin{itemize}
\tightlist
\item
  Spousal pairs - the pairs are the individuals?
\item
  Before/after (e.g., weight loss) - people are individuals.

  \begin{itemize}
  \tightlist
  \item
    This is the same idea as spousal pairs!
  \end{itemize}
\end{itemize}

\end{tcolorbox}

All of the variables we just talked about are measured on individuals.
That is to say, an individual is what you are measuring when collecting
data. This can take the form of a single penguin, in which case it's
obvious that this body mass belongs to this penguin; we have measured
this body mass on this.

There are some gray areas to this as well, though. For example, if we're
measuring carbon dioxide every month, then we're actually measuring
carbon dioxide as the variable and months as the individuals, and we can
measure other things on those individuals if needed.

We will also encounter \textbf{paired observations} in this course,
which are measurements on two things at once. For example, we might be
looking at spousal pairs, perhaps measuring the difference in height per
pair. The variable we are measuring is the \emph{difference}, and so we
only have one observation per individual, which means that the
individuals must be the pairs of people. A slightly more obvious example
is something like a weight loss study were observing a change in weight
for a certain person, even though we have two observations the
individual is still the person who we're
measuring.{\marginnote{\begin{footnotesize}\textbf{Paired Observations}:
a special type of data where the difference (subtraction) of two values
is what we are studying.\end{footnotesize}}}

\hypertarget{example-what-are-the-individuals-what-are-variables}{%
\subsection{Example: What are the Individuals? What are
Variables?}\label{example-what-are-the-individuals-what-are-variables}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"wt"}\NormalTok{, }\StringTok{"mpg"}\NormalTok{, }\StringTok{"cyl"}\NormalTok{, }\StringTok{"am"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                     wt  mpg cyl am
Mazda RX4         2.620 21.0   6  1
Mazda RX4 Wag     2.875 21.0   6  1
Datsun 710        2.320 22.8   4  1
Hornet 4 Drive    3.215 21.4   6  0
Hornet Sportabout 3.440 18.7   8  0
Valiant           3.460 18.1   6  0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Individuals: Each car (not brand)
\item
  Variables: \texttt{wt}, \texttt{mpg}, \texttt{cyl}, \texttt{am}, etc.

  \begin{itemize}
  \tightlist
  \item
    \texttt{wt}: Quantitative; the weight of the car.
  \item
    \texttt{am}: Binary (categorical); whether the car is automatic or
    manual.
  \item
    \texttt{cyl}: It's the number of cylinders, so it can be considered
    a number. However, there are only three possible values: 4, 6, or 8.
    We \emph{could} consider these numbers, but it is likely more useful
    to think of 4 cylinder cars in one category, 6 cylinder in another
    category, and 8 cylinder in the last category. This way, when we do
    analysis, we are just comparing categories rather than see what
    happens when we add cylinders (``adding cylinders'' makes it sound
    like we might add 1 cylinder to a 4 cylinder car, or like we might
    make predictions about what would happen with a 2 cylinder car).
  \end{itemize}
\end{itemize}

\hypertarget{graphschartsplots}{%
\section{Graphs/Charts/Plots}\label{graphschartsplots}}

\hypertarget{pie-charts}{%
\subsection{Pie Charts}\label{pie-charts}}

\begin{itemize}
\tightlist
\item
  The wedges must sum to 1.

  \begin{itemize}
  \tightlist
  \item
    If ``Adelie'' makes up 44\% of the data, it should be 44\% of the
    pie chart.
  \item
    All penguins are either Adelie, Gentoo, or Chinstrap; no penguins
    have more than one species.
  \end{itemize}
\item
  Mainly good for \emph{emphasizing} one wedge

  \begin{itemize}
  \tightlist
  \item
    \emph{Emphasizing} can easily mean \emph{misrepresenting}, whether
    accidentally or on purpose!
  \end{itemize}
\end{itemize}

\url{https://www.darkhorseanalytics.com/blog/salvaging-the-pie}

In this course, I will not be providing you the code required to make a
pie chart. However, you should understand what a pie chart is, what data
it works for (categories), and how they relate to bar charts.

\hypertarget{bar-charts-categories}{%
\subsection{Bar Charts: Categories}\label{bar-charts-categories}}

Bar charts are similar to pie charts, but better in practically every
way.

Each bar represents a category, and the height represents the number of
observations in that category.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{theme\_set}\NormalTok{(}\FunctionTok{theme\_bw}\NormalTok{())}

\FunctionTok{ggplot}\NormalTok{(mtcars) }\SpecialCharTok{+}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{factor}\NormalTok{(am)) }\SpecialCharTok{+}
    \FunctionTok{geom\_bar}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Transmission Type"}\NormalTok{,}
        \AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-4-1.pdf}

}

\end{figure}

The code required to create the bar chart can be shown by clicking the
``\textgreater Code'' icon. An explanation of the code is below (but
this will \emph{not} be tested).

\textbf{Code Explanation}

The data set is built into our so we don't need to load anything to put
this data. We do need to load in the \texttt{ggplot} library, though. In
my lecture notes, you'll see lots of code that looks like this, but you
will not be tested on your ability to re-create this code. For those
interested, here's a quick breakdown of the functions I used:

\begin{itemize}
\tightlist
\item
  The \texttt{ggplot()} function tells R what data we will be using.
\item
  The \texttt{aes()} function sets up the plot ``aesthetics'', such as
  what variable goes on the x-axis, what variable goes on the y-axis,
  what variable is assigned to a colour, what variable determines the
  shapes of points, etc.
\item
  \texttt{geom\_bar()} actually draws the bar plot using the data set
  that \texttt{ggplot()} set up and the aesthetics, that \texttt{aes()}
  set up.

  \begin{itemize}
  \tightlist
  \item
    Try running the code without this line and see what
    happens!\footnote{It will still create a plot with the correct x and
      y axes, but won't draw the bars.}
  \end{itemize}
\item
  The \texttt{labs()} function simply adds \texttt{lab}el\texttt{s} to
  the plot to make it look nicer.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Compare this to the following table:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{am)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

 0  1 
19 13 
\end{verbatim}

Bar charts are primarily used to compare categories. The most common use
of a bar chart is to count the number of observations in each category,
and create a bar with a corresponding height. In this example, we see,
automatic and manual transmissions, with automatic labelled as zero and
manual labelled as one. We can see that approximately 19 cars are
automatic and 13 cars are manual. Unlike a pie chart, we can read these
numbers off of the plot and it's easy to compare these two categories.

\hypertarget{titanic-example}{%
\subsection{Titanic Example}\label{titanic-example}}

The following example demonstrates why it's important to be clear about
what an ``individual'' is. Depending on how we define an individual, we
might choose to make a different plot!

If we're measuring things about different Sexes (``sexes'' are
``individuals''), we're doing a different study than if we consider
ourselves to be making measurements about different Classes.

Based on this plot, we might be asking how ``Sex'' varies by ``Class''.

\includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-6-1.pdf}

Based on this plot, we might be asking how ``Class'' varies by ``Sex''.

\includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-7-1.pdf}

\textbf{Exercises}

The following exercises are based on the exercises in the (optional)
OpenIntro biostats textbook. They are based on the \textbf{F}unctional
polymorphisms \textbf{A}ssociated with human \textbf{Mu}scle
\textbf{S}ize and \textbf{S}trength, or \texttt{famuss}, data
set.\footnote{The ``FAMUSS'' acronym is a bit of a stretch, but just go
  with it.}

The data are available in the \texttt{oibiostat} pacjage in R, which is
a package based on the OpenIntro Biostat textbook. Don't worry if you
don't know what any of that means - it's not important for this portion
of the course.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(oibiostat)}
\FunctionTok{data}\NormalTok{(famuss)}
\FunctionTok{head}\NormalTok{(famuss)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  ndrm.ch drm.ch    sex age      race height weight actn3.r577x    bmi
1      40     40 Female  27 Caucasian   65.0    199          CC 33.112
2      25      0   Male  36 Caucasian   71.7    189          CT 25.845
3      40      0 Female  24 Caucasian   65.0    134          CT 22.296
4     125      0 Female  40 Caucasian   68.0    171          CT 25.998
5      40     20 Female  32 Caucasian   61.0    118          CC 22.293
6      75      0 Female  24  Hispanic   62.2    120          CT 21.805
\end{verbatim}

The columns are a little difficult to understand, so here's a brief
overview.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
variable & description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{sex} & Biological sex of the patient \\
\texttt{age} & Age (years) \\
\texttt{race} & Self-reported race \\
\texttt{height} & Subject's height in inches \\
\texttt{weight} & Subject's weight in pounds \\
\texttt{bmi} & Subject's body mass index (weight divided by
height\(^2\)) \\
\texttt{actn3.r577x} & I think it's obvious what this column is \\
\texttt{drm.ch} & Again, this is obvious. \\
\texttt{ndrm.ch} & No need to explain this one. \\
\end{longtable}

Okay, so some of the columns need some explaining. The study was
interested in whether a particular genotype affected the ability of
subjects to build muscle. The genotype is at the genome position r557x
in the ACTN3 gene, which is a fancy way of saying that the
\texttt{actn3.r577x} tells us something about the subject's genetic
code. The genotype can be either \texttt{TT}, \texttt{TC}, \texttt{CT},
or \texttt{CC}, and the researchers believed that these genes determine
how easily people build muscle.

The way the study was carried out is as follows. The researchers asked
each subject to perform a test of strength using each arm. Subjects were
then asked to follow a muscle strengthening exercise, but \emph{only} on
their non-dominant side (if they're right handed, they were asked to
strengthen their left arm). After the strengthening, they repeated the
test of strength. The columns labelled \texttt{drm.ch} and
\texttt{ndrm.ch} are the percentage change in their strength for their
dominant arm and their non-dominant arm (the dominant arm was measured
to see whether the patients gained or lost strength for reasons other
than the prescribed strength training exercise).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Based on the R output, what type of variable is each column?
\item
  What counts as an individual in this study?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Each person
  \item
    Each pair of people
  \item
    Each arm (two per person in the study)
  \item
    Each column in the data
  \end{enumerate}
\item
  Explain why either a bar chart or a pie chart would be appropriate for
  the \texttt{actn3.r577x} column. Be extremely precise.
\end{enumerate}

\hypertarget{ordered-and-unordered}{%
\subsection{Ordered and Unordered}\label{ordered-and-unordered}}

Whether the categorical variable is ordered or unordered affects the way
we make the plot:

\begin{itemize}
\tightlist
\item
  Ordered: put the bars in order

  \begin{itemize}
  \tightlist
  \item
    For example, if we have data from 2020, 2021, and 2022, then we
    would have the bars in that order!
  \end{itemize}
\item
  Unordered: put it in an arbitrary order

  \begin{itemize}
  \tightlist
  \item
    Alternative: order according to largest to smallest.
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(palmerpenguins)}
\FunctionTok{ggplot}\NormalTok{(penguins) }\SpecialCharTok{+}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species) }\SpecialCharTok{+}
    \FunctionTok{geom\_bar}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Count"}\NormalTok{,}
        \AttributeTok{title =} \StringTok{"Unordered Categories"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-9-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(forcats) }\CommentTok{\# For rearranging "factors", aka. categorical variables}
\FunctionTok{ggplot}\NormalTok{(penguins) }\SpecialCharTok{+}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{fct\_infreq}\NormalTok{(species)) }\SpecialCharTok{+}
    \FunctionTok{geom\_bar}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Count"}\NormalTok{,}
        \AttributeTok{title =} \StringTok{"Unordered Categories, Ordered by Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-10-1.pdf}

}

\end{figure}

The bar chart is the de-facto standard for categorical variables,
whether binary or otherwise. For quantitative, variables, we need other
options.

\hypertarget{quantitative-variables}{%
\subsection{Quantitative Variables}\label{quantitative-variables}}

Recall the distinction between discrete and continuous:

\begin{itemize}
\tightlist
\item
  Discrete (whole numbers)

  \begin{itemize}
  \tightlist
  \item
    Ex. Number of students in a classroom.
  \end{itemize}
\item
  Continuous (could be measured with more precision)

  \begin{itemize}
  \tightlist
  \item
    Ex. height
  \end{itemize}
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Grey Area}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

What type of variable is ``dose level'', defined as either no dose, half
dose, or full dose? They aren't whole numbers, but we can't measure them
with greater precision!

\end{tcolorbox}

Quantitative variables are split into discrete and continuous variables.
Discrete variables are generally represented by whole numbers, for
example, the number of students in a given classroom.

In contrast, continuous numbers could be anything! I like to think of
them as numbers that could've been measured with more precision if we
had better tools. For example, peoples Heights could be measured to
infinite precision if we had perfect tools, whereas we don't need better
tools to measure the number of children in a family more precisely.

Of course, as with all things, there is a gray area here. Many studies
will choose to give their subjects either no dose, a half dose or a full
dose. These are obviously numbers and it is very likely that the
response for a 0.75 dose is somewhere in between the half dose and the
full dose. However, we chose these numbers and thus there are only three
possible numbers. No amount of measuring is going to give us something
other than a half dose (any deviation in administration of the dose can
hopefully be ignored for the purpose of the study). In the definitions
we've used it is neither a whole number, nor cannot be measured with
higher precision. For the purposes of visualization, we might actually
want to use a bar chart as if this were a categorical variable. If the
dose had more categories and we expected the response to have a smooth
trend across different dose levels, then we might use visualizations
meant for discrete data. If the dose could have been any number between
zero and one then we might use visualization meant for continuous data.

\hypertarget{plotting-quantitative-variables}{%
\subsection{Plotting Quantitative
Variables}\label{plotting-quantitative-variables}}

Here are the lengths of sharks:

\begin{verbatim}
 9.4 12.1 12.2 12.3 12.4 12.6 13.2 13.2 13.2 13.2 13.5
13.6 13.6 13.8 14.3 14.6 14.7 14.9 15.2 15.3 15.7 15.7
15.8 15.8 16.1 16.2 16.2 16.4 16.4 16.6 16.7 16.8 16.8
17.6 17.8 17.8 18.2 18.3 18.6 18.7 18.7 19.1 19.7 22.8
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Even though we only know the data to one decimal point, we could have
  measured more precisely!

  \begin{itemize}
  \tightlist
  \item
    This is a continuous variable.
  \item
    Note that there are ties in these data, and thus we could make bar
    charts with bars that are more than one unit tall. However, if we
    measured more precisely, these ties would go away.
  \end{itemize}
\item
  Can't just draw a bar chart with all sharks that were 9.4, all that
  were 12.1, \ldots{}
\end{itemize}

How many we display this collection of shark lengths? It is clear that
there are many different values that we could've gotten for the length
and so we might not want to use something like a bar chart. Let's try it
anyway.

\hypertarget{quantitative-variables-as-a-bar-chart}{%
\subsection{Quantitative Variables as a Bar
Chart}\label{quantitative-variables-as-a-bar-chart}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{theme\_set}\NormalTok{(}\FunctionTok{theme\_bw}\NormalTok{())}
\NormalTok{sharks }\OtherTok{\textless{}{-}}  \FunctionTok{c}\NormalTok{(}\FloatTok{9.4}\NormalTok{, }\FloatTok{12.1}\NormalTok{, }\FloatTok{12.2}\NormalTok{, }\FloatTok{12.3}\NormalTok{, }\FloatTok{12.4}\NormalTok{, }\FloatTok{12.6}\NormalTok{, }\FloatTok{13.2}\NormalTok{, }\FloatTok{13.2}\NormalTok{, }\FloatTok{13.2}\NormalTok{, }\FloatTok{13.2}\NormalTok{, }\FloatTok{13.5}\NormalTok{,}
\FloatTok{13.6}\NormalTok{, }\FloatTok{13.6}\NormalTok{, }\FloatTok{13.8}\NormalTok{, }\FloatTok{14.3}\NormalTok{, }\FloatTok{14.6}\NormalTok{, }\FloatTok{14.7}\NormalTok{, }\FloatTok{14.9}\NormalTok{, }\FloatTok{15.2}\NormalTok{, }\FloatTok{15.3}\NormalTok{, }\FloatTok{15.7}\NormalTok{, }\FloatTok{15.7}\NormalTok{,}
\FloatTok{15.8}\NormalTok{, }\FloatTok{15.8}\NormalTok{, }\FloatTok{16.1}\NormalTok{, }\FloatTok{16.2}\NormalTok{, }\FloatTok{16.2}\NormalTok{, }\FloatTok{16.4}\NormalTok{, }\FloatTok{16.4}\NormalTok{, }\FloatTok{16.6}\NormalTok{, }\FloatTok{16.7}\NormalTok{, }\FloatTok{16.8}\NormalTok{, }\FloatTok{16.8}\NormalTok{,}
\FloatTok{17.6}\NormalTok{, }\FloatTok{17.8}\NormalTok{, }\FloatTok{17.8}\NormalTok{, }\FloatTok{18.2}\NormalTok{, }\FloatTok{18.3}\NormalTok{, }\FloatTok{18.6}\NormalTok{, }\FloatTok{18.7}\NormalTok{, }\FloatTok{18.7}\NormalTok{, }\FloatTok{19.1}\NormalTok{, }\FloatTok{19.7}\NormalTok{, }\FloatTok{22.8}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sharks) }\SpecialCharTok{+} \FunctionTok{geom\_bar}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-11-1.pdf}

}

\end{figure}

This plot demonstrates why bar chart isn't appropriate for these data.
We can see that each data point essentially gets its own bar, and so the
heights are no longer meaningful. The exception is that these data are
rounded to one decimal place, and so some lengths end up in the same
bar. Knowing that some of our data are rounded to the same value is not
necessarily meaningful for any analyses that we might want to do.
Instead, we would like a chart that shows us where most of the data are,
and whether or not they are clear patterns in these data.

\hypertarget{histograms-put-observations-into-bins}{%
\subsection{Histograms: Put observations into
bins}\label{histograms-put-observations-into-bins}}

The steps in building a histogram:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose the bins.

  \begin{itemize}
  \tightlist
  \item
    e.g.~(0,10{]}, (10,20{]}, (20, 30{]}, etc.

    \begin{itemize}
    \tightlist
    \item
      The notation (a, b{]} means that ``a'' is \emph{not} included in
      the interval, but ``b'' is. We have no sharks that have a length
      of 0, but a shark with a recorded length of exactly 10 would be in
      the first bin, labelled (0, 10{]}, not the second bin that is
      labelled (10, 20{]}.
    \end{itemize}
  \end{itemize}
\item
  Count the number of obs. in each bin.
\item
  Draw a bar chart as if the bins are categories.

  \begin{itemize}
  \tightlist
  \item
    Bars should touch since there's nothing in between.
  \end{itemize}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Note that I\textquotesingle{}ve manually chosen the bin widths and centers.}
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sharks) }\SpecialCharTok{+}
    \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth=}\DecValTok{2}\NormalTok{, }
        \AttributeTok{center =} \DecValTok{0}\NormalTok{, }\CommentTok{\# Only need to specify the center of one bin}
        \AttributeTok{colour =} \StringTok{"black"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"lightgrey"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Shark Length"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-12-1.pdf}

}

\end{figure}

In this histogram, the bins are (-1, 1{]}, (1,3{]}, (3,5{]}\ldots{}

Notice how the y-axis is still ``Counts'' (like a bar chart).

Most of the time we will probably want to use a histogram to display
quantitative, continuous data. A histogram is very much like putting
continuous numbers into discrete bins, and then showing it as a bar
chart. In this example, I chose bins from 1 to 3, then 3 to 5, then 5 to
7, and so on. For the bar on this histogram centred at a shark length of
12 we can see that there were five observations between 11 and 13. Note
that the definitions of bins has a round bracket on the left side and
the square bracket on the right side, this is to say that the left end
point \emph{is not} included but the right end point \emph{is} included.
This is just to account for cases where X may fall directly on the
border between two bins, and we have to choose which bin. The actual bin
we choose is arbitrary, kind of like driving in the left or the right.
You will not be tested on whether you can remember which endpoint is
inclusive.

From the plot, we can see that most of the sharks are around 16 feet in
length with sun going down to 10 feet and some as long as around 22
feet. The plot has a nice bell shape.

\hypertarget{histograms-bin-width-matters}{%
\subsection{Histograms: Bin Width
Matters!}\label{histograms-bin-width-matters}}

These histograms are showing the same data!

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sharks) }\SpecialCharTok{+}
    \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth=}\DecValTok{2}\NormalTok{, }
        \AttributeTok{center =} \DecValTok{0}\NormalTok{, }\CommentTok{\# Only need to specify the center of one bin}
        \AttributeTok{colour =} \StringTok{"black"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"lightgrey"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Shark Length"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-13-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sharks) }\SpecialCharTok{+}
    \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth=}\FloatTok{1.5}\NormalTok{, }
        \AttributeTok{center =} \FloatTok{0.75}\NormalTok{, }\CommentTok{\# Only need to specify the center of one bin}
        \AttributeTok{colour =} \StringTok{"black"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"lightgrey"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Shark Length"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-14-1.pdf}

}

\end{figure}

In the previous graph, it looked like the distribution of sharks
followed a nice bell-shaped curve. However, if we use bins that are 1.5
units wide we get a plot that looks fairly different. It still looks
like most sharks are around 16 feet and some go down to 10 and some go
as high is 22 or 23, But we see a large bar that covers 12 to 13.5.

With histograms the bins that you choose are extremely important. Most
software have default values that are generally reasonable, But it's
always always always worth investigating other bins.

A simple version of the plot can be made as follows, where
\texttt{ggplot} chooses the bins automatically. Note that this is rarely
desireable, and you should almost always choose the bins yourself.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sharks) }\SpecialCharTok{+}
    \FunctionTok{geom\_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-15-1.pdf}

}

\end{figure}

Below is an app to visualize the difference that the binwidth can make!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DBecker7/DB7\_TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Apps/DensHist"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{describing-distributions}{%
\subsection{Describing Distributions}\label{describing-distributions}}

When you're asked to comment on a histogram, always mention the
following:

\begin{itemize}
\tightlist
\item
  \textbf{Shape}: \textbf{Unimodal}/\textbf{bimodal} and
  \textbf{skewness}

  \begin{itemize}
  \tightlist
  \item
    Skewness: put a glob of peanut butter on toast, ``skew'' it to one
    side.
  \end{itemize}
\item
  \textbf{Center}: midpoint (\textbf{mean}/\textbf{median})

  \begin{itemize}
  \tightlist
  \item
    \textbf{Mode} depends on the bin!
  \item
    Skewness shows up in the relation between mean and median: ``Mean
    less (than median) means left (skew).''
  \end{itemize}
\item
  \textbf{Spread}: the \textbf{range}/\textbf{variance}/\textbf{IQR}

  \begin{itemize}
  \tightlist
  \item
    More on IQR later!
  \end{itemize}
\item
  \textbf{Outliers}: points that don't fit the shape

  \begin{itemize}
  \tightlist
  \item
    More on outliers when we cover IQR!
  \end{itemize}
\end{itemize}

There are many shapes that a histogram can show. A distribution can be
skewed (or ``heavy-tailed''), which means that it looks like a bell
curve but one side has a longer/thicker tail. We also want to know about
several measures of the center of the distribution, as well as how
spread out it is. Outliers are also something interesting to note;
outliers are something that are \emph{not} part of the shape (so you
wouldn't consider them when evaluating the skewness of a distribution).

Try drawing out each of these shapes/patterns!

\hypertarget{example-what-is-the-shape}{%
\subsection{Example: What is the
Shape?}\label{example-what-is-the-shape}}

\includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-17-1.pdf}

This represents a \textbf{bimodal} distribution because it has two peaks
(the word ``mode'' can refer to the category with the most observations,
but it can also refer to the top of a peak). This would be described as
a bimodal distribution with centres around 190 and 215, ranges around
195 to 205 and 205 to 235, with both peaks being symmetric and without
any outliers.

\hypertarget{example-what-is-the-shape-1}{%
\subsection{Example: What is the
Shape?}\label{example-what-is-the-shape-1}}

\includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-18-1.pdf}

This is the classic sort of gotcha question that I like to use. This is
actually a bar chart that I modified so that the bars have no space
in-between - the x-labels are categories, not ranges! It may look
somewhat symmetric and unimodal without any outliers, but the x-labels
are out of order. These numbers are just numerical encodings of species
names - 1 refers to Adelie penguins, 2 refers to Chinstrap, and 3 refers
to Gentoo. These numbers were applied alphabetically because there isn't
really a logical way to order these species: they're unordered
categories!

So, basically, it does not make sense to talk about shape in a bar graph
where the labels could have been put in any order!

\hypertarget{purely-pedagogical-stem-and-leaf-plots.}{%
\subsection{Purely Pedagogical: Stem-and-Leaf
plots.}\label{purely-pedagogical-stem-and-leaf-plots.}}

Consider the data

\begin{verbatim}
12, 43, 12, 32, 53, 66, 78, 25, 36, 12, 26,
34, 98, 39, 44, 23, 15, 67, 1,  4,  54, 21
\end{verbatim}

\textbf{Stem-and-Leaf}

\begin{verbatim}
0  | 14
10 | 2225
20 | 1356
30 | 2469
40 | 34
50 | 34
60 | 67
70 | 8
80 |
90 | 8
\end{verbatim}

\textbf{Sideways Histogram}

\includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-19-1.pdf}

This visualization technique is shown purely for pedagogical reasons. A
stem and leaf plot is like a histogram where the bins are all powers of
10. It is displayed using the stem which is the first digit, and the
leaf which is the second digit. For example, the number 78 has a 7 in
the tens place (the tens place is the stem) and an 8 in the ones place
(and we're using the ones place as the leaf). In the stem and leaf plot,
78 goes on the stem labelled 70 and it gets a leaf of eight. Going the
other way, we can see a stem labelled 90 and a leaf labelled eight which
corresponds to the number 98. For the stem labelled zero we have the
numbers one and four, for the stem label 10 we have the numbers 12, 12,
12, and 15.

Essentially, this is just a histogram. Instead of drawing a bar that
corresponds to the number of observations in that bin, we are just
listing the observations in that bin. Compare the stem and leaf plot to
the sideways histogram on the right: in the first bin from 0 to 10 (not
including 10) there are two numbers, one and four, and the length of the
bin is two. For the stem label 20, we have the numbers 21, 23, 25 and
26, and this is displayed as a bar with length four in the histogram.

The main reason for showing this visualization technique is that it can
be very useful for tests and quizzes, because it allows you to create a
histogram without software. It also allows easy computation of the
median since all of the leaves are in order. These are not used in
practice because in practice you will have software to create histograms
\emph{and} find the median!\footnote{That software is R!}

Note that the shape of the distribution can be seen from the stem and
leaf plot. It is a unimodal distribution that is right skewed and likely
does not have any clear outliers (there is one point that appears to be
separate from the others, but this might be due to bin choice).

\hypertarget{summary}{%
\subsection{Summary}\label{summary}}

\begin{itemize}
\tightlist
\item
  \textbf{Individuals} are what we make measurements on

  \begin{itemize}
  \tightlist
  \item
    Can be pairs, dates, or people
  \end{itemize}
\item
  \textbf{Variables} are what we measure

  \begin{itemize}
  \tightlist
  \item
    Can be derived from other measurements
  \end{itemize}
\item
  You will not be asked to do anything with pie charts in this course.
\item
  \textbf{Bar charts} show counts of categories.

  \begin{itemize}
  \tightlist
  \item
    Can optionally sum to 1 (like a pie chart).
  \end{itemize}
\item
  \textbf{Histograms} are like bar charts for binned data.

  \begin{itemize}
  \tightlist
  \item
    \textbf{Bins matter}.
  \item
    Must interpret \textbf{shape}.
  \end{itemize}
\end{itemize}

\hypertarget{exercises}{%
\section{Exercises}\label{exercises}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Which of the following plots would be appropriate for the \texttt{bmi}
  column?
\end{enumerate}

\textbf{Bar chart}

What do you think? Does the plot below give you any useful information
about the data?

\includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-20-1.pdf}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Pie Chart}

No.~I'm not even going to try in this case.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Histogram}

Correct! The plot below tells us where most of the subjects' BMI lie. We
can see that most of the subjects are between 15 and 30, with a few
between 30 and 35 and few above 35.

This is the whole reason we categorize variables as quantitative or
categorical: knowing the type of the variable tells us which plots will
give us useful information!

\includegraphics{L01-Intro_PicturingGraphs_files/figure-pdf/unnamed-chunk-21-1.pdf}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Prescriptions of opioid pain relievers.} Opioid pain relievers
  are prescribed at a higher rate in the United States than in any other
  nation, even though abuse of these medications can result in addiction
  and fatal overdoses. The CDC examined opioid pain reliever
  prescriptions in each state to find out how variable prescription
  rates are across the nation. Here are the 2012 state prescription
  rates, in number of prescriptions per 100 people, listed in increasing
  order:
\end{enumerate}

\texttt{opiods\ \textless{}-\ c(52.0,\ 57.0,\ 59.5,\ 61.6,\ 62.9,\ 65.1,\ 66.5,\ 67.4,\ 67.9,\ 69.6,\ 70.8,\ 71.2,\ 71.7,\ 72.4,\ 72.7,\ 72.8,\ 73.8,\ 74.3,\ 74.3,\ 74.7,\ 76.1,\ 77.3,\ 77.5,\ 79.4,\ 82.0,\ 82.4,\ 85.1,\ 85.6,\ 85.8,\ 88.2,\ 89.2,\ 89.6,\ 90.7,\ 90.8,\ 93.8,\ 94.1,\ 94.8,\ 96.6,\ 100.1,\ 101.8,\ 107.0,\ 109.1,\ 115.8,\ 118.0,\ 120.3,\ 127.8,\ 128.4,\ 137.6,\ 142.8,\ 142.9)}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Make a histogram of the state opioid pain reliever prescription rates
  using classes of width 10 starting at 50.0 prescriptions per 100
  people. e.g.~(50, 60{]}. Do this by hand first, then using R.
\item
  Would you say that the distribution is single-peaked or
  multiple-peaked? Is it roughly symmetric or skewed?
\end{enumerate}

The Statistical Abstract of the United States, prepared by the Census
Bureau, provides the number of single-organ transplants for the year
2010, by organ. The following two exercises are based on this table:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Disease & Count \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Heart & 2,333 \\
Lung & 1,770 \\
Liver & 6,291 \\
Kidney & 16,898 \\
Pancreas & 350 \\
Intestine & 151 \\
\end{longtable}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  The data on single-organ transplants can be displayed in
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  a pie chart but not a bar graph.
\item
  a bar graph but not a pie chart.
\item
  either a pie chart or a bar graph.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Kidney transplants represented what percent of single- organ
  transplants in 2010?
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Nearly 61\%.
\item
  One-sixth (nearly 17\%).
\item
  This percent cannot be calculated from the information provided in the
  table.
\end{enumerate}

See also:
\href{https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book\%3A_OpenIntro_Statistics_(Diez_et_al)./01\%3A_Introduction_to_Data/1.E\%3A_Introduction_to_Data_(Exercises)}{OpenIntro
Textbook} problems relating to visualizations that we have learned,
especially 1.30, 1.36, 1.37, 1.39, 1.40, 1.47.

\hypertarget{crowdsourced-questions}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  In a study examining the effects of a new dietary supplement on plant
  growth, researchers measure the following variables. Which of the
  variables listed is qualitative?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Type of plant (e.g., fern, moss, flowering plant)
  \item
    Growth rate (cm per week)
  \item
    Color intensity of leaves (rated on a scale of 1-10)
  \item
    Number of leaves produced after a 2-month period
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

The correct answer is 1. Type of plant. This variable is qualitative
because it describes a category or quality of the plant (e.g., fern,
moss, flowering plant) rather than quantifying a characteristic.
Qualitative data, also known as categorical data, includes descriptions
or characteristics that cannot be measured or counted in the traditional
sense. Variables 2, 3, and 4 are quantitative because they involve
measurements or counts that result in numerical values: growth rate is
measured in cm per week (continuous), color intensity of leaves is rated
on a numerical scale (ordinal), and the number of leaves is a count
(discrete).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{describing-distributions-with-numbers}{%
\chapter{Describing Distributions with
Numbers}\label{describing-distributions-with-numbers}}

\hypertarget{quantitative-variables-1}{%
\section{Quantitative Variables}\label{quantitative-variables-1}}

\hypertarget{parameters-versus-statistics}{%
\subsection{Parameters Versus
Statistics}\label{parameters-versus-statistics}}

\begin{itemize}
\tightlist
\item
  Numerical summaries are called parameters when they describe an entire
  population, and statistics when they describe a sample.
\item
  Since we typically will not collect data on the entire population, we
  use (sample) statistics to make statements (with some uncertainty)
  about what the (population) parameter is.
\item
  Categorical variables are summarized by the count or proportion
  (percent) of the data in each category.
\item
  Quantitative variables are summarized by the centre and spread of the
  data
\end{itemize}

\hypertarget{parameters-versus-statistics-truth}{%
\subsection{\texorpdfstring{Parameters Versus Statistics:
``\,````Truth''``\,''}{Parameters Versus Statistics: ``\,``\,``Truth''\,``\,''}}\label{parameters-versus-statistics-truth}}

We assume there's some ``true'' population mean.

\begin{itemize}
\tightlist
\item
  This will change if, say, a new baby is born.
\end{itemize}

We cannot know the population parameter!

If we were able to measure the height of every Canadian at this very
instant, we would get one value. We can't do this though, so we collect
a sample instead. We try to collect the sample in such a way that we get
value close to the population parameter.

In this course, we make a big distinction between population parameter
and sample statistic. A sample statistic is something that we calculate
from a sample, where is the population? Parameter is the value that we
would get if we had the whole population.

Most of this course is centred around using the sample statistic to get
an idea of what the population parameter might be.

\hypertarget{measures-of-centre}{%
\subsection{Measures of Centre}\label{measures-of-centre}}

\hypertarget{the-centre}{%
\subsection{The Centre}\label{the-centre}}

The ``centre'' is a strange concept.

\begin{itemize}
\tightlist
\item
  Where are ``most'' of the data?
\item
  If we took an individual at random, what's the ``best guess'' of their
  height?
\end{itemize}

We want to \textbf{summarize} the data using a few words/numbers.

I prefer the second description here - if I were to make a prediction, I
want my predicted value to be close to the actual value. For example, I
might want to design something that fits the average person's height. I
must make a prediction about the height of the people that will use it.
My prediction is chosen to minimize how far off I would be, which means
that I want to be near the ``centre''. \#\#\# Centre 1: The Median

The \textbf{median} (\(M\)) is the midpoint of a distribution: half the
observations are smaller and the other half are larger than it. To find
the median:{\marginnote{\begin{footnotesize}\textbf{Median}: The middle
number after you've put all the values in order.\end{footnotesize}}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Arrange all observations in order of size, from smallest to largest.
\item
  If the number of observations (\(n\)) is odd, the median \(M\) is the
  centre observation in the ordered list. Find the location of the
  median by counting \((n + 1)/2\) observations up from the smallest
  observation.
\item
  If n is even, the median \(M\) halfway between the two centre
  observations in the ordered list. The location of the median is again
  \((n + 1)/2\), counting from the smallest observation in the list.
\end{enumerate}

Basically, the median is the middle value. With odd \(n\), the middle
value is one of the observations, but when \(n\) is even we have to go
in between two values.

\begin{itemize}
\tightlist
\item
  1

  \begin{itemize}
  \tightlist
  \item
    The median is 1.
  \end{itemize}
\item
  1 2

  \begin{itemize}
  \tightlist
  \item
    The median is 1.5, which occurs at the \((n+1)/2\) position.
  \end{itemize}
\item
  1 2 3

  \begin{itemize}
  \tightlist
  \item
    The median is 2.
  \end{itemize}
\item
  1 2 3 4

  \begin{itemize}
  \tightlist
  \item
    The median is 2.5
  \end{itemize}
\item
  Continue the pattern on your own!
\end{itemize}

\hypertarget{example-1-odd-n}{%
\subsection{\texorpdfstring{Example 1: Odd
\(n\)}{Example 1: Odd n}}\label{example-1-odd-n}}

The distribution of needle lengths is how species of pine trees are
characterized. The following data are the lengths (in cm) of a sample of
15 needles taken at random from different parts of several Aleppo pine
trees (Southern California). What is the median length?

\begin{verbatim}
7.20 7.60  8.50  8.50  8.70  9.00  9.00 9.30
9.40 9.40 10.20 10.90 11.30 12.10 12.80
\end{verbatim}

\hypertarget{example-2-even-n}{%
\subsection{\texorpdfstring{Example 2: Even
\(n\)}{Example 2: Even n}}\label{example-2-even-n}}

We also have the lengths (in cm) of 18 needles from trees of the
noticeably different Torrey pine species. What is the median length for
these 18 pine needles? The ordered data are:

\begin{verbatim}
21.20 21.60 21.70 23.10 23.70 24.20 24.20 25.50 26.60
26.80 28.90 29.00 29.70 29.70 30.20 32.50 33.70 33.70
\end{verbatim}

\hypertarget{example-3-robustness}{%
\subsection{Example 3: Robustness}\label{example-3-robustness}}

\begin{verbatim}
Set 1: 1 2 3 4 5 6
Set 2: 1 1 1 6 6 6
Set 3: -2000 -1000 3 4 5000 60000000
\end{verbatim}

All three have the same median!

Do the ``centres'' make sense? Do they provide a good summary?

These three data sets demonstrate that the median only depends on the
middle two numbers when \(n\) is odd\footnote{The median only depends on
  the middle number (singular) when \(n\) is even.}. For the first two
data sets, the median does seem to describe centre of the data well.

The last data set is a little bit different from the others and the
median might not be enough information. This will come up again and
again: if your data set is ``nice'' (unimodal and no clear outliers),
then summary statistics work well; a simple number can describe a simple
data set. A complex data set needs more complicated numbers.\footnote{If
  your data requires complex numbers (\(\sqrt{-1}\)), then you have a
  \textbf{very} interesting data set!}

\hypertarget{the-mean}{%
\subsection{The Mean}\label{the-mean}}

The \textbf{mean} is defined
as:{\marginnote{\begin{footnotesize}\textbf{Mean}: Add all the numbers,
divide by how many numbers you added.\end{footnotesize}}}

\[
\bar x = \frac{1}{n}(x_1 + x_2 + ... + x_n)= \frac{1}{n}\sum_{i=1}^nx_i
\]

For example, the mean of (1, 2, 3, 4) is \[
\frac{1}{4}(1 + 2 + 3 + 4) = \frac{10}{4} = 2.5
\] (this also happens to be the median!)

The mean has a few interesting interpretations:

\begin{itemize}
\tightlist
\item
  If we had a metre stick and put a 1kg weight on each of the values,
  the mean is where the metre stick would balance.
\item
  If someone pulled one of the observed values out of a hat and we were
  punished based on how wrong our guess was, the mean would be least
  overall punishment. This formula for the mean may look a little bit
  scary, but all it means is that we add up all of the values that we
  have and divide by the number of values.
\end{itemize}

Create a couple examples yourself and find the mean! If you create a
list of values, you can use R to check your work as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_values }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\FloatTok{6.3212}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\FunctionTok{mean}\NormalTok{(my\_values)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.29015
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The name ``\texttt{my\_values}'' could have been anything that is just
  letters, numbers, and underscores (no spaces, can't start with a
  number). It's just the name of an object in R.

  \begin{itemize}
  \tightlist
  \item
    An object is just a thing. You can put two things together, do a
    function of a thing, etc.
  \end{itemize}
\item
  \texttt{my\_values} is a \emph{vector}. That is, it's a collection of
  values.

  \begin{itemize}
  \tightlist
  \item
    We create it using the \texttt{c()} function, which means
    ``concatenate'', or ``put together''.
  \end{itemize}
\item
  The mean function takes a vector and calculates the mean for you.
\end{itemize}

To run this code, go to \url{wlu.syzygy.ca} and create a new R notebook.
Insert an ``R cell'', and copy/paste the code above into that cell.
Either hit the ``play'' button, or Alt+Enter (Option+Enter on a Mac).
Alternatively, you can open up an R script in RStudio if you have it
installed on your computer.

A word of caution: R sometimes calculates the median in a different way
than we do in the course. Check your work with R, but do it by hand when
asked!

\hypertarget{the-mean-is-not-robust}{%
\subsection{\texorpdfstring{The mean is \emph{not}
robust}{The mean is not robust}}\label{the-mean-is-not-robust}}

Consider the following sets of data:

\begin{verbatim}
Set 1: 1, 2, 3, 4, 5, 6
Set 2: 1, 2, 3, 4, 5, 60
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Both have the same median.
\item
  Mean of 3.5 and 12.5, respectively.
\end{itemize}

Which do you think is the correct measure of the centre?

Unlike the median, which only depends on the middle value, the mean uses
information from all of the values. This means that if there's an
outlier or a misrecorded point, the mean will reflect this. The median
will not change, though, which is why we call it \textbf{robust}.
Sometimes this is what we want and sometimes it is not.
{\marginnote{\begin{footnotesize}\textbf{Robust}: A statistic is robust
if a small change to the data, such as adding/removing an outlier, does
not affect that statistic.\end{footnotesize}}}

A common example of when the mean is not what we want is income. The
lowest possible income is zero, but there is no maximum income, so
incomes tend to be right skewed. The right skew affects the mean a lot
more than that affects the median, and so, in this case the median is a
better measure of the most common levels of income.

\hypertarget{mean-and-median-vs.-skew-mean-less-means-left}{%
\subsection{Mean and Median vs.~Skew: Mean less means
left}\label{mean-and-median-vs.-skew-mean-less-means-left}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DBecker7/DB7\_TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Apps/MeanLessMeansLeft"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The app above will be used in class, so do not worry if you're unable to
run it. It demonstrates that when they mean is less than the median it
means it's left skewed. The reason for this is that extra weight in the
skewed direction affect the mean more than they affect the median.

\hypertarget{measures-of-spread}{%
\section{Measures of Spread}\label{measures-of-spread}}

\hypertarget{which-has-more-variance}{%
\subsection{Which has more variance?}\label{which-has-more-variance}}

\begin{verbatim}
Set 1: 1 1 1 5 5 5
Set 2: 1 2 3 3 4 5
Set 3: 1 3 3 3 3 5
\end{verbatim}

\begin{itemize}
\tightlist
\item
  All have the same \textbf{range} (max -
  min).{\marginnote{\begin{footnotesize}\textbf{Range}: The difference
  between the maximum and minimum.\end{footnotesize}}}
\end{itemize}

These three data sets all have the same mean and median, but just
looking at them shows that they are different collections of numbers.
The first set only has two unique values, but those values are
relatively far away from each other compared to the other sets. The
second set is a more even spread from one to five. The third set has
four valued equal to the mean and two values that may be outliers.

To me, the first set looks like it's the most variable because all of
the values are very far away from either the mean or the median. The
second set has a smaller variance, because there are values closer to
the mean. And the last set I expect to have the lowest variance because
most values are actually equal to the mean.

The formula for the variance, which will be introduced next, matches
this intuition. However, many students have different intuitions about
which has the most variance - those are valid but harder to quantify.

\hypertarget{measure-of-spread-the-variance}{%
\subsection{Measure of Spread: The
Variance}\label{measure-of-spread-the-variance}}

Consider set 1, which has a mean of 3:

\begin{verbatim}
1 1 1 5 5 5
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The distances to the mean are all -2 or 2

  \begin{itemize}
  \tightlist
  \item
    If we found the mean of these distances, we'd get 0! We need to make
    sure they're all positive.
  \end{itemize}
\item
  Possibility 1: Absolute value. The average \emph{absolute} distance to
  the mean is 2.
\item
  Possibility 2: Squared value.

  \begin{itemize}
  \tightlist
  \item
    The \textbf{average squared distance to the mean} is 4

    \begin{itemize}
    \tightlist
    \item
      Important: This is not the actual variance calculation!
    \end{itemize}
  \end{itemize}
\end{itemize}

The \textbf{variance} is the average \emph{squared} distance to the
mean{[}\textbf{Variance}: The average squared distance to the mean.{]}

We are basically (but not quite) looking at the average deviation from
the mean. We want that deviation to be positive and there are several
ways to do this. We have settled on squaring the numbers for the same
reason we drive on the right side of the road in Canada: it's just
convention. There are benefits to using the absolute distance from the
mean, but there are many mathematical advantages to squaring the values
first.

\hypertarget{variance-formula}{%
\subsection{Variance Formula}\label{variance-formula}}

\vspace{1.5cm}

\[
s^2 = \frac{1}{n-1}\sum_{i=1}^n(x_i - \bar x)^2
\]

We use \(n-1\) because of math reasons.

The easiest way to calculate this is to put it in a table:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\(i\) & \(x_i\) & \(x_i - \bar x\) & \((x_i - \bar x)^2\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 1 & -2 & 4 \\
2 & 1 & -2 & 4 \\
3 & 1 & -2 & 4 \\
4 & 5 & 2 & 4 \\
5 & 5 & 2 & 4 \\
6 & 5 & 2 & 4 \\
\(\sum\) & 18 & 0 & 24 \\
\end{longtable}

The mean is 3, and the variance is 24/5 = 4.8.

In the table above, as before, the subscript \(i\) is just used to
denote different observations. For example \(x_1\) is the first
observation, \(x_2\) is the second observation in our data, and so on
(this ordering is arbitrary).

In order to calculate the variance, we must first know the mean, and so
it's convenient to put this at the bottom of the table. We then square
the deviations from the mean and divide by \(n-1\). There are very good
technical reasons why we divide by (n-1) that we won't get into here.
Come to my office and chat if you'd like to know more, or just ask
ChatGPT!

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{\(n-1\) in the denominator}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

As a quick explanation for \(n-1\), consider the variance of a single
observation. It doesn't vary! There's not enough information to see how
much variance there is. There isn't enough \emph{information} in our
data. The \(n-1\) in the denominator enforces this - we can't calculate
the variance of one observation.

\end{tcolorbox}

Note that the variance can be calculated in R as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_values }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\FloatTok{6.3212}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\FunctionTok{var}\NormalTok{(my\_values)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.050982
\end{verbatim}

\hypertarget{the-variance-and-the-standard-deviation}{%
\subsection{The Variance and the Standard
Deviation}\label{the-variance-and-the-standard-deviation}}

\[
s = \sqrt{\frac{1}{n-1}\sum_{i=1}^n(x - \bar x)^2}
\]

The \textbf{standard deviation} (or \textbf{sd}) is just the square root
of the variance.

\begin{itemize}
\tightlist
\item
  This makes it have the same units as the original data.
\end{itemize}

In addition, if we have two data sets and the variance of one is larger
than the other, then the standard deviation is also larger. They're the
same thing, just in different units!

I will often refer to one when I mean the other. When I'm comparing
standard deviations, I may call them variances because the same patterns
will be there.

Here's the R code:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(my\_values)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.746706
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(my\_values)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.050982
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(my\_values)}\SpecialCharTok{\^{}}\DecValTok{2} \CommentTok{\# the sd is the square root of the variance}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.050982
\end{verbatim}

\hypertarget{exercise-variation-of-the-three-sets}{%
\subsection{Exercise: Variation of the three
sets}\label{exercise-variation-of-the-three-sets}}

\begin{verbatim}
Set 1: 1 1 1 5 5 5
Set 2: 1 2 3 3 4 5
Set 3: 1 3 3 3 3 5
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw out bar plots.
\item
  Set up the table and find the variance.
\item
  Compare the standard deviations; make a conclusion.
\end{enumerate}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\(i\) & \(x_i\) & \(x_i - \bar x\) & \((x_i - \bar x)^2\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & & & \\
2 & & & \\
3 & & & \\
4 & & & \\
5 & & & \\
6 & & & \\
\(\sum\) & & & \\
\end{longtable}

Fill out the table yourself, then try with R.

\hypertarget{measure-of-spread-2-the-iqr}{%
\subsection{Measure of Spread 2: The
IQR}\label{measure-of-spread-2-the-iqr}}

The IQR is very closely related to the median. But first, we must learn
what quartiles are.

Consider the data:

\begin{verbatim}
1 2 3 4 5 6 7 8
\end{verbatim}

The median of these data is 5; 50\% of the data are to the left of this
point. This is half the data. If, instead, we wanted a \emph{quarter} of
the data, we could find half of the half.

\begin{itemize}
\tightlist
\item
  ``Quartile'': Split the data into four.{[}\textbf{Quartile}: One
  quarter of the data. The first quartile is the first 25\%. The second
  quartile is the median.{]}

  \begin{itemize}
  \tightlist
  \item
    Q1: 25\% of the data are to the left.
  \item
    Q2: 50\% of the data are to the left (the median).
  \item
    Q3: 75\% of the data are to the left.
  \end{itemize}
\end{itemize}

\hypertarget{finding-quartiles}{%
\subsection{Finding Quartiles}\label{finding-quartiles}}

\begin{verbatim}
1 2 3 4 5 6 7 8
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find the median

  \begin{itemize}
  \tightlist
  \item
    It's 4.5. Cool.
  \end{itemize}
\item
  Q1 is just half of 50\% - we're finding a median again!

  \begin{itemize}
  \tightlist
  \item
    Q1 is the median of everything to the left of the median (don't
    include the median when doing this calculation).
  \item
    In this case, 1 2 3 4 are the numbers to the left of the median, and
    so Q1 is 2.5.
  \end{itemize}
\item
  By a similar argument, Q3 is 6.5. :::notes Q0 is where 0\% of the data
  are to the left. In other words, it's the minimum value in the data!
  Similarly, Q4 is the maximum value in the data.
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Warning}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

The algorithm we just used for computing the quartiles is not the only
one! In R, there are \emph{NINE} different ways to calculate the
quartiles. You should stick to doing this by hand if you want to get the
WeBWork answers right.

\end{tcolorbox}

\hypertarget{the-five-number-summary}{%
\subsection{The five number summary}\label{the-five-number-summary}}

Let's use the folowing example:

\begin{verbatim}
1, 3, 3, 4, 5, 5, 5, 6, 7, 7, 8, 8, 9, 10, 10, 11, 12
\end{verbatim}

The quartiles give an excellent way to summarise data:

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Q0 (min) & Q1 & Q2 (median) & Q3 & Q4 (max) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 4.5 & 7 & 8.5 & 12 \\
\end{longtable}

The five number summary just shows all five of the quartiles. Note that
there are five quartiles, because zero is also one of them.

For practice, make sure you can calculate the median, and then the
median of all the values to the left of it!

\hypertarget{visualizing-the-five-number-summary-the-boxplot}{%
\subsection{Visualizing the five number summary: the
boxplot}\label{visualizing-the-five-number-summary-the-boxplot}}

\vspace{1cm}

The plot on the right shows the body masses for the Palmer Penguins.

\begin{itemize}
\tightlist
\item
  The lowest point is Q0
\item
  The left of the box is Q1
\item
  The thick line in the box is Q2 (the median)
\item
  The right of the box is Q3
\item
  The highest point is Q4
\end{itemize}

\includegraphics{L02-Describing_Distributions_Numbers_files/figure-pdf/unnamed-chunk-5-1.pdf}

\includegraphics{L02-Describing_Distributions_Numbers_files/figure-pdf/unnamed-chunk-6-1.pdf}

The boxplot and the histogram both demonstrate the right skew of the
data, but the boxplot is much more compact!

Take a moment to compare the two plots and make sure you can explain the
skewness. Remember that 25\% of the data are in each interval shown in
the box plot!

\hypertarget{measure-2-the-inter-quartile-range-iqr}{%
\subsection{Measure 2: The Inter-Quartile Range
(IQR)}\label{measure-2-the-inter-quartile-range-iqr}}

The \textbf{IQR} is defined as: Q3 -
Q1.{\marginnote{\begin{footnotesize}\textbf{IQR}: The distance between
the first quartile and the third quartile.\end{footnotesize}}}

\begin{itemize}
\tightlist
\item
  Same units as the original data
\item
  Robust to outliers (unlike the sd)!
\end{itemize}

This is the second measure of spread that we will learn. The IQR is
commonly used when we have highly skewed data or data with outliers. The
sd measures the average squared deviation from the mean, whereas the IQR
measures the middle 50\% of the data.

Notice how this is not centered on the median. Consider the following
data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_values }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\FunctionTok{length}\NormalTok{(my\_values) }\CommentTok{\# number of observations}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(my\_values)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L02-Describing_Distributions_Numbers_files/figure-pdf/unnamed-chunk-7-1.pdf}

}

\end{figure}

The median of these should be at position
\((n+1)/2 = (20 + 1)/2 = 10.5\) (I used the \texttt{length()} function
in R to count the number of observations for me). This value is halfway
between 3 and 3, meaning it's 3. Q1 is the median of the first 10 data
points (we don't include the median, but this doesn't matter here),
which is at position 5.5, giving us a value of 2. Q3 is 5.5 positions
from the end, which is 4.5. Thus the IQR is \(4.5 - 2 = 2.5\).

First, does this make sense to you? Does 2.5 sound like a reasonable
width for the middle 50\%?

Now consider that the distribution is clearly skewed to the right. This
affects the variance a lot, but the IQR would have been the same no
matter what the first 4 or last 4 values were.

\hypertarget{iqr-for-outliers}{%
\subsection{IQR for Outliers}\label{iqr-for-outliers}}

In this class, we use a rule of thumb for calculating outliers. Anything
that is\ldots{}

\begin{itemize}
\tightlist
\item
  Below Q1 minus 1.5*IQR, or
\item
  above Q3 plus 1.5*IQR
\end{itemize}

is considered an outlier.

This rule of thumb is not based on any mathematical derivations, it just
seems to work in most situations.

The idea is that the IQR gives a measure of spread, and the median gives
the measure of the centre, so anything too far from the centre is an
outlier. We use the spread to figure out how far away from the centre we
are willing to accept. This will show up several times in this course.
We've seen it in this example for the IQR and median because this is
simple and easy to interpret.

Most of the rest of this course will be spent looking at something
similar for the mean. We will still use this idea of the centre plus or
minus some measure of the spread, but will incorporate information about
the sample and assumptions about the population that allow us to make
much stronger conclusions beyond simply checking if something is an
outlier.

\hypertarget{summary-1}{%
\subsection{Summary}\label{summary-1}}

\begin{itemize}
\tightlist
\item
  The ``centre'' is trying to measure the most common value.

  \begin{itemize}
  \tightlist
  \item
    Often, this is our best \textbf{prediction}.
  \end{itemize}
\item
  The ``spread'' is trying to measure the scale, or variation.

  \begin{itemize}
  \tightlist
  \item
    Gives context to the centre.
  \end{itemize}
\item
  The mean and variance

  \begin{itemize}
  \tightlist
  \item
    Interpretations and formulas are important.
  \end{itemize}
\item
  The median and IQR

  \begin{itemize}
  \tightlist
  \item
    Calculations, interpretations, five-number-summary, outliers, and
    boxplots are all important.
  \end{itemize}
\end{itemize}

We saw the same thing a couple of times throughout this lesson. We saw
measures of centre that try to describe the middle of a distribution and
centres of spread that tell us how spread out the data are. The mean and
the sd are intrinsically linked, and the median and IQR are
intrinsically linked.

We also saw the rule-of-thumb to use IQR for finding outliers by using
the median plus-an-minus some number times the spread. You better
believe that this idea will show up again later in this course!

Boxplots are a visual representation of the five number summary. These
can be very small while still showing the shape of our data. However,
these only work for unimodal data - there isn't a good way to show a
bimodal distribution on a boxplot. Also, it is very easy to plot two
boxplots for two different data sets in order to compare the
distributions.

For assignments and exams, be ready to calculate any of these values and
compare the mean/median and sd/IQR. Also be ready to compare the five
number summary to a boxplot.

\textbf{Exercises}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Spider Silk.} Spider silk is the strongest known material,
  natural or man-made, on a weight basis. A study examined the
  mechanical properties of spider silk using 21 female golden orb
  weavers, Nephila clavipes. Here are data on silk yield stress, which
  represents the amount of force per unit area needed to reach permanent
  deformation of the silk strand. The data are expressed in megapascals
  (MPa):
\end{enumerate}

\begin{verbatim}
164.00 173.00 176.10 236.10 251.30 270.50 270.50
272.40 282.20 288.80 290.70 300.60 327.20 329.00
332.10 351.70 358.20 362.00 448.90 478.70 740.20
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Describe the shape, centre, and spread of the data using a histogram
  (code below).
\item
  Find the mean and median yield stress. Compare these two values.
  Referring to the histogram produced by the code below, what general
  fact does your comparison illustrate?
\item
  Re-run the code using different values of \texttt{breaks}. What do you
  see? (Note that this example uses base R rather than \texttt{ggplot2}
  because it has simpler code - \texttt{ggplot2} has more flexibility,
  but that flexibility isn't necessary here.)
\item
  Use the \texttt{boxplot()} function to create a boxplot (you do not
  need the \texttt{breaks=10} part of the code). Compare this to the
  histogram. Also comment on any points that stand out (when there are
  outliers, R shows \(Q1 - 1.5IQR\) rather than Q0).
\item
  Use the \(Q1 - 1.5IQR\) and \(Q3 + 1.5 IQR\) formulas by hand to find
  the outliers, and verify your calculations with the R plot.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{silk\_stress }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{164.00}\NormalTok{, }\FloatTok{173.00}\NormalTok{, }\FloatTok{176.10}\NormalTok{, }\FloatTok{236.10}\NormalTok{, }\FloatTok{251.30}\NormalTok{, }\FloatTok{270.50}\NormalTok{, }\FloatTok{270.50}\NormalTok{,}
    \FloatTok{272.40}\NormalTok{, }\FloatTok{282.20}\NormalTok{, }\FloatTok{288.80}\NormalTok{, }\FloatTok{290.70}\NormalTok{, }\FloatTok{300.60}\NormalTok{, }\FloatTok{327.20}\NormalTok{, }\FloatTok{329.00}\NormalTok{,}
    \FloatTok{332.10}\NormalTok{, }\FloatTok{351.70}\NormalTok{, }\FloatTok{358.20}\NormalTok{, }\FloatTok{362.00}\NormalTok{, }\FloatTok{448.90}\NormalTok{, }\FloatTok{478.70}\NormalTok{, }\FloatTok{740.20}\NormalTok{)}
\FunctionTok{hist}\NormalTok{(silk\_stress, }\AttributeTok{breaks =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L02-Describing_Distributions_Numbers_files/figure-pdf/unnamed-chunk-8-1.pdf}

}

\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \textbf{Deep-sea sediments.} Phytopigments are markers of the amount
  of organic matter that settles in sediments on the ocean floor.
  Phytopigment concentrations in deep-sea sediments collected worldwide
  showed a very strong right-skew. Of two summary statistics, 0.015 and
  0.009 gram per square meter of bottom surface, which one is the mean
  and which one is the median? Explain your reasoning.
\item
  \textbf{Glucose levels.} People with diabetes must monitor and control
  their blood glucose level. The goal is to maintain a ``fasting plasma
  glucose'' between approximately 90 and 130 milligrams per deciliter
  (mg/dl). The data tables below give the fasting plasma glucose levels
  for two groups of diabetics five months after they received either
  group instruction or individual instruction on glucose control.
\end{enumerate}

I provide the data as vectors in R, but you don't need R for this
question (it's good practice to do it both ways).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{group }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{78.00}\NormalTok{, }\FloatTok{95.00}\NormalTok{, }\FloatTok{96.00}\NormalTok{, }\FloatTok{103.00}\NormalTok{, }\FloatTok{112.00}\NormalTok{, }\FloatTok{134.00}\NormalTok{, }\FloatTok{141.00}\NormalTok{, }\FloatTok{145.00}\NormalTok{, }\FloatTok{147.00}\NormalTok{,}
    \FloatTok{148.00}\NormalTok{, }\FloatTok{153.00}\NormalTok{, }\FloatTok{158.00}\NormalTok{, }\FloatTok{172.00}\NormalTok{, }\FloatTok{172.00}\NormalTok{, }\FloatTok{200.00}\NormalTok{, }\FloatTok{255.00}\NormalTok{, }\FloatTok{271.00}\NormalTok{, }\FloatTok{359.00}\NormalTok{)}

\NormalTok{individual }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{128.00}\NormalTok{, }\FloatTok{128.00}\NormalTok{, }\FloatTok{158.00}\NormalTok{, }\FloatTok{159.00}\NormalTok{, }\FloatTok{160.00}\NormalTok{, }\FloatTok{163.00}\NormalTok{, }\FloatTok{164.00}\NormalTok{, }\FloatTok{188.00}\NormalTok{, }\FloatTok{195.00}\NormalTok{,}
    \FloatTok{198.00}\NormalTok{, }\FloatTok{220.00}\NormalTok{, }\FloatTok{221.00}\NormalTok{, }\FloatTok{223.00}\NormalTok{, }\FloatTok{226.00}\NormalTok{, }\FloatTok{227.00}\NormalTok{, }\FloatTok{283.00}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Calculate the five-number summary for each of the two data sets.
\item
  Make side-by-side boxplots comparing the two groups. What can you say
  from this graph about the differences between the two diabetes control
  instruction methods? (\emph{Hint, you can create side-by-side boxplot
  using the code \texttt{boxplot(variable\_1,\ variable\_2)}}.)
\item
  Obtain the mean and standard deviation for each sample. Does this
  information give any clue about the shape of the two distributions?
\item
  Add to the historgrams a symbol representing the mean of each group
  and error bars representing one standard deviation above and below the
  mean. (You can do this by hand.) Compare this graphical summary with
  the boxplot display you also created.
\item
  Use the 1.5  IQR rule to identify any suspected outliers. Then look
  at the raw data to determine if unusually high or low values in either
  data set actually are outliers.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{The Ecological Fallacy}. In the data below there are 40 data
  points, but the data are included in different groups. Consider the
  following possibilities:

  \begin{itemize}
  \tightlist
  \item
    Find the sd of all of the data.
  \item
    Find the mean of each group, then find the sd of the means. Before
    working on this question, what do you expect? Will the sd of the
    data be larger than, smaller than, or the same as the sd of the
    means?
  \end{itemize}
\end{enumerate}

Once you're very certain that you know the answer (you don't learn
anything unless you put effort into, so do the hard thing), uncomment
the commented code (i.e., remove the \texttt{\#} at the start of the
last two lines) and see if you were right!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\NormalTok{g2 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{g3 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\NormalTok{g4 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{)}
\NormalTok{g5 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{12}\NormalTok{)}
\NormalTok{g6 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{g7 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{all\_g }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(g1, g2, g3, g4, g5, g6, g7)}
\NormalTok{all\_means }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{mean}\NormalTok{(g1), }\FunctionTok{mean}\NormalTok{(g2), }\FunctionTok{mean}\NormalTok{(}\DecValTok{3}\NormalTok{), }\FunctionTok{mean}\NormalTok{(}\DecValTok{4}\NormalTok{), }\FunctionTok{mean}\NormalTok{(}\DecValTok{5}\NormalTok{), }\FunctionTok{mean}\NormalTok{(}\DecValTok{6}\NormalTok{), }\FunctionTok{mean}\NormalTok{(}\DecValTok{7}\NormalTok{))}
\CommentTok{\# sd(all\_g)}
\CommentTok{\# sd(all\_means)}
\end{Highlighting}
\end{Shaded}

\textbf{Solution}

The \textbf{Ecological Fallacy} is that the data looks less variable if
we only look at the average values in different groups.

For example, Statistics Canada releases information of the average
household income for people who are 16-24 years old, 25-34, etc. The
variance of these averages is \textbf{NOT} related to the actual
variance of the values. When we learn more about statistical tests, we
learn just how important the variance is - getting it wrong by not
acknowledging that we're working with means is a \textbf{HUGE} problem!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{categorical-variables}{%
\section{Categorical Variables}\label{categorical-variables}}

These variables are much harder to quantify with a single summary
statistic. Instead, we usually give a table of their counts or just draw
a plot. There is no concept of ``mean'' that applies to all categorical
variables, and there is especially no concept of ``variance''. The one
exception is the \textbf{mode} (the most commonly observed category),
but on it's own this gives us very little information about the
``centre'' or ``spread'' of the data.

Instead, we simply show as few numbers as we can while still displaying
enough information:

\hypertarget{frequency-tables}{%
\subsection{Frequency Tables}\label{frequency-tables}}

\hypertarget{one-way-table}{%
\subsubsection{One-Way Table}\label{one-way-table}}

\begin{verbatim}

female   male 
   165    168 
\end{verbatim}

\begin{verbatim}

   Adelie Chinstrap    Gentoo 
      152        68       124 
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The number of penguins in each category.
\item
  From what's given,m we can't tell how many Chinstrap penguins were
  female.
\end{itemize}

\hypertarget{two-way-table}{%
\subsubsection{Two-Way Table}\label{two-way-table}}

\begin{longtable}[]{@{}lrrr@{}}
\toprule\noalign{}
& Adelie & Chinstrap & Gentoo \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
female & 73 & 34 & 58 \\
male & 73 & 34 & 61 \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  The number of penguins in each \emph{combination} of categories.
\item
  We can find that there were 165 female penguins by adding the entries
  in the row labelled \texttt{female}.
\end{itemize}

\hypertarget{crowdsourced-questions-1}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-1}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Given this set of numbers: 23, 19, 27, 36, 21, 29, 38, 39, 42, 25,
  determine the Q0, Q1, Q2, Q3, and Q4. Measure the spread by
  determining the IQR of this set of numbers.
\end{enumerate}

\textbf{Solution}

First we will re-order the numbers from smallest value to largest value.
19, 21, 23, 25, 27, 29, 36, 38, 39, 42.

\begin{itemize}
\tightlist
\item
  Q0 is the lowest value so that will be 19.
\item
  Q4 is the highest value in the set so that will be 42.
\item
  Q2 is the median. Since the number of values (n) is even, the median
  will be between the middle two numbers, 27 and 29. Making Q2 = 28.
\item
  Q1 is the median between the values between Q0 and Q2 (19, 21, 23, 25,
  27). The median in this set is 23, making Q1 = 23.
\item
  Q3 is the median of the second half of the data set, between Q2 and Q4
  (29, 36, 38, 39, 42). The median in this set is 38, making Q3 = 38.
\end{itemize}

Next to determine the IQR, we subtract Q1 from Q3.

IQR = Q3-Q1 = 38 - 23 = 15

Therefore, the Interquartile range for this set of data is 15.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scatterplots-and-correlation}{%
\chapter{Scatterplots and
Correlation}\label{scatterplots-and-correlation}}

\hypertarget{relationships}{%
\section{Relationships}\label{relationships}}

\hypertarget{explanatory-and-response-variables}{%
\subsection{Explanatory and Response
Variables}\label{explanatory-and-response-variables}}

\begin{itemize}
\tightlist
\item
  \textbf{Response:} Responds to the explanatory variable.

  \begin{itemize}
  \tightlist
  \item
    Also called \textbf{dependent} variable.
  \end{itemize}
\item
  \textbf{Explanatory:} Explains the response variable.

  \begin{itemize}
  \tightlist
  \item
    Also called \textbf{independent} variable.
  \end{itemize}
\end{itemize}

Knowledge about explanatory tells us about the response.

\begin{itemize}
\tightlist
\item
  We are \emph{not} assuming the explanatory causes the response. We
  will \emph{not} be covering causality in this course.
\item
  We are discovering tendencies, \emph{not} rules.
\end{itemize}

I just want to make this very clear: we are not looking for a causation.
Instead, we're just looking at whether or not to variables are related,
and we think that measurements of one will be enough to tell us about
measurements of the other. For example, if we think one variable is easy
to measure and another is harder to measure, then we might want to set
the easy to measure variable as the explanatory variable and see if it
``explains'' the harder to measure variable. This has nothing to do with
the easy to measure variable causing the hard to measure one.

\hypertarget{examples}{%
\subsection{Examples}\label{examples}}

\begin{itemize}
\tightlist
\item
  Blood alcohol content affects reflex time. -- Some individuals may be
  more or less affected.
\item
  Smoking cigarettes is associated with increased risk of lung cancer,
  and mortality. -- Some heavy smokers may live to age 90
\item
  As height increases, weight tends to increase.

  \begin{itemize}
  \tightlist
  \item
    Height does cause weight, but there are other explanations.
  \end{itemize}
\end{itemize}

In these examples, we carefully use words like ``affects'', ``associated
with'', and ``tends to''. For all of these examples we would expect a
relationship of some sort, but the causality is not necessarily obvious.

We obviously expect the blood alcohol contact to affect reflex time. We
expect this to be a causal relationship.

In the mid-1900s, it was hypothesized by cigarette companies that,
rather than cigarettes causing cancer, people who were at increased risk
of lung cancer with the sorts of people who also tended to smoke.
Finding a relationship was not enough to convince people that it was
cigarettes causing lung cancer. Even though we know that there's a
relationship between cigarettes and lung cancer, the techniques we learn
in this course are not enough to conclude causality.

Height and weight are an example of how are the knowledge of one
variable tells us about the other, without there being any causal
relationship. We expect that taller people will have more mass, but
there are also other reasons why somebody might have more mass that or
not captured by their height.

\hypertarget{scatterplots}{%
\section{Scatterplots}\label{scatterplots}}

\hypertarget{example}{%
\subsection{Example}\label{example}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1163}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0814}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1744}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1628}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.2093}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1395}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0581}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0581}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
species
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
island
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
bill\_length\_mm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
bill\_depth\_mm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
flipper\_length\_mm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
body\_mass\_g
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
sex
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
year
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Chinstrap & Dream & 50.0 & 19.5 & 196 & 3900 & male & 2007 \\
Chinstrap & Dream & 51.3 & 19.2 & 193 & 3650 & male & 2007 \\
Chinstrap & Dream & 52.7 & 19.8 & 197 & 3725 & male & 2007 \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  One penguin has a flipper length of 193.

  \begin{itemize}
  \tightlist
  \item
    That \emph{same penguin} has a body mass of 3650.
  \item
    Both measurements were made on the \textbf{same individual}.

    \begin{itemize}
    \tightlist
    \item
      Individual: thing we are making measurements on.\lspace
    \end{itemize}
  \end{itemize}
\item
  Each value on the x-axis is paired with a value on the y-axis.
\end{itemize}

\includegraphics{L03-Scatterplots_Correlation_files/figure-pdf/unnamed-chunk-3-1.pdf}

In the plot above, each individual has multiple measurements recorded on
them. Because of this, we can plot each pair as a point in the plot.
Note that we need to know which x-value is associated with each y-value
in order to make the plot!

\hypertarget{what-to-look-for}{%
\subsection{What to look for}\label{what-to-look-for}}

\begin{itemize}
\tightlist
\item
  \textbf{Overall pattern}

  \begin{itemize}
  \tightlist
  \item
    Linear, curved, etc.
  \item
    \textbf{Direction} (increasing/\textbf{positive},
    decreasing/\textbf{negative})
  \item
    Constant variability
  \end{itemize}
\item
  \textbf{Deviations} from the pattern

  \begin{itemize}
  \tightlist
  \item
    E.g., linear only in a small range
  \end{itemize}
\item
  \textbf{Outliers}

  \begin{itemize}
  \tightlist
  \item
    As before, discuss outliers separately from the pattern.
  \end{itemize}
\end{itemize}

In general for this course were looking for a linear pattern. There are
other models out there that fit nonlinear patterns, but we do not cover
them in this course. There's one way for things to be linear, and there
are an infinite number of ways for things to be nonlinear. However,
there are many common ways to account for non-linearity while still
using a linear model.

Regardless of whether something is linear or has some sort of curve, we
are very interested in how strong of a pattern there is. For a linear
model this means we want the points to be very close to the line,
whereas for non-linear models we want the pattern to be very clear. We
generally want patterns to pass the ``facial impact test'', were the
pattern is so obvious that it might as well be slapping you in the face
(this is not an official test).

As with describing the shape of histograms, we treat outliers as
something that are not part of the shape. We can have a clear linear
pattern that happens to have an outlier.

\hypertarget{penguins}{%
\subsection{Penguins!}\label{penguins}}

\vspace{1cm}

What pattern is this?

\includegraphics{L03-Scatterplots_Correlation_files/figure-pdf/unnamed-chunk-4-1.pdf}

The plot above shows a clear linear pattern. There is still some
variation above and below the lines, but the pattern is still clear. It
kinda looks like there may be two clusters; there's a space between the
two groups in the center of the X axis.

\hypertarget{adding-a-categorical-variable}{%
\subsection{Adding a Categorical
Variable}\label{adding-a-categorical-variable}}

\vspace{1cm}

Each point has an \(x\) coordinate, \(y\) coordinate, and some other
information. We can encode that information with a colour! Again, we
have to have a \emph{categorical} variable measured on the same
individual as the x and y values.

\includegraphics{L03-Scatterplots_Correlation_files/figure-pdf/unnamed-chunk-5-1.pdf}

From this plot, we can see that the three species in these data all have
a similar relationship, but still it might be worth separating out the
groups and seeing what happens!

Bonus question: the first plot of body mass versus flipper length only
showed one species. Can you tell which species?

\hypertarget{the-importance-of-plotting-anscombes-quartet}{%
\subsection{The Importance of Plotting: Anscombe's
Quartet}\label{the-importance-of-plotting-anscombes-quartet}}

\begin{longtable}[]{@{}lrr@{}}
\toprule\noalign{}
variable & mean & sd \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
x1 & 9.000000 & 3.316625 \\
x2 & 9.000000 & 3.316625 \\
x3 & 9.000000 & 3.316625 \\
x4 & 9.000000 & 3.316625 \\
y1 & 7.500909 & 2.031568 \\
y2 & 7.500909 & 2.031657 \\
y3 & 7.500000 & 2.030424 \\
y4 & 7.500909 & 2.030578 \\
\end{longtable}

In this course we're introducing plots before we talk about numerical
summaries of two variables for a very good reason. The table above shows
summary statistics from a well-known data set called Anscombes quartet.
Up to the first two decimal places, all of the variables in the data
have the same mean and standard deviation. If this were all of the
information you had, you might expect the plots of y1 versus x1, y2
versus x2, y3 versus x3, and y4 versus x4 to look similar.

Instead, they look like this:

\includegraphics{L03-Scatterplots_Correlation_files/figure-pdf/unnamed-chunk-7-1.pdf}

Clearly, there's a very different pattern in each plot.

\begin{itemize}
\tightlist
\item
  The first plot looks relatively linear with a little bit of random
  variation. For this data set a linear model does seem appropriate.
\item
  The plot at the top right she was a very clear pattern that is not
  linear, so we may be able to fit a model that accounts for this
  non-linearity.
\item
  The plot at the bottom left is almost a perfect line, but with an
  outlier. This outlier makes it so that the line that I have added to
  the plot doesn't actually go through the perfect pattern that we can
  see if that outlier weren't there.
\item
  The bottom right plot is a mess. If it weren't for the outlier, the X
  values would all be identical! In this case, a scatterplot would not
  be appropriate. If I saw this while analysing my data, I would have
  assumed that X was supposed to be either constant (e.g., all X values
  should have been 8) or categorical. In both cases, a scatterplot would
  not be appropriate.
\end{itemize}

Despite all of these wildly different shapes, all of these data sets
have the same summary statistics.

Plot. Your. Data.

\hypertarget{summarizing-plots}{%
\subsection{Summarizing Plots}\label{summarizing-plots}}

\begin{itemize}
\tightlist
\item
  Each data point has an \(x\) and a \(y\). We plot \(y\) against \(x\).

  \begin{itemize}
  \tightlist
  \item
    \(y\) is the response, \(x\) is the explanatory variable.
  \end{itemize}
\item
  We're looking to see if it's linear. Linear models are something we
  know how to deal with!

  \begin{itemize}
  \tightlist
  \item
    Deviations from linearity are noteworthy.
  \item
    Outliers are noteworthy.
  \end{itemize}
\item
  We can incorporate more information in a scatterplot, especially
  \textbf{categorical variables}.
\end{itemize}

\hypertarget{summary-statistics-for-two-continuous-variables}{%
\section{Summary Statistics for Two Continuous
Variables}\label{summary-statistics-for-two-continuous-variables}}

\hypertarget{measuring-strength-of-linearity}{%
\subsection{Measuring Strength of
Linearity}\label{measuring-strength-of-linearity}}

\vspace{1cm}

From plots, we can sorta see that one looks more linear than another.

It would be splendid if we could have a way to quantify this\ldots{}

\includegraphics{L03-Scatterplots_Correlation_files/figure-pdf/unnamed-chunk-8-1.pdf}

From this point on, we're focusing on linear relationships. The plots
above both demonstrate the same linear relationship, but with different
``strength''s. Let's measure that!

\hypertarget{the-correlation-coefficient-r}{%
\subsection{\texorpdfstring{The correlation coefficient
\(r\)}{The correlation coefficient r}}\label{the-correlation-coefficient-r}}

Recall the formula for the variance: \[
s_x^2 = \frac{1}{n-1}\sum_{i=1}^n(x_i - \bar x)^2 = \frac{1}{n-1}\sum_{i=1}^n(x_i - \bar x)(x_i - \bar x) 
\]

The \textbf{correlation coefficient} is defined as: \[
r = \frac{1}{n-1}\sum_{i=1}^n\left(\frac{x_i - \bar x}{s_x}\right)\left(\frac{y_i - \bar y}{s_y}\right)
\] where \(s_x\) is the s.d. of \(x\) and \(s_y\) is the s.d. of \(y\).

It's like a variance for two variables at once!

This explanation might not stick for those of you who aren't a fan of
formulas, but I think this demonstrates an important aspect of the
correlation coefficient. The formula for the standard deviation includes
\((x_i - \bar x)(x_i - \bar x)\). If we replaced one of those with
\(y\), we'd get \((x_i - \bar x)(y_i - \bar y)\), which is one step
closer to the correlation coefficient. In other words, the correlation
is a measure of how two (quantitative) variables vary together!
Correlation is an extension of variance!

Let's try another approach. \(x\) has variance. \(y\) has variance. They
also have variance \emph{with each other}. This is measured by the
correlation!

If neither of these explanations make sense, don't worry! We'll see
plenty of correlations and get an intuition for how correlations are
different with different data.

\hypertarget{the-range-of-r}{%
\subsection{\texorpdfstring{The range of
\(r\)}{The range of r}}\label{the-range-of-r}}

\[
r = \frac{1}{n-1}\sum_{i=1}^n\left(\frac{x_i - \bar x}{s_x}\right)\left(\frac{y_i - \bar y}{s_y}\right)
\]

\begin{itemize}
\tightlist
\item
  \(s_x\) and \(s_y\) are positive
\item
  \(s_x > \sum_{i=1}^n(x_i - \bar x)\), similar for \(s_y\)

  \begin{itemize}
  \tightlist
  \item
    The correlation coefficient cannot be larger than 1
  \end{itemize}
\item
  \(x_i - \bar x\) \emph{can} be negative (same with \((y_i-\bar y)\)).
\end{itemize}

Together, this means that the correlation coefficient can be anything
from -1 to 1, with 0 representing no correlation and -1 and 1
representing perfect correlation.

The fact that the correlation can be negative is important. A
correlation coefficient of -1 looks like a perfect downward slope. It's
still a strong relationship. In other words, the relationship is
stronger if \(r\) is \emph{further away from 0}\footnote{It is
  \emph{not} true that a ``larger'' \(r\) means stronger relationship!}.

\hypertarget{interpreting-correlation}{%
\subsection{Interpreting correlation}\label{interpreting-correlation}}

\begin{itemize}
\tightlist
\item
  1 and -1 are \textbf{perfect} correlation.
\item
  0.8 is a strong correlation (depending on context)

  \begin{itemize}
  \tightlist
  \item
    Physics: 0.8 is very very weak.
  \item
    Social science: 0.8 is very very strong.
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DB7{-}CourseNotes/TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Apps/ScatterCorr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The app above shows data that start uncorrelated, then are slowly
transformed into perfect correlation. If you have R installed on your
computer it should run just fine (you may need to run
\texttt{install.packages("shiny")} for the shiny package, and possibly
\texttt{install.packages("ggplot2")} if you haven't already).

For more examples (and more info on the correlation coefficient in
general), see the
\href{https://www.openintro.org/book/biostat/}{OpenIntro Textbook}!

\hypertarget{comments-on-the-correlation}{%
\subsection{Comments on the
correlation}\label{comments-on-the-correlation}}

\[
r = \frac{1}{n-1}\sum_{i=1}^n\left(\frac{x_i - \bar x}{s_x}\right)\left(\frac{y_i - \bar y}{s_y}\right)
\]

\begin{itemize}
\tightlist
\item
  The order of \(x\) and \(y\) can be switched

  \begin{itemize}
  \tightlist
  \item
    2 times 3 is the same as 3 times 2.
  \end{itemize}
\item
  Since we're subtracting the mean and dividing by the s.d., the units
  don't matter!

  \begin{itemize}
  \tightlist
  \item
    Switching from kg to lbs has no effect on the correlation.
  \end{itemize}
\item
  \(r>0\) means the line goes up. \(r < 0\) means the line goes down.
\item
  Quantitative only
\item
  Linear only
\item
  \emph{Not} robust to outliers.
\end{itemize}

Let's explore some of these ideas with code!

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(y1 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{data =}\NormalTok{ anscombe)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L03-Scatterplots_Correlation_files/figure-pdf/unnamed-chunk-10-1.pdf}

}

\end{figure}

It looks relatively linear. Take a moment to think of how correlated
these two variables are, and assign it a value between 0 and 1. This is
how you would guess the correlation coefficient

On exams, you will be expected to differentiate between ``not
correlated'' (about 0), ``slightly correlated'' (0.2 to 0.4), ``very
correlated'' (0.6 to 0.8), and ``near perfect correlation (almost
exactly 1)'', or the negatives of these values; you won't need to guess
whether the correlation is 0.55 or 0.6.

In R, we calculate the \(r\) with the \texttt{cor()} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(anscombe}\SpecialCharTok{$}\NormalTok{y1, anscombe}\SpecialCharTok{$}\NormalTok{x1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.8164205
\end{verbatim}

Does this number make sense to you? It seems fairly high to me, but with
small amounts of data it's not that surprising. Think of it this way: if
you removed a quarter of the data at random, would you still be able to
see the pattern? If so, then it's probably ``very correlated''!

The first point states that the order doesn't matter:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(anscombe}\SpecialCharTok{$}\NormalTok{y1, anscombe}\SpecialCharTok{$}\NormalTok{x1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.8164205
\end{verbatim}

The units don't matter:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(anscombe}\SpecialCharTok{$}\NormalTok{y1}\SpecialCharTok{*}\DecValTok{5} \SpecialCharTok{+} \DecValTok{1}\NormalTok{, anscombe}\SpecialCharTok{$}\NormalTok{x1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.8164205
\end{verbatim}

However, it \emph{does} matter if we do a \emph{non-linear}
transformation, such as squaring the values. The correlation is a
measure of \textbf{linear} association, so making things non-linear will
affect it.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(y1}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{data =}\NormalTok{ anscombe)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L03-Scatterplots_Correlation_files/figure-pdf/unnamed-chunk-14-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(anscombe}\SpecialCharTok{$}\NormalTok{x1, anscombe}\SpecialCharTok{$}\NormalTok{y1}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7992029
\end{verbatim}

For these data, squaring didn't have much of an effect (as we can see in
the plot), but we still saw a change in \(r\)! Notice that a unit change
had absolutely no effect on \(r\). In general, we either expect things
to be exactly the same or they can be completely different; very few
things are ``almost equal'' in the general case (they may be almost
equal with one set of data, but that means nothing for completely
different sets of data).

\hypertarget{r-measures-linear-correlation}{%
\subsection{\texorpdfstring{\(r\) measures \emph{linear}
correlation}{r measures linear correlation}}\label{r-measures-linear-correlation}}

Enzymatic activity is known to be affected by temperature. A study
examined the activity rate (in micromoles per second, mol/s) of the
digestive enzyme acid phosphatase in vitro at varying temperatures
(measured in kelvins, K). The findings are displayed in the following
table.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Describe the relationship
\item
  Explain why it doesn't make sense to describe this as ``positively
  associated'' or ``negatively associated''.
\item
  Is this a strong or a weak relationship? Explain.
\end{enumerate}

\includegraphics{figs/non-linear.png}

\textbf{Solution}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  The relationship increases with an upward curve from temperatures of
  300K to 340K, when it turns downward sharply and decreases to 355K.
\item
  The association is different for different X values. This is
  \emph{not} a linear relationship, which means we have to do extra work
  to make sure that we cover all the non-linearities.
\item
  This is a very strong relationship. The pattern clearly passes the
  facial impact test that we discussed before. It is far from a linear
  relationship, but it's clearly noticable.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{again-always-plot-your-data}{%
\subsection{Again, always plot your
data!!!}\label{again-always-plot-your-data}}

\vspace{1cm}

All of the plots in the Anscombe quartet \emph{have the same correlation
coefficient}.

\(r\) is a measure of linear association - if it's not linear, \(r\)
can't be interpreted!!!

\includegraphics{L03-Scatterplots_Correlation_files/figure-pdf/unnamed-chunk-15-1.pdf}

It's important to note that \(r\) can always be calculated for numeric
data. If we had student numbers as well as a categorical variable that
used 0 to represent black, 1 to represent asian, etc., then we could
technically calculate the correlation coefficient. This would be utterly
meaningless!!!!!

\hypertarget{example-penguins}{%
\subsection{Example: Penguins}\label{example-penguins}}

\includegraphics{L03-Scatterplots_Correlation_files/figure-pdf/unnamed-chunk-16-1.pdf}

This is an example of something called \textbf{Simpson's Paradox}: If we
don't account for the sub-groups, we get the opposite affect! As we can
see in the plot, if we have all the groups together than it looks like a
negative correlation (plot on the left), but once we separate groups
each individual group has a positive correlation (plots on the right).
In general, the conclusion that incorporates the most information is
probably closest to the truth.

\hypertarget{correlation-summary}{%
\subsection{Correlation Summary}\label{correlation-summary}}

\begin{itemize}
\tightlist
\item
  \(r\) is a measure of \textbf{linear} association

  \begin{itemize}
  \tightlist
  \item
    I've said it plenty, I'll say it again: \(r\) does not apply to
    non-linear patterns!
  \item
    Always plot your data before calculating \(r\).
  \end{itemize}
\item
  \(r\) is like a measure of how two variables vary together.

  \begin{itemize}
  \tightlist
  \item
    Formula is similar to the variance formula!
  \end{itemize}
\item
  \(r\) is a number between -1 and 1, with 0 meaning no correlation and
  1 or -1 meaning perfect correlation.

  \begin{itemize}
  \tightlist
  \item
    A negative \(r\) means a negative relationship (i.e.~a line that
    goes down).
  \end{itemize}
\item
  Everything on the ``Comments'' slide is fair game for test questions.
\end{itemize}

\textbf{Exercises:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The following code will draw a plot and calculate the correlation
  coefficient. Currently, it's doing this for the column \texttt{mpg}
  (response) versus the column \texttt{wt} (``weight'', explanatory) in
  the \texttt{mtcars} data which is built in to R.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Re-run the code, but replace \texttt{wt} with \texttt{disp} (engine
    displacement), \texttt{hp} (horsepower), \texttt{drat} (rear axle
    ratio, although I couldn't explain this further), and \texttt{qsec}
    (quarter mile time, in seconds). Comment on the apparent pattern and
    the magnitude of the correlation.
  \item
    Change \texttt{wt} to\texttt{cyl}, the number of cylinders. What do
    you notice about the plot, and how does this affect your
    interpretation of the correlation between \texttt{mpg} and
    \texttt{cyl}? Explain why \texttt{cyl} might be better incorporated
    as a categorical variable, even though it is indeed numeric.
  \item
    Repeat part (b) for \texttt{am}, which is ``0'' for automatic
    transmission and ``1'' for manual transmission.
  \end{enumerate}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(mpg }\SpecialCharTok{\textasciitilde{}}\NormalTok{ wt, }\AttributeTok{data =}\NormalTok{ mtcars)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L03-Scatterplots_Correlation_files/figure-pdf/unnamed-chunk-17-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{mpg, mtcars}\SpecialCharTok{$}\NormalTok{wt)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.8676594
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The following figure comes from the article ``Shared neural
  representations and temporal segmentation of political content predict
  ideological similarity'' by De Brujin et al., published in 2023
  (\href{https://www.science.org/doi/10.1126/sciadv.abq5920}{link to
  aricle here}). The star on the plot indicates that they have found a
  statistically significant relationship (more on this next week). Is
  this a strong correlation?
\end{enumerate}

\includegraphics{figs/scatterbad.png}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  The following figure comes from the article ``Effect on Blood Pressure
  of Daily Lemon Ingestion and Walking'' by Kato et al., published in
  2013 (\href{https://www.hindawi.com/journals/jnme/2014/912684/}{link
  to article here}). Comment on the shape of this relationship. Recall
  how we described a ``strong'' shape as a shape that remains even if
  some of the data points were removed.
\end{enumerate}

\includegraphics{figs/lemon.png}

\textbf{Exercises from OpenIntro Biotatistics textbook}

Questions 1.35, 1.36, 1.37.

For further R practice and case studies, see the
\href{https://www.openintro.org/book/statlabs/?labblock=biostat_intro_to_data}{labs
page for the OpenIntro textbook}.

\hypertarget{crowdsourced-questions-2}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-2}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Consider a study investigating the relationship between the amount of
  time students spend studying for an exam (in hours) and their
  resulting exam scores (percentage). The study gathers data from 100
  students, measures the two variables for each student, and plots these
  data points on a scatterplot. Which of the following statements best
  aligns with the principles of interpreting scatterplots and
  understanding relationships between variables as discussed in the
  course notes?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    If the scatterplot shows a clear upward trend, it proves that
    spending more time studying causes students to achieve higher exam
    scores.
  \item
    The study identifies the amount of time spent studying as the
    response variable and the exam score as the explanatory variable,
    predicting that higher exam scores explain why students spend more
    time studying.
  \item
    The scatterplot can help visualize the relationship between the two
    variables, but further analysis is required to determine if one
    variable causes changes in the other.
  \item
    A linear pattern in the scatterplot indicates that every additional
    hour of study leads to a uniform increase in exam scores for all
    students.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

C is the correct answer. This option correctly acknowledges that while
scatterplots are instrumental in visualizing the relationship between
two variables (the amount of time spent studying and exam scores in this
case), they alone cannot confirm causality. This aligns with the
course's emphasis on the distinction between correlation and causation
and the role of scatterplots in identifying patterns rather than proving
causation. Options A, B, and D either incorrectly assume causation from
correlation, misidentify explanatory and response variables, or
oversimplify the interpretation of a linear pattern, respectively.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  In an agricultural study, researchers are investigating the impact of
  different amounts of fertilizer (in kilograms) applied to tomato
  plants on the yield of tomatoes (in kilograms). Which of the following
  correctly identifies the explanatory and response variables?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Explanatory variable: Yield of tomatoes; Response variable: Amount
    of fertilizer
  \item
    Explanatory variable: Amount of fertilizer; Response variable: Yield
    of tomatoes
  \item
    Both the amount of fertilizer and the yield of tomatoes are
    explanatory variables since they influence each other.
  \item
    Both the amount of fertilizer and the yield of tomatoes are response
    variables due to external factors like sunlight and water.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

B is the correct answer. The amount of fertilizer is the explanatory
variable because it is the variable being manipulated or controlled by
the researchers to observe its effect on the yield of tomatoes, which is
the response variable.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  A study plots the average daily temperature against the total daily
  sales of ice cream over a summer in a coastal city. The scatterplot
  shows a clear upward trend. What does this trend indicate about the
  relationship between these two variables?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    As the average daily temperature increases, the total daily sales of
    ice cream decrease.
  \item
    There is no relationship between the average daily temperature and
    the total daily sales of ice cream.
  \item
    As the average daily temperature increases, the total daily sales of
    ice cream also increase.
  \item
    The increase in average daily temperature causes an increase in the
    total daily sales of ice cream.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

C is the correct answer. The upward trend in the scatterplot indicates
that there is a positive relationship between the average daily
temperature and the total daily sales of ice cream---meaning, as one
increases, so does the other. However, it is important to note that this
does not imply causation (which option D incorrectly suggests).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  In a study examining the relationship between hours spent on physical
  activity per week and overall quality of sleep, a correlation
  coefficient of -0.3 is found. Which of the following statements best
  interprets this finding?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    There is a strong negative relationship between hours spent on
    physical activity and quality of sleep.
  \item
    There is a weak negative relationship between hours spent on
    physical activity and quality of sleep, suggesting that as physical
    activity increases, quality of sleep slightly decreases.
  \item
    There is a weak positive relationship between hours spent on
    physical activity and quality of sleep.
  \item
    The correlation coefficient indicates that increased physical
    activity causes poorer quality of sleep.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

B is the correct answer. A correlation coefficient of -0.3 indicates a
weak negative relationship between the two variables. This means that as
one variable increases (hours spent on physical activity), the other
variable (quality of sleep) slightly decreases. However, it's important
to remember that correlation does not imply causation, making option D
incorrect.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{regression}{%
\chapter{Regression}\label{regression}}

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

These notes are based on Chapter 6.1 to 6.3 in OpenIntro Biostats.

In linear modelling, we have a collection of pairs \(x_i\) and \(y_i\).
We think that there's some sort of relationship between \(x\) and \(y\),
and we think that a line is an adequate way to characterize that
relationship\footnote{Very few things are actually linear, but lines are
  fantastic approximations to many things.}.

Just like we assume that there's a ``true'' population mean, there is
also a ``true'' slope and intercept for the line that characterizes the
relationship between \(x\) and \(y\). In the plot below, the green line
represents the ``true'' relationship between \(x\) and \(y\), and the
data are random values above and below that line\footnote{We assume that
  \(x\) is fixed, but \(y\) has random noise. In other words, \(x\) is
  not a random variable but \(y\) is.}.

\includegraphics{L04-Regression_files/figure-pdf/unnamed-chunk-2-1.pdf}

In high school, you may have learned a line as \(y = mx + b\). In
statistics, we often use latin letters (a, b, c, d, \ldots) for
estimates and greek letters (\(\alpha\), \(\beta\), \(\gamma\), and
other lower case versions of letters you've seen on frat/sorority
houses) for population parameters\footnote{Because we think it makes us
  sound smarter.}. The population line is labelled:

\[
y_i = \alpha + \beta x_i + \epsilon_i
\]

\begin{itemize}
\tightlist
\item
  \(\alpha\) is the \textbf{intercept}.
\item
  \(\beta\) is the \textbf{slope}.

  \begin{itemize}
  \tightlist
  \item
    A 1 unit increase in \(x\) corresponds to a \(\beta\) increase in
    \(y\).
  \end{itemize}
\item
  \(\epsilon_i\) is random noise (\(N(0,\sigma)\), although you're not
  expected to understand this notation yet).

  \begin{itemize}
  \tightlist
  \item
    Again, we think of \(x\) as being fixed. The random noise is above
    and below the line, not side to side.
  \end{itemize}
\item
  The formula implies that \(y_i\) is centered at \(\alpha + \beta x_i\)
  but randomly varies above and below the line with variance
  \(\sigma^2\).
\end{itemize}

The word ``regression'' means to go backward. I like to think that we
are ``going backward'' to the population numbers from the sample
values\footnote{Actually, the word comes from ``regressing to the
  mean'', which comes from how children are closer to average height
  than their parents - they go back toward the mean. This is not
  important.}. Any situation where you are estimating a population
parameter is technically a \textbf{regression}, but this terminology is
not useful for this class.\footnote{I get very annoyed by the term
  ``Regression Analysis'' because there are practically infinite
  different types of regression. Linear regression is just one of them,
  albeit a a very very very popular one.}

To regress, we \textbf{estimate} the parameters using sample statistics.
\(a\) is the estimate for \(\alpha\), \(b\) for \(\beta\), and \(e\) for
\(\epsilon\). In order to do find these sample statistics, we minimize
the squared error between the line and the data:

\[e_i^2 = (y_i - a - b x_i)^2\]

In other words, we find \(a\) (for \(\alpha\)) and \(b\) (for \(\beta\))
that make the sum of the squared errors \(e_i\) as small as possible. We
use the squared errors for the same reason we use squared deviations in
the forumla for the variance: so that positive and negative values do
not cancel out\footnote{Also, because the calculus works out so much
  better.}.

The estimates \(a\) and \(b\) are as follows:

\begin{align*}
b &= rs_y/s_x\\
a &= \bar y - b\bar x
\end{align*}

These are called the \textbf{least squares} estimates\footnote{There are
  other ways to estimate these parameters, but they're outside the scope
  of this course. For example, we could use the absolute value instead
  of the squared value. This works just as well for the calculation, but
  there are a lot of mathematical reasons why the square is nice.
  Mainly, it has a nice derivative and allows for easy equation
  manipulation.}. The equation for \(b\) is especially important!

In R, these can be calculated as follows. The \texttt{mtcars} data set
is a collection of measurements made on various cars. In this example,
we'll regress the fuel efficiency (in miles per gallon, or mpg) against
the weight of the car.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Load a built{-}in data set}
\FunctionTok{data}\NormalTok{(mtcars) }

\DocumentationTok{\#\# Define which variables are x and y.}
\DocumentationTok{\#\# This isn\textquotesingle{}t necessary, but helps with teaching}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ mtcars}\SpecialCharTok{$}\NormalTok{wt}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ mtcars}\SpecialCharTok{$}\NormalTok{mpg}

\DocumentationTok{\#\# Calculate the estimates by hand}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x, y) }\SpecialCharTok{*} \FunctionTok{sd}\NormalTok{(y) }\SpecialCharTok{/} \FunctionTok{sd}\NormalTok{(x)}
\NormalTok{a }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(y) }\SpecialCharTok{{-}}\NormalTok{ b }\SpecialCharTok{*} \FunctionTok{mean}\NormalTok{(x)}

\DocumentationTok{\#\# Print the estimates }
\FunctionTok{c}\NormalTok{(a, b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 37.285126 -5.344472
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Use the built{-}in functions}
\FunctionTok{summary}\NormalTok{(}\FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = y ~ x)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***
x            -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10
\end{verbatim}

From this line, we can make \textbf{predictions} about new points by
simply plugging in the \(x\) value. For example, let's say we wanted to
guess the mpg of a car that weighs 3,000 lbs. In the data, the units for
weight are 1000 lbs, so this means plugging a value of \texttt{wt=3}
into the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{*} \DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 21.25171
\end{verbatim}

So we would guess that a 3 ton car would have a fuel efficiency of 21.25
miles per gallon. Let's look at this on a plot:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{points}\NormalTok{(}\DecValTok{3}\NormalTok{, a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{*} \DecValTok{3}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{pch =} \DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L04-Regression_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\end{figure}

It looks like this is somewhere around where we would expect.

If we repeat this for every possible \(x\) value, we get the regression
line below:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{points}\NormalTok{(}\DecValTok{3}\NormalTok{, a }\SpecialCharTok{+}\NormalTok{ b}\SpecialCharTok{*}\DecValTok{3}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{pch =} \DecValTok{16}\NormalTok{)}
\DocumentationTok{\#\# abline adds a line with slope b and intercept a to a plot.}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{a =}\NormalTok{ a, }\AttributeTok{b =}\NormalTok{ b, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L04-Regression_files/figure-pdf/unnamed-chunk-6-1.pdf}

}

\end{figure}

We cal also see the values of \(e\), the residuals.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{{-}}\NormalTok{ (a }\SpecialCharTok{+}\NormalTok{ b}\SpecialCharTok{*}\NormalTok{x) }\DocumentationTok{\#\# Observed minus expected}
\FunctionTok{plot}\NormalTok{(e }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{main =} \StringTok{"Plot of the Residuals"}\NormalTok{)}
\DocumentationTok{\#\# abline can also draw a line with slope 0 (horizontal)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \DecValTok{0}\NormalTok{, }\AttributeTok{col =} \StringTok{"grey"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L04-Regression_files/figure-pdf/unnamed-chunk-7-1.pdf}

}

\end{figure}

\hypertarget{regression-facts}{%
\section{Regression Facts}\label{regression-facts}}

Here are some facts about the least squares regression line:

\begin{itemize}
\tightlist
\item
  The point \((\bar x, \bar y)\) is always on the line.

  \begin{itemize}
  \tightlist
  \item
    Least squares regression can be seen as putting a line through
    \((\bar x, \bar y)\) and rotating it until the squared error is the
    smallest.
  \end{itemize}
\item
  \(s_y\ge 0\) and \(s_x\ge 0\), so whenever \(r > 0\), we know that
  \(b > 0\).

  \begin{itemize}
  \tightlist
  \item
    The slope has the same sign as the correlation. Otherwise, the slope
    could be pretty much any number, regardless of the correlation.
  \item
    If \(r = 0\), then \(b = 0\), and vice versa.
  \item
    Other than the sign and the special case of \(r=0\), there is no way
    to tell the value of \(r\) if all you know is \(b\).
  \end{itemize}
\item
  For \(r\), the distinction between \(y\) and \(x\) doesn't matter.

  \begin{itemize}
  \tightlist
  \item
    For the regression line, it \emph{absolutely} matters!
  \end{itemize}
\item
  The sum of the errors is 0.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# The prediction at mean(x) is equal to mean(y)}
\DocumentationTok{\#\# In other words, (mean(x), mean(y)) is a point on the line}
\NormalTok{a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{*} \FunctionTok{mean}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 20.09062
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 20.09062
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Correlation doesn\textquotesingle{}t care about order}
\FunctionTok{cor}\NormalTok{(x, y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.8676594
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(y, x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.8676594
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Theoretically 0, but computers aren\textquotesingle{}t perfectly precise}
\DocumentationTok{\#\# Note: e{-}14 refers to 10\^{}{-}14, or 14 zeroes before the first digit}
    \CommentTok{\# So, pretty close to 0.}
\FunctionTok{sum}\NormalTok{(e) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.065814e-14
\end{verbatim}

\hypertarget{percent-of-variation-explained}{%
\section{Percent of Variation
Explained}\label{percent-of-variation-explained}}

Because of some mathematical magic, \(r^2\), the squared value of \(r\),
can be interpreted as:

\begin{quote}
\textbf{The percent of variation in \(y\) that can be ``explained'' by
the linear model}.\footnote{Usually \(r^2\) is labelled \(R^2\) for
  historical reasons. Capitalization matters in math; it's just
  coincidence that both lower case and upper case mean the same thing
  here.}
\end{quote}

The value of \(r^2\) can be calculated as: \[
R^2 = r^2 \approx \frac{\text{Variance of the predicted }y\text{-values}}{\text{Variance of the observed }y\text{-values}}
\]

I'll explain this in steps. The first plot below shows just the values
in \(y\). This collection of values has a own mean and variance.

The second plot shows the change in variance that the line ``explains''.
Instead of deviations above and below the mean, the variance can now be
characterized as the deviations above and below the regression line.
This variance will always be lower than the variance of \(y\) without
incorporating \(x\)\footnote{Except when \(r=0\), can you explain why?}.

The third plot shows where this variance went. \emph{The line itself has
variance}; there is deviation in the line above and below the mean of
\(y\). This is the variance that gets explained by incorporating \(x\)!
If you consider one of the points in \(y\), say \(y_1\), the distance
between \(y_1\) and \(\bar y\) can be split up into the difference
between \(\bar y\) and the regression line plus the distance between the
regression line and \(y_1\).

\includegraphics{L04-Regression_files/figure-pdf/unnamed-chunk-9-1.pdf}

The rest of the variance is left \textbf{unexplianed}. No regression
will ever be perfect unless we are studing a very very simple .

To see this a different way, consider what happens when
\(r = 0\)\footnote{Therefore the slope will also be 0.}. This will just
be a horizontal line, and none of the variance is explained. On the
other had, if \(r = 1\) then all of the points will be exactly on the
line. All of the variance in \(y\) has been explained by the regression
against \(x\) - there's no variance left to be explained!\footnote{Statistics
  is \emph{still} just the study of variance.}

Notice how the R output includes

\hypertarget{extensions-and-cautions}{%
\section{Extensions and Cautions}\label{extensions-and-cautions}}

\hypertarget{prediction}{%
\subsection{Prediction}\label{prediction}}

For a new \(x\) value, \[y = a + bx\] is the \textbf{predicted} value of
\(y\). That is, if we have an \(x\) value, we can plug it into the
equation and find out what value of \(y\) we would expect.

Note: There is still variance around this prediction! Our ``expected''
value will never be exactly equal to the truth - The value of \(y\) at a
given value of \(x\) follows a normal distribution\footnote{Our
  \textbf{prediction} is just us guessing the mean value of \(y\) at
  different values of \(x\).}, and the probability of a single point is
0!

\hypertarget{extrapolation}{%
\subsection{Extrapolation}\label{extrapolation}}

\textbf{Extrapolation} is what happens when prediction goes wrong. In
particular, it's what happens when we try to make a prediction at an
\(x\) value where we don't have any data. Usually this means we're
predicting an \(x\) value far above or far below the range of our data,
but it can also happen if there's a gap in the middle of our data.

In the plot below, the black dots are the original data, and we're
trying to predict a new value at \(x = 25\). The red line is the true
model that I generated the data from. The black line represents a linear
model. This model fits the original data quite well\footnote{Even though
  it's not the true relationship, it's a reasonable approximation.}, but
predictions are completely inappropriate for values outside the data.

\includegraphics{L04-Regression_files/figure-pdf/unnamed-chunk-10-1.pdf}

\hypertarget{lurking-variables}{%
\subsection{Lurking Variables}\label{lurking-variables}}

The black line in the plot below represents a regression where all of
the data was lumped together. As we can see, this line does not seem to
fit the data well. There is a hidden relationship in the the data - the
green points and the red points should be considered
separately\footnote{Possibly as a blocking variable.}.

\includegraphics{L04-Regression_files/figure-pdf/unnamed-chunk-11-1.pdf}

A more serious consequence of a lurking variable has shown up before in
the Palmer penguins data. In that example, the lurking variable actually
\textbf{reversed} the correlation - if we lumped the groups together we
got a negative correlation (and therefore negative slope), but if we
looked at the groups individually we got positive associations in all of
the groups! This is called \textbf{Simpson's Paradox}, and basically
means that we have to be very careful about interpreting correlations!

\includegraphics{L04-Regression_files/figure-pdf/unnamed-chunk-12-1.pdf}

\hypertarget{exercises-1}{%
\chapter{Exercises}\label{exercises-1}}

1 Suppose \(r = 0.3\). What are the possible values for the slope? a.
\(b > 0\) b. \(b \ge 0\) c.~The slope could still be any value.

\textbf{Solution} (really think it through before revealing answer!)

The slope and the correlation coefficient have the same sign (if the
correlation is positive, then the slope must be positive). From the
formula, \(b=0\) only if \(r = 0\) (and vice versa). Therefore the
answer is a.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Suppose the coefficient of variation is 0.3. What are the possible
  values of the slope?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    \(b > 0\)
  \item
    \(b \ge 0\)
  \item
    The slope could still be any value.
  \item
    The slope could still be any value (except 0).
  \end{enumerate}
\end{enumerate}

\textbf{Solution} (really think it through before revealing answer)

Since \(R^2\) is a squared value, it's positive whether the slope is
positive or negative. However, the slope is still 0 whenever \(r\) is 0,
so the answer is d.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Which of the following might be modelled well by a linear
  relationship?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Career points in a particular sport versus number of injuries.
  \item
    Hours of work required for a project and labour costs.
  \item
    The height of a ball over time after being thrown in the air.
  \item
    Hours spent studying and final grade.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

a, b, and d could all be argued to be linear, assuming that the data
were collected well and as categorical variables. c is clearly not
linear - a ball goes up and then goes down, which cannot be modelled by
a line.

\hypertarget{probability-background}{%
\chapter{Probability Background}\label{probability-background}}

Please pay attention to the margin notes.\footnote{These things!} They
often contain important information.\footnote{Or silliness.}

These notes are based on Chapter 9 in Baldi \& Moore (4th edition).
Chapter 2 of \href{https://www.openintro.org/book/biostat}{OpenIntro
Biostatics} is also a great (free) resource.

\hypertarget{defining-probability-with-dice}{%
\section{Defining Probability with
Dice}\label{defining-probability-with-dice}}

I find that the easiest way is to build this up by examples. Let's start
with rolling a dice.\footnote{The singular form ``die'' is dieing out;
  the dictionary lists ``dice'' as singular noun, and the singular
  ``dice'' is clearer for new English speakers.} Let's say you rolled
the dice, and you got a 3. This is called a \textbf{simple event}. The
collection of all \textbf{simple events} is called the \textbf{Sample
Space}, which in this case is \(\mathcal S\)=\{1,2,3,4,5,6\}.

Now, suppose that you're about to roll a dice. You might be curious
about whether it's a 1, 2, 3, 4, 5, or a 6, but you might only care
about the \textbf{event} that the outcome is even. Since there are
multiple simple events that make up this event, it is called a
\textbf{compound event}.

There's no way for you to know what's going to happen, but you know all
of the possibilities and you know how likely they all are.\footnote{Assuming
  there's nothing unusual about your dice.} This is called a
\textbf{Probability Model}: The sample space along with the probability
of all of the events.

I said ``the probability of all events'', but this is more complicated
than it may seem and requires some explanation. For something like
rolling a dice, you only need to know the probability of each simple
event. Compound events, like the probability that the outcome is even,
can be determined from these simple events.

Suppose you're playing a game where, if the outcome of the dice is less
than a certain cutoff value you get to roll again (e.g., your character
has a special ability that allows re-rolling of dice, but the re-roll
condition depends on the situation). You know the probability of all of
the simple events, but you need to know the cutoff value to actually
compute any probabilities. Without the cutoff value, you cannot define
the probability model.

For a dice, the probability model is simply: Each number has a
probability of 1 in 6. But what does this mean? There are two
perspectives on what a ``probability'' is: The Frequentist approach and
the Bayesian approach. In this class we're only going to learn the
Frequentist definition of probability, but if you're interested in
learning more I'm happy to talk.\footnote{Most of my work uses the
  Bayesian definition.}

\textbf{Probability} (Frequentist Definition): The long run frequency of
observing an event. In other words, it's the number of times an event is
observed divided by the number of trials after doing a near-infinite
number of trials.

For the dice, if we rolled the dice 60 times, we would expect 10 of
those rolls to be a 1, 10 of them to be a 2, etc. Due to randomness, we
won't get exactly that, but this is what we would expect. If we rolled
600 dice, we would expect 100 to be 1, etc. As we roll more dice, we get
closer to the proportion of 1/6. The plot below this demonstrates this -
it is the number of times that a dice was 1 divided by the number of
trials, with the number of trials being increased. Notice how it takes a
while for the ``empirical'' probability to reach the theoretical
probably; as the number of trials approaches infinity, the proportion of
rolls that showed a 1 will approach 1/6.

\includegraphics{L05-Probability_files/figure-pdf/unnamed-chunk-1-1.pdf}

\hypertarget{calculating-probability-with-dice}{%
\section{Calculating Probability with
Dice}\label{calculating-probability-with-dice}}

First, let's introduce some notation. I will use P(x) to mean ``The
probability of x''. In some cases, the context will be clear, such as:

\begin{itemize}
\tightlist
\item
  ``The probability of rolling a 1'' = P(1)
\item
  ``The probability of rolling an even number'' = P(even)
\item
  ``The probability of \emph{not} rolling a 1'' = 1 - P(1)\footnote{This
    is called a \textbf{complement}.}
\end{itemize}

For this section, we'll assume that
P(1)=P(2)=P(3)=P(4)=P(5)=P(6)=1/6.\footnote{The sum of all probabilities
  must be 1.}

\hypertarget{or}{%
\subsection{``Or''}\label{or}}

What's the probability that we roll an even number? The even numbers are
2, 4, and 6, so what we're really asking is ``What's the probability
that we roll a 2, 4, \textbf{or} a 6?'' In this case, the probability is
P(2 or 4 or 6) = P(2)+P(4)+P(6) = 1/6 + 1/6 + 1/6 = 3/6 = 0.5.

We also could have figured out this probability by noting that half of
the values are even, so a probability of 0.5 makes sense. It's a good
thing when our intuition matches our answer, as we'll see next.

Let's consider the probability that the dice is even\^{} (which we will
denote P(even)) \textbf{or} it's strictly larger than 3 (denoted
P(\textgreater3)). This means the dice is either 2, 4, or 6, or it's 4,
5, 6. Since there are 4 different numbers (2, 4, 5, and 6) that would
match the criteria, the probability is 4/6. Let's use our ``or'' rules
to verify this!

The probability that the dice is even is 1/2. The probabilty that the
dice is larger than 3 is also 1/2. So, obviously, P(even or
\textgreater3) = P(even) + P(\textgreater3) = 1/2 + 1/2 = 1.

Wait.

That can't be right.

I think you may be able to see what went wrong. The P(even) = P(2) +
P(4) + P(6), and P(\textgreater3) = P(4) + P(5) + P(6). When we did
P(even) + P(\textgreater3), we added P(4) and P(6) twice! To get the
right answer, we need to fix this. Since we added them twice, we must
subtract them once. This brings us to\ldots{}

\hypertarget{the-addition-rule-for-or}{%
\subsection{The Addition Rule for
``or''}\label{the-addition-rule-for-or}}

For any two events A and B,\footnote{For example, A = ``Even'', B =
  ``\textgreater3''.} the \textbf{Addition Rule} states:

\begin{align}P(A\; or\; B) = P(A) + P(B) - P(A\; and\; B).\end{align}

First, note that the probability of both events is P(Even \textbf{and}
\textgreater3) = P(4) + P(6), since 4 and 6 are both even and larger
than 3.

\begin{align*}
 P(Even\; or\; >3) & = P(Even) + P(>3) - P(Even\; and\; >3)\\
& = [P(2) + P(4) + P(6)] + [P(4) + P(5) + P(6)] - [P(4) + P(6)]\\
& =  P(2) + P(4) + P(5) + P(6)\\
& = 1/6 + 1/6 + 1/6 + 1/6\\
& = 4/6
\end{align*} \normalsize

\hypertarget{and-part-1}{%
\subsection{``and'': Part 1}\label{and-part-1}}

The word ``and'' came up in the addition rule, and so I should give a
good definition of ``and''. When we talk about events A and B, P(A and
B) refers to the probability that they both happen together. It's most
helpful to see this as a Venn diagram:

P(A) is the area of the circle labelled A, P(B) is the area of the
circle labelled B, and P(A and B) is the area of the overlap between
these two circles. P(A or B) is the total shaded area, including the
yellow-green, green, and dark green.

You can see the Addition Rule at work here. If you add the area of A
(which includes P(A and B)) to the area of B (which also includes P(A
and B)), you've added P(A and B) twice!

There are two formulas for P(A and B). The first one is found by
rearranging the formula for P(A or B):

\begin{align*}
\small P(A\; or\; B) &\small = P(A) + P(B) - P(A \;and\; B)\\
\small P(A\; and\; B) &\small = P(A) + P(B) - P(A \;or\; B)
\end{align*}

When in doubt, just remember P(A\_B) = P(A) + P(B) - P(A\_B), then put
``or'' in one blank and ``and'' in the other.

This formula won't always get you to the solution, though. There will be
many times where neither ``and'' nor ``or'' will be obvious, and we'll
need to do some more work to get them. We have special formulas for
``and'', so we'll usually try to figure out the ``and'' and then use it
to figure out the ``or''\footnote{This lecture has some of the weirdest
  sentences.}.

\hypertarget{given-conditional-probabilities}{%
\subsection{``given'': Conditional
Probabilities}\label{given-conditional-probabilities}}

A \emph{condition} is something that must happen before you can proceed.
A \textbf{conditional probability} is a probability that requires
something else to happen, and usually involves a more complicated setup.

Let's look at another scenario. Let's say I told you that the number on
the dice was larger than 3. What's the probability that the number on
the dice is a 4? Intuiutively, it's 1/3, since there are 3 possible
numbers. Our notation fails us here, P(4) denotes the probability that
the dice is a 4, which we already determined was 1/6. We can't use P(4)
for two things, so we need to add some notation.

In this case, the solution is to use a vertical bar, ``\textbar{}'',
which is pronounced ``given''. We write ``P(dice is 4 \textbar{} dice is
greater than 3) = 1/3'',\footnote{P(4 \textbar{} \textgreater3) just
  looks too confusing, so I added some words.} which is read as ``The
probability that the dice is 4, \textbf{given that} the dice is larger
than 3.''

A very important thing happened here: when we used a conditional
probability (``given that''), we \textbf{restricted the sample space}.
When we ``condition'' on an event, it means that we're only looking at
cases where that event happened. ``The probability that the dice is 4,
given that the dice is larger than 3'' is another way of saying that
we're only considering events where the dice roll is greater than 3; we
don't care about 1, 2, or 3.

We defined ``probability'' as the total number of events divided by the
total number of trials. For conditional probabilities, this means that
we're only looking at \emph{some of} the trials.

\begin{align*}
\small P(dice\; is\; 4\; |\; dice\; is >3) = \frac{\#\; ways\;dice\;can\;be\;4\;}{\#\;ways\;dice\;can\;be\;>3}=\frac{1}{3}
\end{align*}

\textbf{This formula is incorrect}: ``The number of ways that a dice can
be 4'' depends on the condition. For instance, the number of ways that a
dice can be 2 is 0 since we're told it's larger than 3. We are actually
looking at the number of ways that the dice can be both 4 \textbf{and}
greater than 3. Let's incorporate this information:

\begin{align*}
\small P(dice\; is\; 4\; |\; dice\; is >3) = \frac{\#\; ways\;dice\;can\;be\;4\;\;and\;>3}{\#\;ways\;dice\;can\;be\;>3}=\frac{1}{3}
\end{align*}

For any two events A and B, \textbf{conditional probabilities} are
defined as follows:\footnote{To remember this, I like to imagine the
  vertical bar falling on the the B and pushing it into the denominator.}

\begin{align*}
\small P(A | B) = \frac{P(A\;and\; B)}{P(B)}
\end{align*}

The equation above is a \emph{definition}. It's not the result of
something else, it's the way we define conditional probability.
Rearranging it, though, gives us an important result.

\hypertarget{and-part-2-the-multiplication-rule}{%
\subsection{``and'' Part 2: The Multiplication
Rule}\label{and-part-2-the-multiplication-rule}}

For any two events A and B, the \textbf{Multiplication Rule} states:

\begin{align*}
\small P(A\; and\; B) = P(A|B)P(B)
\end{align*}

Note that P(B\textbar A) = P(A and B)/P(A), so the multiplication rule
can be extended:

\begin{align*}
\small P(A\; and\; B) &\small = P(A|B)P(B)\\
\small P(A\; and\; B) &\small = P(B|A)P(A)
\end{align*}

In other words, you can write it either way as long as the event that
comes after the ``\textbar{}'' also appears on it's own.

Let's use this to answer the following question: What's the probability
that a dice is larger than 3 \textbf{and} even? By intuition, this
should be 2/6 since there are two cases where both are true, but let's
verify with math!

First, recall that P(\textgreater3) and P(even) are both 1/2.

P(\textgreater3 \textbar{} even) means that we're look at the number of
dice rolls that are larger than 3, but we're only considering even dice
rolls. We have 3 total dice rolls that are even, and 2 of those are
larger than 3, so this probability is 2/3. Using the multiplication
rule, P(\textgreater3 and even) = P(\textgreater3 \textbar{}
even)*P(even) = (2/3)*(1/2) = 2/6, which is what we got before!

The other way works out the same. Given that the roll is larger than 3,
there are 2 even rolls, which means that P(even \textbar{}
\textgreater3) = 2/3. P(\textgreater3 and even) = P(even \textbar{}
\textgreater3)*P(even) = (2/3)*(1/2) = 2/6, which is what we got before!

\hypertarget{special-cases-independent-or-disjoint}{%
\subsection{Special Cases: Independent or
Disjoint}\label{special-cases-independent-or-disjoint}}

\hypertarget{disjoint-a.k.a.-mutually-exclusive}{%
\subsection{Disjoint, a.k.a. Mutually
Exclusive}\label{disjoint-a.k.a.-mutually-exclusive}}

\textbf{Disjoint} events, also called \textbf{mutually exclusive}
events, are events that \emph{cannot} occur together. For example, the
event that you roll a 4 and it's also a 3. This simply does not work, so
the probability is 0.

More formally, A and B are \textbf{disjoint} if P(A and B) = 0.

\hypertarget{the-addition-rule-for-disjoint-events}{%
\subsection{The Addition Rule for Disjoint
Events}\label{the-addition-rule-for-disjoint-events}}

If A and B are disjoint, then P(A or B) = P(A) + P(B).\footnote{Not an
  important point: This is a rule, not a result. The General Addition
  Rule is a result of this rule, not the other way around.}

This is actually why we were able to say P(even) = P(2 or 4 or 6) = P(2)
+ P(4) + P(6) = 3/6: the events ``2'', ``4'', and ``6'' are disjoint.

\hypertarget{independent}{%
\subsection{Independent}\label{independent}}

Two events are \textbf{independent} if the knowledge of one event tells
you nothing about the other.\footnote{The opposite of
  \textbf{independence} is \textbf{dependence}.} For instance, if I flip
two different coins and tell you that the first one was Heads, you still
only have a 50/50 chance of guessing the second one.

Notice the phrasing in the previous sentence: ``If I tell you that the
first one is heads\ldots{}'' That is, I'm \emph{restricting the sample
space}. Independence is all about conditional probabilities!

Formally, A and B are independent if P(A \textbar{} B) = P(A).

This adds further insight into conditional probabilities: P(A\textbar B)
is how likely A is, given that you know B happened. Knowledge of B
changes your guess of the likelihood of A. If it doesn't change your
guess, then they are independent.\footnote{Just like in correlations,
  dependence does \emph{not} imply causation!}

The following app demonstrates this concept:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DBecker7/DB7\_TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Apps/indep"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Another lesson to take from the app above: Independence doesn't look
special. You can't just tell that things are independent by looking at
them.

\hypertarget{the-multiplication-rule-for-independent-events}{%
\subsection{The Multiplication Rule for Independent
Events}\label{the-multiplication-rule-for-independent-events}}

Any time I see a conditional probability, I immediately write down the
formula. For dependence, we are saying:

P(A\textbar B) = P(A and B)/P(B)

which is the same as

P(A and B) = P(A\textbar B)P(B)\footnote{This equation is \emph{always}
  true.}

If two events are \textbf{independent}, then P(A\textbar B)=P(A),
therefore:

P(A and B) \(\stackrel{indep}{=}\) P(A)*P(B)\footnote{The ``\(indep\)''
  over the equals sign is there to specify that this is only true if
  events are independent.}

Get this tattood backwards on your forehead so you see it every time you
look at yourself in the mirror: \textbf{P(A and B) is ONLY equal to
P(A)*P(B) when A and B are independent!!!} Some textbooks start with
this rule then move to the general rule, but far too many students start
using P(A and B) = P(A)P(B) as if it's always true. My entire thesis is
based on whether you can say two things are independent, so it's kind of
a sore spot for me. DO NOT MIX THIS UP.

For example, are the events ``even'' and ``\textgreater3'' independent?
If you know that the dice roll is \textgreater3, then there's a 2/3
chance that it's even. That is, P(even\textbar\textgreater3) = 2/3
\(\ne\) 1/2 = P(even), so it's not independent.

Alternatively, we can calcuate P(even and \textgreater3) = 2/3, but
P(even)*P(\textgreater3) = (1/2)*(1/2) = 1/4. Since 2/3 \(\ne\) 1/4,
these events are not independent.

\hypertarget{disjoint-means-dependent}{%
\subsection{\texorpdfstring{Disjoint means
\emph{Dependent}}{Disjoint means Dependent}}\label{disjoint-means-dependent}}

\textbf{Independence} can be defined as ``if you know that one event
happened, you have no knowledge of the other event.'' \textbf{Disjoint}
can be defined as ``if you know one event happened, you know for sure
that the other one \emph{did not} happen.'' If two events are disjoint,
they must be \textbf{dependent}. In fact, knowledge of one event means
that you for sure know about the other - the exact opposite of
independence!

\ldots{} except when one event is impossible. For instance, P(even and
7) = 0 since there are no dice rolls that are both even and 7, but this
is also equal to P(even)*P(7) = 0 since there are no dice rolls that are
7.

\hypertarget{word-problems}{%
\section{Word Problems}\label{word-problems}}

Question 10.6 from the textbook:\footnote{Baldi, B. and DS. Moore. 2018.
  \emph{The Practice of Statistics in the Life Sciences.} 4th Edition,
  W.H. Freeman and Company.}

The National Survey on Drug Use and Health reports that 18.1\% of all
adults in the United States had a mental illness in 2014. Among adults
with a substance use disorder, 39.1\% had a mental illness. By
comparison, only 16.2\% of adults without a substance use disorder had a
mental illness. The report also states that 3.3\% of American adults had
both a mental illness and a substance use disorder. Use the notation MI
and SUD for mental illness and substance abuse disorder, respectively.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Express the four percents cited here as probabilities for a randomly
  selected American adult. Use proper probability notation.
\item
  Obtain the probability P(SUD\textbar MI). Write a sentence reporting
  this probability in context.
\end{enumerate}

Solutions:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  There are a couple of probabilities:

  \begin{itemize}
  \tightlist
  \item
    ``18.1\% of all adults in the United States had a mental illness'':
    P(MI) = 18.1
  \item
    ``Among adults with a substance use disorder, 39.1\% had a mental
    illness.'' The part that says ``among adults with SUD'' means that
    we're only looking at people with SUD; we're \emph{restricting the
    sample space}. This is a condition, so our answer must be P(\_
    \textbar{} SUD) = \_\_. The blanks can be filled in as
    P(MI\textbar SUD) = 0.391.
  \item
    ``16.2\% of adults without a substance use disorder had a mental
    illness.'' The part that says ``adults without a SUD'' is also
    \emph{restricting the sample space}, so our probability statement
    will be P(\_\_ \textbar{} no SUD) = \_\_. The blanks are filled in
    as P(MI \textbar{} no SUD) = 0.162.\footnote{This is a great place
      to mention: There's absolutely no reason why P(A\textbar B) +
      P(A\textbar{} not B) should add to 1.}
  \item
    ``3.3\% of American adults had both a MI and a SUD''. This clearly
    states \textbf{and}, so we are looking at P(MI and SUD) = 0.033
  \end{itemize}
\end{enumerate}

Part b. is going to take a few steps. Let's write down all the formulas
that might help. Firstly. there's no ``or'', so that probably won't do
it.

\begin{itemize}
\tightlist
\item
  \emph{Want}: P(SUD\textbar MI)

  \begin{itemize}
  \tightlist
  \item
    P(SUD\textbar MI) = P(SUD and MI)/P(MI), so we need P(SUD and MI)
    and P(MI).
  \end{itemize}
\item
  \emph{Have}:

  \begin{itemize}
  \tightlist
  \item
    P(MI) = 0.181
  \item
    P(MI \textbar{} SUD) = 0.391
  \item
    P(MI \textbar{} no SUD) = 0.162
  \item
    P(MI and SUD) = 0.033
  \end{itemize}
\end{itemize}

Both P(SUD and MI) and P(MI) are given in the question, so our answer is
simply:

\begin{quote}
P(SUD \textbar{} MI) = P(SUD and MI)/P(MI) = 0.033/0.181 = 0.1823
\end{quote}

Therefore 18.23\% of people with mental illness have substance abuse
disorder.

Compare this value to P(MI \textbar{} SUD) = 0.391. In general, there is
no easy relationship between P(A \textbar{} B) and P(B \textbar{} A). If
you know what P(A \textbar{} B) is, you can't really guess at what P(B
\textbar{} A) is; you need a lot more information!

\hypertarget{two-way-tables}{%
\section{Two-Way Tables}\label{two-way-tables}}

I rigorously collected the following data\footnote{Source: I made it up.}
on programming language usage for different disciplines using the most
appropriate sampling methods.

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
& Stats & Math & Comp Sci & Total \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
R & 90 & 30 & 40 & 160 \\
Python & 10 & 60 & 100 & 170 \\
MatLab & 15 & 60 & 15 & 90 \\
Julia & 10 & 10 & 1 & 21 \\
\textbf{Total} & 125 & 160 & 156 & 431 \\
\end{longtable}

From this table, we can calculate \textbf{marginal} and
\textbf{conditional} probabilities.

\textbf{Marginal} probabilities are calculated from the margins, which
means that we ignore one of the variables. For example, P(Math) =
160/431 and P(Julia) = 21/431. Both of these proportions are based on
the margins - they don't take the other variable into account.

\textbf{Conditional} probabilities are the same idea as we saw earlier.
Again, we are \emph{restricting our sample space} by conditioning on
another variable. For example, P(R \textbar{} Stats) = 90/125, whereas
P(Stats \textbar{} R) = 90/160. The conditioning event determines which
row/column we use. When we condition on Stats, we \emph{only} look at
the column labelled stats - we do not consider any of the other numbers.
This is why P(R \textbar{} Stats) has a numerator of 125, rather than
431.

You should be familiar with the following calculations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  P(Stats) = 125/431
\item
  P(Stats \textbar{} Julia) = 10/21
\item
  P(Matlab \textbar{} Comp Sci) = ???\footnote{Answer is at the end.}
\item
  P(Stats \textbf{and} Julia) = 10/431
\item
  P(Matlab \textbf{and} Stats) = 15/431
\item
  P(Stats \textbf{or} Julia) = P(Stats) + P(Julia) - P(Stats
  \textbf{and} Julia) = 136/431
\item
  P(Matlab \textbf{or} Stats) = 200
\item
  P(Stats \textbf{or} R) = ???
\item
  P(Stats \textbf{or} Math) = ??
\end{enumerate}

Two-way tables can also be created in R using the \texttt{table()}
function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(mtcars) }\CommentTok{\# It\textquotesingle{}s a very useful dataset}

\FunctionTok{cbind}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{am, mtcars}\SpecialCharTok{$}\NormalTok{cyl) }\CommentTok{\# cbind BINDs Columns together}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      [,1] [,2]
 [1,]    1    6
 [2,]    1    6
 [3,]    1    4
 [4,]    0    6
 [5,]    0    8
 [6,]    0    6
 [7,]    0    8
 [8,]    0    4
 [9,]    0    4
[10,]    0    6
[11,]    0    6
[12,]    0    8
[13,]    0    8
[14,]    0    8
[15,]    0    8
[16,]    0    8
[17,]    0    8
[18,]    1    4
[19,]    1    4
[20,]    1    4
[21,]    0    4
[22,]    0    8
[23,]    0    8
[24,]    0    8
[25,]    0    8
[26,]    1    4
[27,]    1    4
[28,]    1    4
[29,]    1    8
[30,]    1    6
[31,]    1    8
[32,]    1    4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{am, mtcars}\SpecialCharTok{$}\NormalTok{cyl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   
     4  6  8
  0  3  4 12
  1  8  3  2
\end{verbatim}

The table above is telling us that there were 3 cars that were automatic
(0) \textbf{and} had 4 cylinders.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Note: TRUE == 1, so the sum of a logical vector is the number of TRUEs}
\DocumentationTok{\#\# The "\&" operator only returns true if BOTH conditions are true, i.e.}
\DocumentationTok{\#\# if mtcars$cyl == 4 AND mtcars$am == 0}
\FunctionTok{sum}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{cyl }\SpecialCharTok{==} \DecValTok{4} \SpecialCharTok{\&}\NormalTok{ mtcars}\SpecialCharTok{$}\NormalTok{am }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3
\end{verbatim}

\hypertarget{self-study-questions}{%
\section{Self-Study Questions}\label{self-study-questions}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain why P(A) + P(not A) must be 1.
\item
  If P(A) = 0.2, P(B) = 0.35,

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    and P(A or B) = 0.75, find P(A and B).
  \item
    and P(A and B) = 0.15, find P(A or B).
  \item
    explain why P(A and B) can only be as large as 0.2.
  \item
    explain why P(A or B) must be at least 0.35.
  \end{enumerate}
\item
  For a 6-sided dice, show that the events ``even'' and ``odd'' are
  \emph{not} independent.
\item
  For a 6-sided dice, show that the events ``even'' and
  ``\textgreater4'' \emph{are} independent.
\item
  Consider flipping one coin and rolling one dice.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    List out all possible events (e.g., H1 for heads and 1, T4 for tails
    and a 4 on the dice).
  \item
    Based on your sample space, argue that P(T1) = 1/12.
  \item
    Are the events ``coin is tails'' and ``dice is 1'' independent? Give
    an intuitive and a mathematical reason.
  \end{enumerate}
\item
  Consider a loaded dice, where the probability of 1, 2, 3, 4, and 5 are
  all 1/8.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Explain why P(6) must be 3/8.
  \item
    What is P(even)?
  \item
    Are the events ``even'' and ``\textless3'' independent?
  \end{enumerate}
\end{enumerate}

Solutions to Two-Way Table exercises: \textbf{3.} 15/156; \textbf{8.}
195/431; \textbf{9.} 285/431

\hypertarget{binomial-probabilities}{%
\chapter{Binomial Probabilities}\label{binomial-probabilities}}

Please pay attention to the margin notes.\footnote{These things!} They
often contain important information.\footnote{Or silliness.}

\hypertarget{introduction-3}{%
\section{Introduction}\label{introduction-3}}

Probability models are ways of laying out all possible events as well as
the probability of each event. For things like coins and dice,
everything has the same probability and things work out nicely. In
Two-Way tables, we have all the probabilities laid out in front of us.
The Binomial distribution is our first foray into a formulaic approach
to probabilities.

\hypertarget{with-coins}{%
\subsection{With Coins}\label{with-coins}}

If we flip two coins, the outcomes are \{HH, HT, TH, TT\} and each of
these are equally likely. Instead of looking at each event, what is the
probability that there are 0 heads? 1 head? 2 heads?

For 0 and 2 heads, there is only 1 possibility, so it must be 1/4 for
each. For 1 head, there are 2 possibilities, each with probability 1/4,
so the answer is 2*1/4.\footnote{Since these events are
  \textbf{disjoint}, we can simply add them.}

Let's flip three coins. The outcomes are \{HHH, HHT, HTH, THH, HTT, THT,
TTH, TTT\}, so each outcome has a probability of 1/8. Another way to
come to this number is to look at the probability of heads: For HHH, the
probability is 0.5*0.5*0.5 since there's a 50\% chance of heads and each
coin flip is \textbf{independent}.\footnote{For coin flips, this is
  obvious. It won't always be!}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# Heads & Outcomes & Probability \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & TTT & 1/8 \\
1 & TTH, THT, HTT & 1/8+1/8+1/8 = 3/8 \\
2 & HHT, HTH, THH & 1/8+1/8+1/8 = 3/8 \\
3 & HHH & 1/8 \\
\end{longtable}

Alright, let's do 4 coins. How many ways are there to get, say, 2 heads
out of four flips? You can bet that a smart mathemetician has figured
out a way to do this without writing them all out again! This is called
\emph{combinatorics}, and includes a lot of things that are not relevant
right now. We'll focus on the \textbf{choose} function. For three coins,
``3 choose 1'' means ``out of 3 options, choose 1 of them''. Sometimes
this is shortened to ``3C1''. As we saw in the table above, there's 1
way to choose nothing (no heads), 3 ways to choose 1 thing, 3 ways to
choose 2 things, and 1 way to choose 3 things.\footnote{And 0 ways to
  choose 4 things.} In R:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This code will **not** be tested on exams or assignments.}
\CommentTok{\# It\textquotesingle{}s just here to do calculations for us.}
\FunctionTok{choose}\NormalTok{(}\AttributeTok{n =} \DecValTok{3}\NormalTok{, }\AttributeTok{k =} \DecValTok{0}\NormalTok{) }\CommentTok{\# 3C0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\AttributeTok{n =} \DecValTok{3}\NormalTok{, }\AttributeTok{k =} \DecValTok{1}\NormalTok{) }\CommentTok{\# 3C1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\AttributeTok{n =} \DecValTok{3}\NormalTok{, }\AttributeTok{k =} \DecValTok{2}\NormalTok{) }\CommentTok{\# 3C2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\AttributeTok{n =} \DecValTok{3}\NormalTok{, }\AttributeTok{k =} \DecValTok{3}\NormalTok{) }\CommentTok{\# 3C3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\AttributeTok{n =} \DecValTok{4}\NormalTok{, }\AttributeTok{k =} \DecValTok{2}\NormalTok{) }\CommentTok{\# 4C2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 6
\end{verbatim}

So for 4 coins, there is 4C2 = 6 ways to get two heads.\footnote{Verify
  this by writing out all of the possibilities.} What's the probability
of each of these 6 outcomes? Since there's a 0.5 chance of heads and a
0.5 chance of tails, there's a 0.5*0.5*0.5*0.5 = 0.5\(^4\) = 0.0625
chance. That means that there's a 6*0.0625 = 0.375 chance of getting two
heads out of four flips.\footnote{Don't be afraid to re-read this
  paragraph several times, there's a lot of math here.}

Just to be complete, let's do this again for 5 coins. We're already at
the point where we \emph{need} the choose function because there are too
many outcomes to write out by hand. Let's calculate some probabilities
with R:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Again, this code is not on the tests or assignments.}

\DocumentationTok{\#\# Probability of 4 heads out of 5 flips:}
\FunctionTok{choose}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.5}\SpecialCharTok{\^{}}\DecValTok{5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.15625
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Probability of 3 heads out of 5 flips:}
\FunctionTok{choose}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.5}\SpecialCharTok{\^{}}\DecValTok{5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3125
\end{verbatim}

For completeness, let's make sure these all add up to 1:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# I really hope this adds to 1}
\NormalTok{(}\FunctionTok{choose}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{0}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.5}\SpecialCharTok{\^{}}\DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{  (}\FunctionTok{choose}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.5}\SpecialCharTok{\^{}}\DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{  (}\FunctionTok{choose}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.5}\SpecialCharTok{\^{}}\DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{  (}\FunctionTok{choose}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.5}\SpecialCharTok{\^{}}\DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{  (}\FunctionTok{choose}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.5}\SpecialCharTok{\^{}}\DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{  (}\FunctionTok{choose}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.5}\SpecialCharTok{\^{}}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

\hypertarget{with-dice}{%
\subsection{With Dice}\label{with-dice}}

If I roll two dice, what's the probability that exactly 1 of them is a
3? One way this can happen is if the first dice is a 3 and the second
one is \emph{not} a 3.

The probability that the first dice is a 3 is clearly 1/6. The
probability that the second dice is \emph{not} a 3 is 5/6. Finding the
probability that something \emph{doesn't} happen can be simplified:
either something happens or it doesn't. The probability has to add to 1,
so P(happens) + P(doesn't happen) = 1. Rearranging this equation,
P(doesn't happen) = 1 - P(happens). So P(not 3) = 1 - P(3). This will
come up often in this lecture, so take a moment to explain it to your
grandma\footnote{Call your grandma - she'll appreciate it!}.

From this, and knowing that the two dice rolls are independent, we see
that the probability is (1/6)*(1 - 1/6).

We can also have exactly one 3 if the first dice is not 3 but the second
dice is 3. This has the same probability as the other way around: (1 -
1/6)*(1/6).

Notice how this is the second of two options. Again, we get to use the
choose function:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Probability of exactly one 3 in two dice rolls}
\FunctionTok{choose}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{/}\DecValTok{6}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1{-}1}\SpecialCharTok{/}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2777778
\end{verbatim}

If we roll 18 dice, what's the probability that exactly four of them
show a 5? Regardless of the order, we have four dice that are 5 and 14
dice that are not 5. The probability of any one of the outcomes is
(1/6)\(^4\)*(1 - 1/6)\(^{14}\) = 0.000060098. That's pretty unlikely for
this exact dice combination of dice rolls! But how many ways are there
for this to happen? There are 18C4 = 3060, which is a lot, so there are
a lot of opportunities for things with small probabilities. The
probability of exactly four 5s out of 18 rolls is
18C4*(1/6)\textsuperscript{4*(1-1/6)}14 = 0.1840. Even though an
individual dice roll is unlikely, there are a lot of dice rolls that
meet our criteria of four 5s out of 14 rolls!

\hypertarget{binomial-probabilities-1}{%
\section{Binomial Probabilities}\label{binomial-probabilities-1}}

In general, if we have \(n\) trials and the probability of the event of
interest, a.k.a. \textbf{success}, is \(p\), then

\begin{align*}
P(x\text{ successes in }n\text{ trials}) = nCx*p^x*(1-p)^{n-x}
\end{align*}

For the dice example, ``x successes in n trials'' can be interpreted as
``four 6s in 18 trials'', where \(x=4\), \(n=18\), and the ``14 rolls
that are not four'' comes from \(n-x=14\).

\hypertarget{confusing-but-useful-notation}{%
\subsection{Confusing (but Useful)
Notation}\label{confusing-but-useful-notation}}

In the statement above, we used \(x\) to refer to the number of heads. I
like this. Let's keep doing this.

For Binomial probabilities, we use the notation:

\begin{align*}
X \sim B(n,p)
\end{align*}

which is read as ``the random variable X is distributed as Binomial with
n trials and probability of success p''.\footnote{Notice how we're using
  upper case for the \textbf{random variable}, and lower case for the
  actual values. This is important for future stats classes, but just
  something you'll see me do for now.} The ``\(\sim\)'' just means ``is
distributed as'', which tells us where the probabilities are
distributed. This is why \(nCx*p^x*(1-p)^{n-x}\) is called the
\textbf{probability distribution function}, or pdf.\footnote{I usually
  use lower case so you don't confuse it with the PDF file extension.}

A \textbf{random variable} is just a variable that has a probability
distribution,\footnote{There's a much more correct, much more technical
  definition, but it's outside the scope of this course.} such as the
number of heads out of 5 flips. Before flipping these coins we have no
idea how many heads there will be, but we know the probability of each
number. We always use upper case letters for random variables. Once we
actually have a value (say, 1 heads), we use lower case. We often use
the notation \(P(X = x)\) to refer to ``the probability that the
\textbf{random variable} \(X\) will have the specific value of \(x\)''.
In other words, \(X\) is the unknown that could be anything, \(x\) is
the specific probability that we're interested in.

I just want to talk about ``distributions'' a little bit more. A
\textbf{distribution} tells you where the probabilities are. For coins,
50\% of the probability is in Heads, 50\% is in in tails. When we talk
about ``is the dice a 3?'', one-sixth of the probability is distributed
to the 3 and five-sixths are distributed elsewhere.

To summarise, saying that \(X \sim B(n,p)\), or that \(X\) is
distributed as a Binomial random variable with \(n\) trials and
probability of success \(p\), is the exact same as saying that
\(P(x\text{ successes in }n\text{ trials})\) can be found using the
equation \(nCx*p^x*(1-p)^{n-x}\). This is what it means to have a
\textbf{probability distribution function.}

To see all of these probabilities at once, we can plot this as a graph.
To reduce coding, let's look at \(X\sim B(3, 0.4)\):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We\textquotesingle{}re still not going to have this on tests!}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{) }\CommentTok{\# X values}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
    \FunctionTok{choose}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{0}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\FloatTok{0.4}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{0} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.4}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{,}
    \FunctionTok{choose}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\FloatTok{0.4}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{1} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.4}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{,}
    \FunctionTok{choose}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\FloatTok{0.4}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.4}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{1}\NormalTok{,}
    \FunctionTok{choose}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\FloatTok{0.4}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{3} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.4}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{0}
\NormalTok{)}

\CommentTok{\#plot(x,y) \# This will plot them, but it looks kinda bad}
\DocumentationTok{\#\# Since X can only be 0, 1, 2, or 3, let\textquotesingle{}s us a bar plot!}
\FunctionTok{barplot}\NormalTok{(y, }\AttributeTok{names =}\NormalTok{ x,}
  \AttributeTok{main =} \StringTok{"pdf of B(3, 0.4)"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"x"}\NormalTok{,}
  \AttributeTok{ylab =} \StringTok{"3Cx * p\^{}x * (1{-}p)\^{}(3{-}x)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L07-Binomial_Probabilities_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\end{figure}

Notice how 1 is the most likely value, with 2 being much less likely.
This makes sense - if the probability of heads is less than 0.5, we
expect that more of the coin flips will be tails! If the probability of
``heads'' were 0.5, then we would expect 1 and 2 to be equally likely.

\hypertarget{examples-1}{%
\subsection{Examples}\label{examples-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Suppose I have a coin that is weighted so that Heads comes up 80\% of
  the time. What is the probability that I get 8 heads in 10 flips?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\FloatTok{0.8}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{8} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\FloatTok{{-}0.8}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3019899
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What's the probability that I get anything other than 10 flips?

  \begin{itemize}
  \tightlist
  \item
    Try it yourself!
  \end{itemize}
\item
  What's the probability that I get \emph{more than} 8 heads in 10
  flips?

  \begin{itemize}
  \tightlist
  \item
    Since the events ``9 heads'' and ``10 heads'' are \textbf{disjoint},
    we can calculate these individually and add them together.
  \end{itemize}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{9}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\FloatTok{0.8}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{9} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\FloatTok{{-}0.8}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{1} \SpecialCharTok{+}
  \FunctionTok{choose}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{10}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\FloatTok{0.8}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{10} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\FloatTok{{-}0.8}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3758096
\end{verbatim}

\hypertarget{in-r}{%
\subsection{In R}\label{in-r}}

Typing out the whole formula is getting boring. Surely R, a
\emph{statistical} programming language, has a way to do it for me,
right? Of course!

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\FloatTok{0.8}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{8} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.8}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3019899
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\AttributeTok{x =} \DecValTok{8}\NormalTok{, }\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.8}\NormalTok{) }\CommentTok{\# This will be useful!}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3019899
\end{verbatim}

The \texttt{dbinom()} function has exactly the arguments that you would
expect. Lower case x is the specific value, size is the number of coin
flips, prob is the probability of success. The \texttt{d} stands for
``density'', which for our purposes is the same as ``distribution''.

As a special note, R will take a vector for \texttt{x}. We can find
multiple probabilities at once:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{), }\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3019899 0.2684355 0.1073742
\end{verbatim}

This allows us to easily plot the pdf:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\DecValTok{10} \CommentTok{\# a vector of the numbers from 0 to 10}

\DocumentationTok{\#\# note: x is the name of the object AND the argument,}
\DocumentationTok{\#\# hence why I wrote "x = x"}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{dbinom}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.8}\NormalTok{)}

\FunctionTok{barplot}\NormalTok{(}\AttributeTok{height =}\NormalTok{ y, }\AttributeTok{names =}\NormalTok{ x)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L07-Binomial_Probabilities_files/figure-pdf/unnamed-chunk-10-1.pdf}

}

\end{figure}

This bar plot shows us a couple of things. We can see that eight heads
is the most likely outcome with 30\% of all sets of 10 flips having 8
heads, which makes sense because the probability of heads is 80\%. Since
we're only flipping 10 times, we can't have values above 10. Because of
this, our plot is left skewed!

\hypertarget{cumulative-binomial-probabilities}{%
\section{Cumulative Binomial
Probabilities}\label{cumulative-binomial-probabilities}}

A \textbf{cumulative probability} is the probability of observing
\emph{up to} \(x\) successes in \(n\) trials. In other words, this is
\(P(X \le x)\): the probability that the \textbf{random variable} \(X\)
is smaller than or equal to some specific number \(x\). This is referred
to as the \textbf{Cumulative Distribution Function}, or cdf. It really
matters whether it's \(P(X\le x)\) or \(P(X< x)\)!

What's the probability that we get \emph{at most} 4 heads in 10 flips?
That's the same as the probability of 0 heads plus the probability of 1
heads plus the probability of 2 heads plus\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Note: R evaluates the arguments *in order*}
\DocumentationTok{\#\# It expects the arguments in the order of "x, size, prob",}
\DocumentationTok{\#\# so it assumes the first argument is x, the second is size,}
\DocumentationTok{\#\# and the third is prob.}
\FunctionTok{dbinom}\NormalTok{(}\AttributeTok{x =} \DecValTok{0}\NormalTok{, }\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{dbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{dbinom}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{10}\NormalTok{, }\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{dbinom}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{10}\NormalTok{, }\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{dbinom}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{10}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3769531
\end{verbatim}

What about the probability of \emph{at most} 40 heads in 100 flips? Do I
have to type all that out?

Nope! We can use the \texttt{pbinom()} function. First, let's verify it
with what we've already calculated:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pbinom}\NormalTok{(}\AttributeTok{q =} \DecValTok{4}\NormalTok{, }\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3769531
\end{verbatim}

Now, let's find the probability of at most 40 heads in 100 flips:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pbinom}\NormalTok{(}\DecValTok{40}\NormalTok{, }\DecValTok{100}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.02844397
\end{verbatim}

It's surprisingly small! Let's look at the pdf to see why:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{30}\SpecialCharTok{:}\DecValTok{70} \CommentTok{\# The pdf is REALLY small outside this range}

\DocumentationTok{\#\# I\textquotesingle{}m going to colour the bars where x \textless{}= 40}
\DocumentationTok{\#\# Start with a bunch of white bars by REPeating the colour}
\DocumentationTok{\#\# white for as many x values as we have}
\NormalTok{mycols }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\StringTok{"white"}\NormalTok{, }\FunctionTok{length}\NormalTok{(x))}
\DocumentationTok{\#\# Next, we change the colour where x \textless{}= 40}
\NormalTok{mycols[x }\SpecialCharTok{\textless{}=} \DecValTok{40}\NormalTok{] }\OtherTok{\textless{}{-}} \StringTok{"red"}

\DocumentationTok{\#\# Calculate the distribution function}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{dbinom}\NormalTok{(x, }\DecValTok{100}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\FunctionTok{barplot}\NormalTok{(}\AttributeTok{height =}\NormalTok{ y, }\AttributeTok{names =}\NormalTok{ x, }\AttributeTok{col =}\NormalTok{ mycols)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L07-Binomial_Probabilities_files/figure-pdf/unnamed-chunk-14-1.pdf}

}

\end{figure}

Make sure this number makes sense to you! It's always good to check the
results against your intuition - can you see why this number is so close
to 1 (use the plot above to inform your answer).

\hypertarget{examples-2}{%
\subsection{Examples}\label{examples-2}}

What's the probability of \emph{at least} 40 heads in 100 flips? Be
careful here: it matters whether I ask ``at least'' or ``more than''.
The cdf always calculates ``less than or equal to''\footnote{P(X \(\le\)
  x)}, and the \textbf{complement} of this is ``strictly greater
than''.\footnote{P(X \(\le\) x) = 1 - P(X \textgreater{} x)} If I'm
looking for ``strictly greater than'', I need to be careful what I use!

In this case, P(X \(\ge\) 40) = P(X \textgreater{} 39) = 1 - P(X \(\le\)
39) = \texttt{1\ -\ pbinom(39,\ 100,\ 0.5)}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pbinom}\NormalTok{(}\AttributeTok{q =} \DecValTok{39}\NormalTok{, }\AttributeTok{size =} \DecValTok{100}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9823999
\end{verbatim}

\hypertarget{properties-of-the-binomial-distribution}{%
\section{Properties of the Binomial
Distribution}\label{properties-of-the-binomial-distribution}}

I define ``math'' as the process of making up rules just to see what
happens. The Binomial distribution isn't just some abstract entity that
we discovered - it's a set of rules we created that seem to logically
fit some situations.\footnote{The philosophy of math is \emph{extremely}
  interesting. Most philosophers seem believe that we \emph{do} discover
  math, rather than create it. I also believe this, but probability
  distributions are in a grey area for this part of philosophy. When all
  this is over we should grab a drink and discuss this.} So first: what
are the rules?

\hypertarget{binomial-assumptions}{%
\subsection{Binomial Assumptions}\label{binomial-assumptions}}

I'm going to motivate these assumptions first. If you're the type that
just wants to memorize, you can skip to the end of this section.

We've been talking about flipping coins and rolling dice, which helped
motivate this distribution. We wouldn't be teaching you this
distribution if it only applied to dice and coins, so when can we apply
it?

Consider flipping a ``sticky'' coin twice. It starts with a 50/50 chance
of being heads, but the next flip has a 75\% chance of being the same as
the first.\footnote{If an engineer could make this coin for me I'd be
  infinitely grateful.} So if the first flip was heads, there's a 75\%
chance that the second flip will be heads. If the first flip was tails,
there's a 75\% chance that the second flip will be tails.

Let's first just calculate the probability of each outcome. The
probability that the first flip is heads \textbf{and} the second flip is
tails can be found using the \textbf{Multiplication Rule}, which states
that P(A and B) = P(A)P(B\textbar A). So P(HH) = P(first is H)P(second
is H \textbf{given that} the first was H) = 0.5*0.75 = 0.375. Similarly,
P(HT) = 0.125, P(TT) = 0.375, and P(TH) = 0.125.\footnote{Always make
  sure the numbers that I give you add to 1 - I will try and trick you
  with this!}

Let's compare these probabilities with the ones we calculated earlier.
The probability of 0 heads with the fair coin was 1/4, and this value
was calculated with the binomial distribution. With the sticky coin, the
probability of 0 heads is 0.375, which does \emph{not} come from the
binomial distribution.

Formally, the Binomial distribution \textbf{assumes} that each trial is
independent and the probability of success is the same in each trial.
While I didn't touch on this, the only random thing should be the number
of successes, \emph{not} the number of trials. Finally, recall that,
with the dice, I converted things to ``3'' or ``not 3''; the Binomial
distribution only works when each individual trial can only be one thing
or another. More succinctly, the \textbf{assumptions for the Binomial
Distribution} are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  There are n trials, and this number is known ahead of time.
\item
  Each trial is either a ``success'' or a ``failure''.
\item
  Each trial is \textbf{independent} of the other trials.
\item
  The probability of success is the same for all trials.
\end{enumerate}

\hypertarget{side-note-probability-of-success-is-the-same}{%
\subsection{Side note: ``probability of success is the
same''}\label{side-note-probability-of-success-is-the-same}}

As an example, consider studying, say, the proportion of questions that
a student got right on a multiple choice test. Each student has a
different probability of getting each question correct. However, if we
want to say something about the proportion of questions that a
\emph{random} student gets right on a test. In this sense, the fourth
assumption is not violated.

As an alternative, consider a test where the students go
one-by-one\footnote{in a random order} and can see the previous
student's solutions. In this case, the probability of success changes as
you have more trials. This is where the problem lies - the students are
still coming in a random order, but the probability of success changes.

As another alternative, suppose some students are cheating. They're more
likely to get the right answers together, so they're answers are
\textbf{dependent} on each other; knowing one cheater's answer gives you
a better guess at another cheater's answer.

In summary, a different probability of success is only an issue if the
researcher would be able to know this ahead of time. If the probability
of success is different but we have a simple random sample with
independent trials, there is no issue with this assumption.

\hypertarget{binomial-mean-and-variance}{%
\subsection{Binomial Mean and
Variance}\label{binomial-mean-and-variance}}

Now that we know the assumptions, we can see what comes out of these
assumptions. First, we can find the average value. It makes perfect
sense that the average number of heads in 10 flips should be 5. There's
a 50/50 chance of heads, so you'd expect half of the flips to be heads!
Formally, \(\mu = np\).\footnote{Why \(\mu\) and not \(\bar x\)? Because
  this is a \emph{theoretical} result. You can think of this as being
  the ``true'' population.} That is, the theoretical average is just the
number of trials times the probability of success.

What about the variance? It's not as obvious. I'm going to try and give
my own intuitive argument, but most teachers and textbooks simply skip
this and have you memorize the answer. If this is your style, you can
skip to the end of this section.

In the past, I have defined ``variance'' as something like ``the average
amount that you would be wrong if you always guessed the mean value.''
Consider flipping one coin. If this coin is rigged and always comes up
heads, the mean number of heads is 1 and you would always be right when
you guess the mean. Intuitively, the variance here is 0. The same
happens if the coin is rigged to always come up tails - the mean number
of heads is 0, and the number of heads never varies so the variance is
0.

What happens between 0 and 1? If the coin was heads 80\% of the time,
then your guess would be right 80\% of the time. The actual value of the
coin varies, but not too much. If the coin was heads 20\% of the time,
you'd still be right 80\% of the time by guessing 0 heads each time.
You'd be wrong \emph{most often} if the coin had a 50\% chance of being
heads.

So we've established this: At \(p=0\) and \(p=1\), the variance is 0.
The maximum value is at 0.5, and the variance should be the same if
you're 0.2 above 0.5 or 0.2 below (it's symmetric around 0.5). The
following plot, then, seems reasonable:

\includegraphics{L07-Binomial_Probabilities_files/figure-pdf/unnamed-chunk-16-1.pdf}

There's a lot of math behind this, but the variance for
Bin(1,p)\footnote{When n=1, this is also called the \emph{Bernoulli}
  distribution, but this is not important right now.} turns out to be
p(1-p). You can see that it would be symmetric around 0.5 and would be 0
whenever p=0 or p=1.

\textbf{In general, the variance of a B(n,p) distribution is
\(\sigma^2\) = np(1-p).}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

If you have a known number of repeated trials that are independent and
are either a ``success'' or ``falure'', then the Binomial distribution
is your friend. Once these assumptions are met, you can calculate the
probability of any number of successes using the pdf, you know what the
mean number of successes in \(n\) trials will be, and you know the
variance!\footnote{\textbf{Statistics} is the study of variance.}

As a rule, if you see the phrase ``Not enough information for a valid
answer'' as an option in a multiple choice question, double check that
the assumptions are all met. If the observations are not independent,
you need to know all of the \textbf{conditional probabilities} in order
to calculate the answer, which you probably don't have, so you're
missing information. If the probability of success changes from trial to
trial, you need to know how it changes.

\hypertarget{self-test-questions}{%
\section{Self-Test Questions}\label{self-test-questions}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Take a moment to explain what the \texttt{dbinom()} and
  \texttt{pbinom()} R functions do.
\item
  What happens when you put \texttt{x\ =\ 0.5} into
  \texttt{dbinom(x,\ 10,\ 0.5)}? Interpret this in terms of flipping
  coins.
\item
  I debated whether to include a section on ``shape'', but decided to
  let you figure it out for yourself. I've already given you the code to
  plot the pdf. For each of the values of n (size) and p (prob), plot
  the pdf and describe the shape. Note that x should (almost) always be
  \texttt{x\ \textless{}-\ 0:n}.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \tightlist
  \item
    Bin(50, 0.5)
  \item
    Bin(50, 0.8)
  \item
    Bin(50, 0.2)
  \item
    Bin(50, 0.02)
  \item
    Bin(4, 0.25)
  \end{enumerate}
\item
  For each of the assumptions, give an example of a situation that
  violates \emph{only one} of them, not the others.
\end{enumerate}

\hypertarget{crowdsourced-questions-3}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-3}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\hypertarget{the-normal-distributions}{%
\chapter{The Normal Distributions}\label{the-normal-distributions}}

\hypertarget{introduction-4}{%
\section{Introduction}\label{introduction-4}}

In this lecture we are looking at continuous distributions. Continuous
distributions have an odd quirk. If a variable has a continuous
distribution, then \(P(X = x) = 0\). That is, the probability of any
specific value is infinitely small.

Think of it this way: suppose that human heights go from 54 cm to 272
cm. For now, suppose all of these heights are equally likely. If we
record heights to the nearest centimeter, there are 219 possible
heights, so the probability that you are one of those heights is 1/219.
If we round to the nearest mm, there are 21,900 different heights. As we
get a more and more accurate measuring instrument, the probability of
any given height goes to 0. It's not that these heights are impossible,
it's that you're probably not going to ever guess my exact height when
we measure it with infinite accuracy.

So what do we do? How could we possibly calculate probabilities? Well,
we measure ranges! You can't guess my height exactly, but we can talk
about the probability that my height is between 170 and 180 cm, or even
the probability that my height would be 170, assuming we round to the
nearest centimeter.

\hypertarget{some-facts-about-distributions}{%
\subsection{Some Facts about
Distributions}\label{some-facts-about-distributions}}

Before we begin, the following properties are true of \emph{any}
distribution, regardless of whether they are discrete or continuous.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  All probabilities must be between 0 and 1.
\item
  All probabilities together must make 1.

  \begin{itemize}
  \tightlist
  \item
    For discrete, adding them all should get you to 1.
  \item
    For continuous, the area under the density curve must be
    1.\footnote{This is done with integrals, but we won't actually do
      this in this course.}
  \end{itemize}
\item
  If two events are disjoint, you must be able to add their
  probabilities.

  \begin{itemize}
  \tightlist
  \item
    It's weird, but we have to define this as a rule first before we can
    calculate probabilities.
  \end{itemize}
\end{enumerate}

The first point should be obvious, and you won't ever need to check
whether the third point is true.

The second point is the important one: The total probability for all
events must be 1. For continuous distributions like the normal
distribution, that means that the area under the curve is 1.\footnote{For
  continuous distributions, ``probability'' and ``area under the curve''
  are synonyms.}

\hypertarget{the-normal-distribution}{%
\section{The Normal Distribution}\label{the-normal-distribution}}

The normal distribution is a way to define the probability of something
using a function, but the function is complicated.\footnote{\((2\pi\sigma^2)^{-1/2}\exp\left(\frac{(x-\mu)^2}{-2\sigma^2}\right)\)}
Instead, we'll jump right into how to use it and let software deal with
the function.

In the introduction, I used the example of people's heights. I made the
assumption that all heights were equally likely, but this is just a
bonkers thing to say. Instead, some heights are more likely than other
heights. Of course, this doesn't mean that, say, 170 cm is very
unlikely, but 175 is likely, then 176 is unlikely, then 177 is
\emph{very} unlikely, then 178 is suddenly really likely again; most
people have heights close to the average and heights further from the
average are less likely. This is exactly what the normal distribution is
for! Here's what the normal distribution looks like:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu }\OtherTok{\textless{}{-}} \FloatTok{162.3}
\NormalTok{sig }\OtherTok{\textless{}{-}} \FloatTok{7.11}
\NormalTok{xseq }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(mu}\DecValTok{{-}3}\SpecialCharTok{*}\NormalTok{sig, mu }\SpecialCharTok{+} \DecValTok{3}\SpecialCharTok{*}\NormalTok{sig, }\AttributeTok{length.out =} \DecValTok{300}\NormalTok{)}
\NormalTok{yseq }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(}\AttributeTok{x =}\NormalTok{ xseq, }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sd =}\NormalTok{ sig) }

\FunctionTok{plot}\NormalTok{(xseq, yseq, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{,}
  \AttributeTok{main =} \StringTok{"Heights of Canadian Women"}\NormalTok{,}
  \AttributeTok{xlab =} \StringTok{"Height (cm)"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Prob. Density"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L08-Normal_Distributions_files/figure-pdf/unnamed-chunk-1-1.pdf}

}

\end{figure}

The plot above has the highest point occurs at exactly 162.3, which is
the best number I could find for the actual average height of Canadian
women. This is denoted \(\mu\). The width of the curve is a little
trickier - how did I choose to make it go from 145 to 180? I could
easily have stretched it out or squeezed it inwards in both directions.
The width is defined by the standard deviation, which is denoted
\(\sigma\). Because of the way the normal distribution is defined,
there's nothing else we can change about it - knowing \(\mu\) and
\(\sigma\) are enough to draw the entire curve.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Requires the "shiny" library}
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DBecker7/DB7\_TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Tools/normShape"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If we have a variable \(X\) that follows a normal distribution, we use
the notation \(X \sim N(\mu, \sigma)\).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Warning}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

Some textbooks use the notation \(X \sim N(\mu, \sigma^2)\), i.e.~they
use \(\sigma^2\) rather than \(\sigma\). It's like driving on the left
or the right side of the road - both are fine, but we have to choose one
and stick with it.

\end{tcolorbox}

The idea that ``most things are close to the center, and fewer things
further away'' can be very powerful. This applies to:

\begin{itemize}
\tightlist
\item
  Human heights
\item
  Income for a given job position
\item
  Change in stock price from day to day

  \begin{itemize}
  \tightlist
  \item
    On average the change is 0, but it does change. Small changes are
    much more likely than large ones, but large ones do happen.
  \item
    Obviously, extreme events happen sometimes, and major changes can
    happen.
  \end{itemize}
\item
  IQ scores
\item
  Birth weight
\item
  How much the prediction of a model differs from the truth
\end{itemize}

\hypertarget{calculating-normal-probabilities---part-1}{%
\section{Calculating Normal Probabilities - Part
1}\label{calculating-normal-probabilities---part-1}}

The height and width of the normal distribution are determined by the
\textbf{mean} (\(\mu\)) and \textbf{standard deviation} (\(\sigma\)),
and \emph{only} the mean and standard deviation. The mean just moves the
curve left and right, the standard deviation squeezes or stretches it.

To highlight this, we introduce something called the \textbf{Empirical
Rule}, a.k.a. the 68-95-99.5 Rule. No matter what the mean of the
distribution is, 68\% of the probability is within 1 standard deviation
of the mean. To say this another way, let's extend our notation
slightly. If \(X\sim N(\mu,\sigma)\), we can say that:

\begin{align*}
P(\mu - \sigma \le X \le \mu + \sigma) \approx 0.68
\end{align*}

To phrase this in another way, if we were to draw random numbers from
the normal distribution, 68\% of them would be between 1sd below the
mean and 1sd above the mean.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{4}\NormalTok{) }\CommentTok{\# Ensure the same random numbers every time}

\DocumentationTok{\#\# generate 10000 random N(0,1) values}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{10000}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{) }

\DocumentationTok{\#\# You won\textquotesingle{}t need to know how to write this code:}
\FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{\textgreater{}} \SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{\&}\NormalTok{ x }\SpecialCharTok{\textless{}} \DecValTok{1}\NormalTok{) }\CommentTok{\# x is larger than {-}1 AND less than 1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 6766
\end{verbatim}

So out of 10,000 random numbers from a N(0,1) distribution, 6,766
(67.66\%) of them were above -1 but below 1. If we change the mean and
sd, we still get the same results:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Mean is 4, sd is 30, so mean {-} 1sd = 4 {-} 30}
\DocumentationTok{\#\# Change the mean and sd for yourself to see what happens!}
\NormalTok{mu }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \DecValTok{30}
\NormalTok{x2 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{10000}\NormalTok{, }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sd =}\NormalTok{ sigma)}
\FunctionTok{sum}\NormalTok{(x2 }\SpecialCharTok{\textgreater{}}\NormalTok{ (mu }\SpecialCharTok{{-}}\NormalTok{ sigma) }\SpecialCharTok{\&}\NormalTok{ x2 }\SpecialCharTok{\textless{}}\NormalTok{ (mu }\SpecialCharTok{+}\NormalTok{ sigma)) }\CommentTok{\# Not exactly 68\%, but approximate!}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 6845
\end{verbatim}

As you can guess from the name ``68-95-99.7 Rule'', 68\% being within
one sd is only part of the story. The 95 refers to 95\% being within 2sd
of the mean, and the 99.7 refers to 99.7\% being within 3sd of the mean.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{\textgreater{}} \SpecialCharTok{{-}}\DecValTok{2} \SpecialCharTok{\&}\NormalTok{ x }\SpecialCharTok{\textless{}} \DecValTok{2}\NormalTok{) }\CommentTok{\# within 2sd of the mean}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9523
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{\textgreater{}} \SpecialCharTok{{-}}\DecValTok{3} \SpecialCharTok{\&}\NormalTok{ x }\SpecialCharTok{\textless{}} \DecValTok{3}\NormalTok{) }\CommentTok{\# within 3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9970
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Try this with x2 as well!}
\end{Highlighting}
\end{Shaded}

Some variant of the following image appears in countless textbooks:

\includegraphics{L08-Normal_Distributions_files/figure-pdf/unnamed-chunk-6-1.pdf}

As a small side note, the image above uses the word ``data''. By this,
it means that if this is the \textbf{population}, then 68\% of all the
data that it were possible to collect would be within one standard
deviation of the mean. As we saw in the simulated data above, this
number is almost never going to be perfect.

\hypertarget{trickier-calculations}{%
\subsection{Trickier calculations}\label{trickier-calculations}}

If 68\% of the data is between \(\mu - \sigma\) and \(\mu + \sigma\),
then there's still 32\% of the distribution outside this range. The
normal distribution is \textbf{symmetric}, so this 32\% gets split
exactly in half and 16\% of the distribution is below \(\mu - \sigma\),
and 16\% is above \(\mu + \sigma\).

Based on this calculation, we can say that 84\% of any normal
distribution is below \(\mu + \sigma\), and 84\% is above
\(\mu - \sigma\). Before we move on, draw out some normal distributions
to convince yourself that 97.5\% of any normal distribution is less than
\(\mu + 2\sigma\).\footnote{I generally keep a running tally of the
  number of normal distributions I draw on the board. Last time I did
  this, I was almost at 100. The moral: you should be drawing a lot of
  normal distributions!!!}

You should try the following calculations yourself, all of which can be
done with basic arithmetic and the 68-95-99.7 Rule:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Below \(\mu+2\sigma\) and above \(\mu-\sigma\).
\item
  Below \(\mu+2\sigma\) and above \(\mu+\sigma\).
\item
  Above \(\mu + 2\sigma\) and below \(\mu + 3\sigma\)
\item
  Above \(\mu - 3\sigma\) and below 0.
\end{enumerate}

\hypertarget{the-standard-normal-distribution}{%
\section{The Standard Normal
Distribution}\label{the-standard-normal-distribution}}

We use a special letter (Z, pronounced ``zed'' because we're Canadian)
to denote a standard normal distribution. In particular,
\(Z\sim N(0, 1)\) is a normal distribution with mean 0 and standard
deviation 1. Many many many many textbooks have a table in the back of
them that gives probabilities for the standard normal distribution, and
they call them \(Z\) tables.

All normal distributions have the exact same shape. In order to change
the mean and sd, we can simply re-write the numbers on the axes. If we
want to shift the whole curve to the left by 2 units, we can re-label
the numbers on the x axis. If we change the sd, the plot might get
``taller'' or ``shorter'', but if we zoom in on the plot we can make it
look exactly the same!\footnote{This is also the reason why the
  empirical rule works! If you change the labels on the plot,
  \(\mu+\sigma\) stays in the same place so you can calculate the same
  probability.}

\hypertarget{standardizing-a-normal-distribution}{%
\subsection{Standardizing a Normal
Distribution}\label{standardizing-a-normal-distribution}}

Because they all look the same, we might as well work with just one of
them! Suppose \(X\sim N(\mu,\sigma)\). If we shift the whole curve to
the left, then the mean shifts as well and the mean is 0. In other
words, \(X-\mu \sim N(0,\sigma)\). Now that the mean is at 0,
\(\mu + 1\sigma\) is simply \(\sigma\), \(\mu-3\sigma\) is \(-3\sigma\),
and so on. If we divide all of the numbers by \(\sigma\), then
\(\sigma\) is simply 1, \(-3\sigma\) is simply -3, and so on. To
formalize this, if \(x\sim N(\mu,\sigma)\), then

\begin{align*}
\frac{X-\mu}{\sigma} = Z \sim N(0, 1)
\end{align*}

This is called \textbf{standardizing} a normal distribution. The
resultant value is called the \textbf{z-score}.

For example, suppose a woman is 155.19 cm tall. If the true mean height
of Canadian women is 162.3 and the standard deviation is 7.11, then this
particular woman is exactly one standard deviation \emph{below} the
mean. This is the \textbf{z-score}, a.k.a. the standardized value; this
woman's z-score is -1.

Now consider a woman who is 161.22 cm tall. Her z-score would be
-0.152,\footnote{The negative is important!} meaning that she is 0.152
standard deviations below the mean.

Let's return to the 155.19 cm tall woman. If you take a woman at random
from the population, what is the probability that the randomly chosen
woman be be shorter than 155.19 cm? Based on the 68-95-99.7 rule, 68\%
of women are within one standard deviation of the mean, which is a range
from 155.19 to 169.41. Since 68\% of the women are betwen these two
numbers, 16\% of them are shorter than 155.19 (it is also true that 16\%
are taller than 169.41, but this was not required for the question).

Now, what's the probability that a randomly chosen woman is, say,
shorter than 160 cm? This doesn't fit nicely in the empirical rule, so
we need another way to calculate probabilities. However, it's worth
stopping and trying to make a guess! The empirical rule tells us that
16\% of women are below 155.19 cm, and we also know that 50\% of women
are shorter than the average of 162.3 cm (since the normal distribution
is symmetric), so we expect that the answer is somewhere between 16\%
and 50\%, probably closer to 50\% since 160 cm is closer to 162.3 cm
than it is to 155.19 cm.

\hypertarget{calculating-normal-probabilities---part-2}{%
\section{Calculating Normal Probabilities - Part
2}\label{calculating-normal-probabilities---part-2}}

In general, we use the \textbf{cumulative distribution function} (CDF,
or cdf) to calculate probabilities. As with the cumulative probability
tables we saw in the probability lectures, the cumulative probability
calculates the area to the \emph{left} of a particular point.\footnote{Recall
  that \(P(X=x) = 0\) in continuous distributions, so we look at ranges.}
Questions about the normal distribution generally come in three
flavours:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find \(P(X \le a)\)
\item
  Find \(P(X \ge b)\)
\item
  Find \(P(c \le X\le d)\)
\end{enumerate}

The \textbf{cdf} is defined as \(P(X\le x)\), which allows us to answer
questions like 1. For the standard normal distribution, a table of Z
probabilities can be found at the back of the textbook. I've added a
file that demonstrates how to use the Z-table in the Lecture Materials.
This is something that is crucial to know for closed-book tests since
you will need to caclulate probabilities somehow, but we can't let you
have a computer to run R! Before moving on, read ``\textbf{Intro to
Ztable.pdf}''.

In that file, there are some practice problems. Below, you'll find a
selection of solutions using R. For your own practice, try and calculate
them with the Z-table (with some good drawings) and verify your answer
with R.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 1. Find the probability of a z{-}value less than 1.11.}
\FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.11}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.8665005
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 2. Find the probability of a z{-}value greater than 1.11}
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.11}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1334995
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 3. Find the probability of a z{-}value greater than {-}2.01 but less than 1.}
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{2.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.8191292
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 4. Verify the empirical rule: 68{-}95{-}99.7}
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6826895
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9544997
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{3}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9973002
\end{verbatim}

For questions like \(P(X\ge x)\), we can simply use the fact that
\(P(X \ge x) = 1 - P(X<x)\). Since this is a continuous distribution and
\(P(X = x)=0\), we also know that \(P(X\le x) = P(X<x)\) and we can just
use the cdf. The last one is a little bit trickier.

To calculate the probability that a randomly chosen value will be within
a given range, there are a few steps. Let's use the same example as the
textbook: If \(X\sim N(-2, 1)\) find \(P(-2.5\le X\le -1)\). If we want
to use the cdf, we need to re-write this in terms of \(P(X\le x)\).

Here's how we do it. If we only find \(P(X\le-1)\), then we have taken
too much of the distribution. Everything to the left of -2.5 was
something that should not have been included. So why don't we just
remove it? By this logic, we can find
\(P(-2.5\le X \le -1) = P(X\le -1) - P(X \le -2.5)\). This is shown
graphically below:

\includegraphics{figs/addgraphs.jpg}

Returning to the heights example, the probability of a randomly chosen
woman being less than 160 cm can be calculated as: \[
\frac{x - \mu}{\sigma} = \frac{160 - 162.3}{7.11} = -0.323488045
\] We can now look up -0.323 with the pnorm function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.323488045}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3731628
\end{verbatim}

Note that R will do the standardization for you if you ask it politely.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\AttributeTok{q =} \DecValTok{160}\NormalTok{, }\AttributeTok{mean =} \FloatTok{162.3}\NormalTok{, }\AttributeTok{sd =} \FloatTok{7.11}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3731628
\end{verbatim}

I have created a shiny app that lets you explore these
calculations\footnote{If you're curious, yes I've made a lot of Shiny
  apps. You can find them all here:
  \url{https://github.com/DB7-CourseNotes/TeachingApps}}. Feel free to
use this to answer the questions in this lecture, and then double check
the answers with pnorm.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# install.packages("shiny") \# Run this if you get an error about "package not found"}
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DB7{-}CourseNotes/TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Tools/pnorm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{examples-3}{%
\subsection{Examples}\label{examples-3}}

\hypertarget{ex1-px-x}{%
\subsection{Ex1: P(X \textless{} x)}\label{ex1-px-x}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If X has a mean of 4 and a sd of 2, what's the probability of a value
  less than 0?

  \begin{itemize}
  \tightlist
  \item
    \textbf{Solution 1}: Standardize and Z-table. I'll split this up
    into steps:

    \begin{enumerate}
    \def\labelenumii{\arabic{enumii}.}
    \tightlist
    \item
      Standardize: \((x-\mu)/\sigma = (0 - 4)/2 = -2\).
    \item
      Find -2 on the Z table: -2=-2.00, so this will be in the row
      labelled -2.0 and the column labelled 0.00,\footnote{The rows are
        the digits before and after the decimal, the column is the
        second digit after the decimal.} which is 0.0228.
    \item
      Conclude: 2.28\% of the N(4,2) distribution is below 0.
    \end{enumerate}
  \item
    \textbf{Solution 2}: Empircal rule.

    \begin{itemize}
    \tightlist
    \item
      Before calculating a normal probability, try and estimate how many
      standard deviations away from the mean the value is. In this case,
      0 is 2 standard deviations from 4. The 68-95-99.7 rule states that
      95\% of the distribution is outside the range from
      \(\mu - 2\sigma\) to \(\mu + 2\sigma\), so 5\% is outside of this
      range. This means that 2.5\% is on either side, which means that
      2.5\% is below 0.
    \end{itemize}
  \end{itemize}
\end{enumerate}

A short version of Solution 2: By the 68-95-99.7 Rule, 95\% is between 0
and 8. Therefore, 2.5\% must be less than 0.

As you can see, the 68-95-99.7 rule is \emph{approximate}. However, I
highly recommend doing many practice problems with it. On a multiple
choice question, if you can figure out the answer with the Empirical
Rule than you might be able to guess the correct answer much quicker.
You won't get the exact answer, but if there's only one answer that's
close to your guess, then that's probably it.\footnote{You need to trust
  your ability to use the Empirical Rule, though.}

\textbf{Solution 3}: R.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Standardize:}
\FunctionTok{pnorm}\NormalTok{((}\DecValTok{0} \SpecialCharTok{{-}} \DecValTok{4}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.02275013
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Same answer, without standardizing:}
\FunctionTok{pnorm}\NormalTok{(}\AttributeTok{q =} \DecValTok{0}\NormalTok{, }\AttributeTok{mean =} \DecValTok{4}\NormalTok{, }\AttributeTok{sd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.02275013
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  If \(X\sim N(1234, 56)\), what's the probability of a number smaller
  than 1432.
\end{enumerate}

\emph{Before we begin:} What do we expect the number to be? The mean is
1234, which is smaller than 1432. Is it a little smaller, or is it a lot
smaller? Compared to the standard deviation, it's a lot smaller. By the
empirical rule, the vast majority of the distribution is below
\(\mu + 3\sigma\), which is approximately 1400.\footnote{Quick maths -
  we're just trying to get an okay guess, not the exact answer right
  now.} We should expect an answer close to 1, since the area under the
normal distribution is 1.

\textbf{Solution 1}: \((x-\mu)/\sigma = (1432-1234)/56 = 3.54\), which
is not on the Z table. When this happens (and we don't have access to
technology), we simply say the answer is 1.\footnote{If the z-score were
  -3.54, we'd say the probability is 0.}

\textbf{Solution 2}: The value we're interested in isn't 1, 2, or 3
standard deviations from the mean, so the Empirical Rule doesn't apply.
However, we can guess that our probability will be close to 1 since it's
larger than 3 standard deviations away.

\textbf{Solution 3}: R.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{1432}\NormalTok{, }\AttributeTok{mean =} \DecValTok{1234}\NormalTok{, }\AttributeTok{sd =} \DecValTok{56}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9997967
\end{verbatim}

Ideally, you would only ever use intuition from the Empirical rule, or
use R. The Z-table is super convenient for written, in-person exams.
It's also nice for situations where you don't have a computer with R
available.

\hypertarget{px-x}{%
\subsection{P(X \textgreater{} x)}\label{px-x}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  If X has a mean of 4 and a sd of 2, what's the probability of a value
  greater than 0?
\end{enumerate}

\emph{Before we start}: Use the empirical rule! 0 is 2sd below the mean,
so the answer should be close to 97.5\%

\textbf{With the Z table}: \((x-\mu)/\sigma = -2\), and we've already
found this on the table as 0.0228. Since we're looking at the
\textbf{right tail}, our answer is 1 - 0.0228 = 0.9772.

\textbf{With R}:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{0}\NormalTok{, }\AttributeTok{mean =} \DecValTok{4}\NormalTok{, }\AttributeTok{sd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9772499
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Suppose \(X\sim N(23, 23)\). What's the probability of a value larger
  than 23?
\end{enumerate}

\emph{Before we start}: The normal distribution is perfectly symmetric,
which we have learned means that the mean is equal to the median. The
median marks the point where 50\% of the distribution is smaller. So
before doing any work, we know that the answer must be 50\%

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{23}\NormalTok{, }\DecValTok{23}\NormalTok{, }\DecValTok{23}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5
\end{verbatim}

\hypertarget{pa-x-b}{%
\subsection{P(a \textless{} X \textless{} b)}\label{pa-x-b}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  If \(X\sim N(0, 1)\), what's the probability of a value between -1.52
  and -0.5?
\end{enumerate}

\textbf{Solution 1}: We have a standard normal value, so we can look
these values up directly. P(Z \textless{} -1.52) = 0.0643\footnote{Row
  labelled -1.5, column labelled 0.02.} and P(Z \textless{} -0.5) =
0.3085.\footnote{Verify this!} We want the area between these two
values. P(Z \textless{} -0.5) contains everything from negative infinity
to -0.5, but we only want values from -1.52 to -0.5. To fix this, we
remove everything from negative infinity to -1.52. Our answer is 0.3085
- 0.0643 = 0.2442.

\textbf{Solution 2}: R.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.52}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2442821
\end{verbatim}

I have made a shiny app for you to visualize this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DB7{-}CourseNotes/TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Tools/pnorm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  \(X \sim N(2,3)\), find \(P(-1 < X < 5)\)
\end{enumerate}

\emph{Before we begin:} This is the empirical rule for 1sd. The answer
is 68\%.

\emph{With a Z table}: We calculate the z-score individually, then
subtract the probabilities in a way that makes sense.\footnote{P(X
  \textless{} 5) - P(X \textless{} -1)}
\(P(X < -1) = P((X-\mu)/\sigma < (-1 - \mu)/\sigma) = P(Z < (-1 - 2)/3) = P(Z < -1) = 0.1587\).
Similarly, \(P(X < 5) = P(Z < 1) = 0.8413\). The answer is 0.8413 -
0.1587 = 0.6826, which is very close to what we got with the Empirical
Rule.

\emph{With R}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{5}\NormalTok{, }\AttributeTok{mean =} \DecValTok{2}\NormalTok{, }\AttributeTok{sd =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\AttributeTok{mean =} \DecValTok{2}\NormalTok{, }\AttributeTok{sd =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6826895
\end{verbatim}

\hypertarget{going-backwards}{%
\subsection{Going Backwards}\label{going-backwards}}

What's the first quartile of an N(2,3) distribution? It's the point at
which 25\% of the distribution is smaller. In other words, P(X
\textless{} Q1) = 0.25. How do we find Q1?

We can look up 0.25 as a probability. That is, as a value in the
\emph{body} of the Z table. This will give us the corresponding
z-score.\footnote{Recall: the body of the Z table are probabilities, the
  margins are z-scores.} Unfortunately, 0.25 isn't in the table. The
closest values are 0.2514 (which is a Z score of -0.67) and 0.2483 (Z
score of -0.68). On a test situation, -0.67 and -0.68 would both be
valid answers, as would -0.675.

In R, the ``\texttt{q}'' family of functions are the reverse lookup
functions. That is, You tell them the probability, and they return the
z-score.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.6744898
\end{verbatim}

However, we're not done yet! We found the quartile for a \emph{standard
normal} distribution. We have to go backwards in the standardization
formula. In essence, we have found Z and we need to find X.

\begin{align*}
\frac{x - \mu}{\sigma} = z \Leftrightarrow x = z\sigma + \mu
\end{align*}

To finish this question, we say that the first quartile of a N(2, 3)
distribution is -0.67*3 + 2 = -0.01.\footnote{-0.68*3 + 2 and -0.675*3 +
  2 would also be acceptable.}

In R:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\AttributeTok{mean =} \DecValTok{2}\NormalTok{, }\AttributeTok{sd =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.02346925
\end{verbatim}

\hypertarget{problems-verifying-the-empirical-rule}{%
\section{Problems: Verifying the Empirical
Rule}\label{problems-verifying-the-empirical-rule}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

68-95-99.7

\hypertarget{problems-z-scores}{%
\section{Problems: Z-scores}\label{problems-z-scores}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  \(P(z \le 2.25)\)
\item
  \(P(z \le -2.25)\)
\item
  \(P(z \ge 2.25)\)
\item
  \(P(z \ge -2.25)\)
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  \(P(-2 \le z \le 2)\)

  \begin{itemize}
  \tightlist
  \item
    \(P(Z \le 2\; and\; Z \ge -2)\)
  \end{itemize}
\item
  \(P(2 \le z \le -2)\)
\item
  \(P(0 \le z \le 2)\)
\item
  \(P(-2 \le z \le 0)\)
\item
  \(P(Z \ge 2\; or\; Z \le -2.5)\)
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{itemize}
\tightlist
\item
  \(P(Z \le z) = 0.5\)
\item
  \(P(Z \ge z) = 0.4238\)
\end{itemize}

What is \(z\)?

\hypertarget{problems-standardizing}{%
\section{Problems: Standardizing}\label{problems-standardizing}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

The birthweights of cute widdle babies born at full-term is
\(N(3350, 440)\).

\begin{itemize}
\tightlist
\item
  Low birthweight babies are those with a weight less than 2500.
  Probability of this?
\item
  High birthweight is above 4200. Probability?
\item
  Probability of either low or high?
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

A paper claimed that their control group was normal with a mean of 7
headaches per month, and the treatment group had a mean of 3.

The paper later claims that there's only a 10\% chance of seeing fewer
than 3 headaches in the control group.

The paper never provided the sd. What is it?

\hypertarget{participation}{%
\section{Participation}\label{participation}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(P(Z < 1.5)\)
\item
  \(P(Z > -1.5)\)
\item
  \(P(Z < 1.2 or Z > 1.3)\)
\item
  \(X\sim N(0,2)\), find \(P(X < 2)\)
\item
  \(X\sim N(\mu, 5)\) and \(P(X \le 2) = 0.25\), find \(\mu\)
\item
  \(X \sim N(2, 4)\). Find the IQR.
\end{enumerate}

\hypertarget{summary-2}{%
\section{Summary}\label{summary-2}}

\begin{itemize}
\tightlist
\item
  Most values are close to the mean, with fewer values as you get
  further away.
\item
  The mean and sd are sufficient to draw the whole curve.
\item
  Probabilities are areas. The area of a single point is 0.\footnote{P(X=x)
    = 0}
\item
  68\% is within one sd of the mean, 95\% within 2 sd, and 99.7\% within
  3 sd

  \begin{itemize}
  \tightlist
  \item
    \(P(\mu - 1\sigma \le X \le \mu + 1\sigma) \approx 0.68\).
  \item
    \(P(\mu - 2\sigma \le X \le \mu + 2\sigma) \approx 0.95\).
  \item
    \(P(\mu - 3\sigma \le X \le \mu + 3\sigma) \approx 0.997\).
  \end{itemize}
\item
  For standard normal, the values on the x axis are \textbf{z-score}.
\item
  The cdf, P(X \textless= x), is used to calculate areas.

  \begin{itemize}
  \tightlist
  \item
    The table can be found in the back of the textbook for standard
    normal. To standardize, use the formula \((x-\mu)/\sigma\).
  \item
    \texttt{pnorm(x,\ mean\ =\ 0,\ sd\ =\ 1)} gives the standard normal
    cdf. If mean and sd are not specified, \texttt{pnorm()} assumes you
    want standard normal.
  \end{itemize}
\item
  \(P(a \le X \le b) = P(X \le b) - P(X \le a)\)

  \begin{itemize}
  \tightlist
  \item
    Empirical rule: \texttt{pnorm(1)\ -\ pnorm(-1)};
    \texttt{pnorm(2)\ -\ pnorm(-2)}; \ldots{}
  \end{itemize}
\item
  You need a lot of practice with these kinds of problems. \emph{Do not
  check the answers prematurely.}
\item
  *\texttt{norm} functions:

  \begin{itemize}
  \tightlist
  \item
    \texttt{rnorm(n,\ mean,\ sd)} generates random numbers
  \item
    \texttt{dnorm(x,\ mean,\ sd)} gives the height of the curve at the
    point x. This is not a probability.
  \item
    \texttt{pnorm(q,\ mean,\ sd)} = \(P(X \le q)\).
  \item
    \texttt{qnorm(p,\ mean,\ sd)} finds \(q\) such that
    \(P(X \le q) = p\).

    \begin{itemize}
    \tightlist
    \item
      It is the backwards version (inverse function) of
      \texttt{pnorm()}.
    \item
      \texttt{pnorm(qnorm(0.5))} returns 0.5, \texttt{qnorm(pnorm(2))}
      returns 2.
    \end{itemize}
  \end{itemize}
\end{itemize}

\hypertarget{self-study-questions-1}{%
\section{Self-Study Questions}\label{self-study-questions-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each of the probability statements, draw the normal distribution
  and add shading for the probability. For example, P(Z \textgreater{}
  1) should be a normal distribution with everything under the curve and
  larger than 1 shaded in. This is a very good way to help internalize
  the fact that all probabilities are areas.
\item
  In P(Z \textless{} 1.32) = 0.9066, what do 1.32 and 0.9066 represent?
  Where are they on the Z table. If I were to give you one and not the
  other, could you find the missing number?
\item
  Write down all of the probability statements on a separate piece of
  paper. Solve them without looking at these notes. More practice, more
  better.
\item
  Picture two normal distributions: one looks taller, and one looks
  wider. Which one has the larger standard deviation?
\item
  Explain why the standard deviation does \emph{not} affect the shape of
  the normal distribution. Now, explain why it \emph{does} affect the
  shape.\footnote{Hint: Use the app with ``Sticky Axes'' checked and
    unchecked.}
\end{enumerate}

\hypertarget{more-questions}{%
\section{More Questions}\label{more-questions}}

If you have not calculated at least 50 or 60 different normal
probabilities by the midterm, you have probably not done enough
practice.

For each of these questions, start by trying to use the empirical rule,
then use the Z table, then confirm your answer with R. Answers with R
are shown below, but you should only check these once you're confident
with your own answer.\footnote{Pre-emptively checking the answer
  destroys any chance of learning and creates a false sense of
  knowledge.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X \sim N(0,2)\), what percent of the distribution is above 1?
\item
  \(X \sim N(0,2)\), what percent of the distribution is above 2?
\item
  \(X \sim N(0,2)\), what percent of the distribution is above 3?
\item
  \(X \sim N(-2, 500)\), find the 75\% quantile (aka Q3).
\item
  \(X \sim N(3.14, 15.9)\), what proporion of values are between 2.71
  and 8.28?
\item
  Suppose 25\% of a normal distribution is below 0, and the mean of this
  distribution is 1. What's the standard deviation?\footnote{Hint: Find
    the z-score for Q1, then fill out the standardization formula with
    the values you have.}
\item
  What to Expect claims that the average baby weighs about 7.5 lbs, with
  a ``normal''\footnote{Normal as in ``usual'', not as in the normal
    distribution.} range of 5.8 to 10 lbs. If the ``normal'' range is
  defined as the middle 95\%, what is the standard deviation of birth
  weights?
\item
  You're asked to estimate the number of M\&M's in family-sized bags.
  You're pretty sure that they are normally distributed and you think
  the mean is 600. How do you go about guessing the sd? One way is to
  say that you think it's ``unlikely'' that there are more than 650
  M\&Ms in any given bag.\footnote{This is actually a very useful way to
    think about distributions, especially in Bayesian statistics.}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    If ``unlikely'' = 10\%, that is, only 10\% of the bags have more
    than 650 M\&M's, what is the sd?
  \item
    If ``unlikely'' = 5\%, what is the sd?
  \end{enumerate}
\item
  In the population of Canadian women, what's the probability that a
  randomly selected woman is \emph{further than} 1.7 standard deviations
  from the mean?
\item
  There's a peculiar model that applies to certain kinds of data. If you
  have \(\mu = \sigma\), then the normal distribution has certain nice
  properties.\footnote{Sorry, the details are far beyond the scope of
    this course.} Suppose \(X\sim N(\theta, \theta)\), where \(\theta\)
  is just a stand-in for the mean and variance. If \(P(X < 8) = 0.2\),
  what is \(\theta\)?\footnote{This is one of the hardest questions you
    will encounter.}
\end{enumerate}

I'm going to say it again before you check the answers:
\textbf{Pre-emptively checking the answer destroys any chance of
learning and creates a false sense of knowledge.} You should spend time
struggling to convince yourself that you did it right. On an exam, you
won't have the answers so you'll feel that struggle. Practice the exam
struggle now, then you'll be more confident in your answer on exams.

Have you ever had that feeling that you knew the material because you
could do all of the practice problems, but when you get the exam you
forgot everything? \emph{That's because you checked the answers before
struggling.} You taught yourself to anticipate the answers of those
particular questions, rather than teaching yourself the material. The
struggling is where you learn. It's the same as exercise: no pain no
gain.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DocumentationTok{\#\# Questions 1, 2, and 3}
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3085375 0.1586553 0.0668072
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DocumentationTok{\#\# Q4}
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.75}\NormalTok{, }\AttributeTok{mean =} \SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\AttributeTok{sd =} \DecValTok{500}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 335.2449
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.75}\NormalTok{)}\SpecialCharTok{*}\DecValTok{500} \SpecialCharTok{{-}} \DecValTok{2} \CommentTok{\# Alternative, using standard normal}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 335.2449
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DocumentationTok{\#\# Q5.}
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\FunctionTok{pnorm}\NormalTok{(}\FloatTok{8.28}\NormalTok{, }\FloatTok{3.14}\NormalTok{, }\FloatTok{15.9}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FloatTok{3.14}\NormalTok{, }\FloatTok{3.14}\NormalTok{, }\FloatTok{15.9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1267548
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Alternative version, with standard normal}
\NormalTok{a }\OtherTok{\textless{}{-}}\NormalTok{ (}\FloatTok{3.14} \SpecialCharTok{{-}} \FloatTok{3.14}\NormalTok{)}\SpecialCharTok{/}\FloatTok{15.9}
\NormalTok{b }\OtherTok{\textless{}{-}}\NormalTok{ (}\FloatTok{8.28} \SpecialCharTok{{-}} \FloatTok{3.14}\NormalTok{)}\SpecialCharTok{/}\FloatTok{15.9}
\FunctionTok{pnorm}\NormalTok{(b) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(a) }\CommentTok{\# P(a \textless{} z \textless{} b) = P(Z \textless{} b) {-} P(Z \textless{} a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1267548
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DocumentationTok{\#\# Q6: x = z*sigma + mu =\textgreater{} sigma = (x{-}mu)/z}
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\NormalTok{(}\DecValTok{0} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.482602
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Verify that 0 is the first quartile}
\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\AttributeTok{mean =} \DecValTok{1}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ (}\DecValTok{0} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.25}\NormalTok{)) }\CommentTok{\# Good!}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DocumentationTok{\#\# Q7: empirical rule: 5.8 = mu {-} 2*sigma, so sigma = (7.5 {-} 5.8)/2}
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\NormalTok{(}\FloatTok{7.5} \SpecialCharTok{{-}} \FloatTok{5.8}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.85
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# However, if 10 = mu + 2*Sigma,}
\NormalTok{(}\DecValTok{10} \SpecialCharTok{{-}} \FloatTok{7.5}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# The normal distribution doesn\textquotesingle{}t work because this is a *skewed distribution*}

\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DocumentationTok{\#\# Q8.a) sigma = (x {-} mu)/z}
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\NormalTok{(}\DecValTok{650} \SpecialCharTok{{-}} \DecValTok{600}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 39.01521
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Verify:}
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{650}\NormalTok{, }\DecValTok{600}\NormalTok{, }\FloatTok{39.01521}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Q8b:}
\NormalTok{(}\DecValTok{650} \SpecialCharTok{{-}} \DecValTok{600}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 30.39784
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DocumentationTok{\#\# Q9: The "Canadian Women" part is irrelevant.}
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DocumentationTok{\#\# The area WITHIN the range is:}
\FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.7}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9108691
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# So the area outside this range is:}
\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ (}\FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.7}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.7}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.08913093
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Why is the "Canadian Women" part irrelevant?}
\DocumentationTok{\#\# The lower bound will be mu {-} 1.7*sd = 150.213. When we}
\DocumentationTok{\#\# standardize this, we get z = (x{-}mu)/sd = 1.7, so we\textquotesingle{}d use}
\DocumentationTok{\#\# 1.7 in the standard normal distribution}

\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DocumentationTok{\#\# Q10}
\DocumentationTok{\#\# \textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}\textasciitilde{}}
\DocumentationTok{\#\# P(X \textless{} 8) = 0.2, so let z = qnorm(0.2)}
\DocumentationTok{\#\# z = (x {-} mu)/sigma = (8 {-} theta)/theta}
\DocumentationTok{\#\# and therefore theta = 8/(z + 1)}
\DecValTok{8}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 50.51182
\end{verbatim}

\hypertarget{crowdsourced-questions-4}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-4}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A group of researchers studying Kane toads found that the length of
  the toads follow a normal distribution. They have a mean length of 20
  cm and a standard deviation of 2 cm. Using the 68-95-99.7 Rule, answer
  the following questions about the toad lengths:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    What percentage of Kane toads have a length between 18-22 cm?
  \item
    What percent of the toads have a length between 14-26 cm?
  \item
    What Percent of Kane toads have a length between 16-24 cm?
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  With a mean length of 20 cm and a standard deviation of 2 cm, the
  toads with a length between 18-22 cm fall within one standard
  deviation. Approximately 68\% of the toads have a length in this
  range.
\item
  99.7\% of the toads have a length that fall within 3 standard
  deviations, therefore, falling in the range of 14-26 cm.
\item
  Toads with a length of 16-24 cm, fall into 2 standard deviations,
  meaning 95\% of the toads fall into this range.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Let X represent the heights, in metres (m), of male basketball
  players. It is known that X follows a normal distribution with a mean
  () of 2.05 m and a standard deviation () of 0.1 m. Find the
  probability that a randomly selected male basketball player is at
  least 2.2 m tall.
\end{enumerate}

\textbf{Solution}

We want to find the probability of a randomly selected male basketball
player's height to be \textbf{at least} 2.2 m tall, which means we are
trying to find P(X \textgreater{} 2.2)

In order to find the probability, we are going to use the z-score
formula: \(Z = \frac{X - \mu}{\sigma} = (2.2 - 2.05) / 0.1 = 1.5\)

Find the probability using the z table:

\begin{itemize}
\tightlist
\item
  P(Z \textgreater{} 1.5) = 1 - P(Z \textless{} 1.5)

  \begin{itemize}
  \tightlist
  \item
    P(Z \textgreater{} 1.5) = 1 - 0.9332
  \item
    P(Z \textgreater{} 1.5) = 0.0668
  \end{itemize}
\end{itemize}

Therefore, there is a 6.68\% (or 0.0668) chance that a randomly selected
male basketball player is at least 2.2 m tall.

In R, this can be calculated without rounding:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0668072
\end{verbatim}

We can also let R do the standardization for us!

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FloatTok{2.2}\NormalTok{, }\AttributeTok{mean =} \FloatTok{2.05}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0668072
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{sampling-distributions}{%
\chapter{Sampling Distributions}\label{sampling-distributions}}

Please pay attention to the notes.\footnote{These things!} They often
contain important information.\footnote{Or silliness.}

\hypertarget{prelude-populations-and-samples}{%
\section{Prelude: Populations and
Samples}\label{prelude-populations-and-samples}}

The main idea in the rest of the course is this: We can use a sample to
say something about the population. Before we dive into that idea, let's
make a distinction.

\begin{itemize}
\tightlist
\item
  \textbf{Statistic:} A number that we calculate from data.
\item
  \textbf{Population parameter:} The value of a statistic if it were
  calculated for the whole population.
\item
  \textbf{Sample Statistic:} The value of a statistic if it were
  calculated for a single sample.
\end{itemize}

For example, we find the mean by taking all of the values and adding
them up, then dividing by the number of things we added. For heights of
Canadians, the population parameter is the value we would get if we
found every Canadians' height and added them up, then divided by the
population of Canada. We obviously can't do this, but it's useful to
think about. The sample mean is the mean we get when we just have a
sample. Since we can only get a sample, it would be super cool if we
could use that sample mean to talk about what values of the population
mean were reasonable guesses.

In the height example, the \textbf{population} was all Canadians. This
isn't always how we define the population! For example, if we wanted to
know the average length of pregnancy, we'd be looking at a population of
all people who get pregnant at some point in their lives.

\hypertarget{introduction-5}{%
\section{Introduction}\label{introduction-5}}

You take a sample. You find the \textbf{sample mean}. Is this mean
\emph{exactly} equal to the \textbf{population mean}?\footnote{Recall:
  \textbf{population} refers to the population of interest. The
  \textbf{population mean} is the true mean of the population.} Probably
not.

Wait, did I just say \emph{probably} not? How probably? We've done a few
lectures on probability, so we can probably describe the distribution
somehow. What is the probability that the sample mean is within one
standard deviation of the population mean? Two standard deviations?

Because of random sampling error,\footnote{In statistics, error does
  \emph{not} mean mistake.} every sample is going to have a different
mean. We expect most of the sample means to be close to the population
mean, with fewer samples resulting in sample means that are further
away. In other words, the \textbf{sample mean} should be close to the
\textbf{population mean}, but due to \textbf{sampling error} there will
be a little bit of a difference.

The variation within our sample should be similar to the variation
within the population\footnote{Assuming we have a \textbf{good} sample.},
and the variance in the population tells us the variance in the sample
means. Variation is not something to be afraid of, and sampling errors
are \emph{not} sampling \emph{mistakes}; we can harness the variability
within a sample to draw conclusions about the population!

\hypertarget{sampling-distribution-of-the-sample-mean}{%
\section{Sampling distribution of the sample
mean}\label{sampling-distribution-of-the-sample-mean}}

Because the value of a sample mean is random (since we took a random
sample), there's a probability distribution that describes it. I could
just jump to the answer, but it's best if I build up to it.

The app below\footnote{If you don't have access to R right now, try this
  one.} will take a random sample from the population (in this case,
normal), then find the mean and add it to a histogram. As you collect
more means, the histogram gets more and more data. This simulates taking
many many different samples.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2) }\CommentTok{\# if this fails, run install.packages("ggplot2")}
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DB7{-}CourseNotes/TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Tools/samplingDist"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Play around yourself! Start with \(n\) equal to 2 or 3. The sample shows
the individual values, but it also shows the sample mean. Notice how the
mean is usually closer to the population mean than any of the individual
sample values.

Now, take another sample! Again, the sample mean is closer to the
population mean than most of the sampled values. Take more samples. Take
1000 more samples. Notice how the distribution of sample means is
bell-shaped, but slightly skinnier than the population.

Repeat what you did above, but use n = 25 or so. The histogram of sample
means is even skinnier now! It's still centered on the population mean,
though!

These histograms are approximations to the \textbf{sampling distribution
of the sample mean.} If you take an infinite number of samples and
calculate the mean for each different sample, you'll get a distribution
of all possible sample means. This is what a \textbf{sampling
distribution} is. I'm going to repeat that, since this is often a very
difficult topic: the population distribution shows you the probability
distribution for all possible \emph{individuals}, while a sampling
distribution shows you the probability distribution for all possible
sample \emph{means}. Each sample has a different mean, the sampling
distribution describes many many samples.

\hypertarget{normal-populations}{%
\section{Normal Populations}\label{normal-populations}}

If the population is normal with mean \(\mu\) and standard deviation
\(\sigma\), then there is some relatively straightforward
math\footnote{You'll probably see it in the next stats course you take.}
to show that:

\[
\bar X \sim N\left(\mu, \frac{\sigma}{\sqrt{n}}\right)
\]

That is, the distribution of all possible sample means\footnote{i.e.~the
  sampling distribution of the sample mean} is normal with the same mean
as the population, but with a smaller standard deviation. Go back to the
app and see this for yourself.

\hypertarget{example-1}{%
\subsection{Example}\label{example-1}}

Suppose the population of heights of Canadian women is N(162.3,
7.11).\footnote{Note: these numbers actually come from a sample, and we
  don't know that the population is normal. We're making some massive
  assumptions here.} We're going to try and build up some intuition for
why the distribution of all means has a smaller variance than the
distribution of the population.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The probability that a randomly chosen woman is taller than 170 cm is
  \(P(X > 170)\) =
  \texttt{1\ -\ pnorm(q\ =\ 170,\ mean\ =\ 162.3,\ sd\ =\ 7.11)} =
  0.139. So there's about a 14\% chance of finding a woman taller than
  170 cm.
\item
  (This is just for example - this part is not often
  important.\footnote{You will not need to do something like this on a
    test.}) If we take a sample of n=2 women, what's the probability
  that \emph{both} of them are taller than 170cm? If it's a truly random
  sample, then the heights of the two women should be independent and we
  can just multiply their probabilities.\footnote{Remember the most
    important fact from probability: Multiplying probabilities only
    works when they're independent.} This means that there's
  approximately \(0.14*0.14 = 0.0193 = 1.93\%\) chance of this.
  Obviously, if one woman taller than 170 is unlikely, then both women
  taller than 170 is very unlikely.
\item
  If we take a sample of \(n=2\) women, what's the probability that
  their average height is larger than 170? From above, we know that the
  \textbf{distribution of the sample mean} is
  \(N(162.3, 7.11/\sqrt{2})\), so we can calculate this probability as
  \(P(\bar X > 170)\) =
  \texttt{1\ -\ pnorm(q\ =\ 170,\ mean\ =\ 162.3,\ sd\ =\ 7.11/sqrt(2))}
  = 0.06. This is somewhere in between \emph{just} one of them being
  taller than 170cm and \emph{both} of them being taller than 170.
\end{enumerate}

When we took a sample of 2 women, one might have been taller than 170
but one might have been shorter, so the average ends up being less than
170. The sample mean is \emph{less variable} than the individual values,
so it's less likely to be further away.\footnote{Take a moment and make
  sure you understand this relationship. Write out a description of it.
  Call a grandparent and try to explain it to them.}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Summary}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

If you take two values from a normal distribution, the average of those
two values is probably closer to the true mean than either of the
individual values. If you found the average of 100 observations from a
normal distribution, the mean of all of those means is probably even
closer to the true mean. If you took 200 observations, the mean of means
will be even closer!

\end{tcolorbox}

\hypertarget{non-normal-populations-with-large-sample-size}{%
\section{Non-Normal Populations with Large Sample
Size}\label{non-normal-populations-with-large-sample-size}}

In the previous example, we saw that a normal population distribution
will result in a distribution for all possible sample means that is also
normal, but with a smaller variance. If the population \emph{isn't}
normal, but you have a large enough sample size, the sampling
distribution is still normal. It's kind of amazing, but it seems to work
in practice!

The app below\footnote{Or the same app as before, with population set to
  Exponential.} will help you understand this relationship. I use an
``Exponential distribution'' for the population, but this isn't a
distribution you really need to worry about. All you need to know is
that the population \emph{clearly} isn't normal.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DB7{-}CourseNotes/TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Tools/nLarge"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Regardless of ``lambda''\footnote{Which controls how skewed the
  population distribution is.}, as n increase, the sampling distribution
becomes closer and closer to the normal distribution. By around n=30 or
40,\footnote{I will either ask you questions where n \textless{} 30
  (non-normal sampling distr.) or n \textgreater{} 50 (normal sampling
  distr.), nothing in between.} they're basically the same!\footnote{Although,
  in this case, the normal approximation is \textbf{biased}, but the
  bias decreases as n increases and you're not expected to know these
  details.}

Again,

\[
\text{If }X\sim N(\mu, \sigma)\text{ and n is ``large'', then }\bar X\sim N(\mu,\sigma/\sqrt{n})
\]

where 60 is definitely ``large'', 50 is probably ``large'', 30 is
debatably ``large'' (depending on what textbook you read), and anything
less than 30 is definitely small. I will not test you on the grey areas
here.

This result has a very special name:

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{The Central Limit Theorem}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

Given a simple random sample of size \(n\) (where \(n\) is ``large'')
from \emph{any} population with mean \(\mu\) and standard deviation
\(\sigma\), the sampling distribution of the sample mean will follow a
\(N(\mu, \sigma/\sqrt{n})\) distribution.

\end{tcolorbox}

For a perfectly normal population, this is true for any \(n\). For a
population that just a little bit not normal, \(n\) must be moderately
large. For a very not normal population (e.g.~Binomial with \(p\) far
from 0.5), we need \(n\) even larger. Still, as long as the sd of the
population is finite, the sampling distribution will be normal for
sufficiently large \(n\)!

\hypertarget{examples-4}{%
\subsection{Examples}\label{examples-4}}

\includegraphics{L10-Sampling_Distributions_files/figure-pdf/unnamed-chunk-4-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  The angle of big toe deformation in 38 patients.

  \begin{itemize}
  \tightlist
  \item
    There's an outlier, but the sampling distribution would still be
    normal even for relatively small \(n\).
  \end{itemize}
\item
  The number of servings of fruit per day for 74 adolescent girls.

  \begin{itemize}
  \tightlist
  \item
    The distribution is clearly (right or left???) skewed\footnote{Answer:
      right}. This makes sense - the number of fruits can only be as low
    as 0 and there may be many people who don't eat a lot of fruit, but
    there will be a few eating many fruits per day!
  \item
    The skewness of the data implies skewness in the population
    (assuming this is a good sample). No worries, though, the sampling
    distribution will still be normal! We just might need a larger
    sample size in future studies.
  \end{itemize}
\item
  The lengths of 56 perch from a Swedish lake.

  \begin{itemize}
  \tightlist
  \item
    This is clearly a bimodal distribution, indicating that there might
    be two subgroups in these data.
  \item
    The sampling distribution will still be normal (unimodal), but the
    mean of this sampling distribution will probably be somewhere in
    between the two peaks. In other words, it won't be describing either
    of the apparent subgroups! No amount of beautiful theorems will ever
    fix errors in sampling.
  \item
    In this case, we would want to find out why there are two subgroups
    before trying to say anything about the population distributions. If
    we actually have two types of fish, it's better to study them
    separately!
  \end{itemize}
\end{enumerate}

\hypertarget{non-normal-population-with-small-sample-size}{%
\subsection{Non-Normal Population with Small Sample
Size}\label{non-normal-population-with-small-sample-size}}

This is modelled with the \(t\)-distribution, which will be covered
later.

\hypertarget{very-non-normal-the-binomial-distribution}{%
\section{Very Non-Normal: The Binomial
Distribution}\label{very-non-normal-the-binomial-distribution}}

Here's some mild deja-vu:

You roll a dice. You find the \textbf{sample proportion} of heads,
denoted \(\hat p\).\footnote{i.e.~\(\hat p\) = number of success divided
  by number of trials.} Is this proportion \emph{exactly} equal to the
\textbf{population proportion}? Probably not.

Wait, did I just say \emph{probably} not? How probably? What is the
probability that the sample proportion is within one standard deviation
of the population proportion? Yeah, we're back on this again.

\hypertarget{aside-the-normal-approximation-to-binomial}{%
\subsection{Aside: The normal approximation to
Binomial}\label{aside-the-normal-approximation-to-binomial}}

Most textbooks provide the rule: if \emph{both} np and n(1-p) are larger
than 10\footnote{Or sometimes 15. Again, I won't test you on the grey
  areas.}, then the normal distribution is a good approximation to the
binomial distribution. I prefer to let you see whether these rules make
sense. The app below lets you change n and p, and shows a \(B(n, p)\)
and an \(N(np, \sqrt{np(1-p)})\)\footnote{Recall that the mean and sd of
  a Binomial distribution are np and np(1-p), respectively.}
distribution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DB7{-}CourseNotes/TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Apps/normBinom"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Set n = 20 and find p such that np \textless{} 10. Also find p such that
n(1-p) \textless{} 10. What is the shape of the Binomial distribution in
these cases? What do you notice about the normal distribution? Why do
both np and n(1-p) need to be greater than 10?\footnote{Answers: Skewed;
  positive probability below 0 or above n; symmetric.}

\hypertarget{binomial-more-like-binormial}{%
\subsection{\texorpdfstring{Binomial? More like
Bi\emph{norm}ial!}{Binomial? More like Binormial!}}\label{binomial-more-like-binormial}}

It turns out that, with large \(n\) the sampling distribution of \(p\)
also follows a normal distribution!\footnote{Again, we use the rule of
  thumb that \(np>10\) and \(n(1-p)>10\).} Even though the population
distribution isn't even continuous,\footnote{This is important.} the
normal distribution approximates it well when there are lots of samples.

For each sample, the actual proportion that you calculate is variable.
You might get 3 heads out of 10 flips one time, then 8 heads out of 10
flips the next. On average, though, you'll get 5 heads out of 10 flips.
Formally, the mean of the sampling distribution of the sample proportion
is \(p\).\footnote{Not n*p, since the proportion of heads is x/n.}

The variance is a little trickier. In the Binomial lecture notes, I said
that the variance increases as n increases. However, when we calculate
the proportion, we take the number of successes divided by n.~According
to some math that is not important for this course, this leads to a
\textbf{variance of the sampling distribution of the sample proportion}
of p(1-p)/n, which means that the \textbf{standard deviation}\footnote{Which
  is simply the square root of the variance.} \textbf{of the sampling
distribution} is \(\sqrt{p(1-p)/n}\).

To recap: The variance of a Binomial distribution is \(np(1-p)\). If we
take repeated samples from that Binomial distribution and calculate the
proportion of sucesses, the variance will be \(p(1-p)/n\).\footnote{Notice
  how they're equal when n = 1. When n=1, we're just taking individuals
  from the population and calling each individual a sample.}

\hypertarget{example-2}{%
\subsection{Example}\label{example-2}}

Suppose I'm rolling a dice 5 times. The probability of exactly 1 one is
defined by the Binomial distribution:
\texttt{dbinom(1,\ size\ =\ 5,\ prob\ =\ 1/6)} = 0.4.\footnote{In other
  words, 1 successes in 5 trials, where a success is defined as
  ``rolling a one''.} The number of ones we expect after rolling many
many dice is \(np = 5/6 =0.8333\). The variance in the number of ones in
5 rolls is \(np(1 - p) = 25/36 = 0.69444\), meaning the standard
deviation of the number of ones in 5 rolls is
\(\sqrt{np(1-p)} = \sqrt{5/36}\).

Let's use R to roll some dice for us!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Rolling 1 dice}
\CommentTok{\# The "r" version of functions givexs random values}
\CommentTok{\# Not on midterm}
\FunctionTok{rbinom}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{, }\AttributeTok{size =} \DecValTok{5}\NormalTok{, }\AttributeTok{prob =} \DecValTok{1}\SpecialCharTok{/}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Rolling 1000 dice}
\CommentTok{\# Not on midterm}
\NormalTok{dice\_1000 }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\AttributeTok{n =} \DecValTok{1000}\NormalTok{, }\AttributeTok{size =} \DecValTok{5}\NormalTok{, }\AttributeTok{prob =} \DecValTok{1}\SpecialCharTok{/}\DecValTok{6}\NormalTok{)}
\FunctionTok{mean}\NormalTok{(dice\_1000) }\CommentTok{\# We expect this to be 0.8333}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.834
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(dice\_1000) }\CommentTok{\# We expect this to be 0.69444}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7111552
\end{verbatim}

The results match! For 1000 rolls of the dice, we got close an average
of 0.833 ones per sample (note that this is the number of ones, not a
probability). The variance in the number of ones per roll for 1000 is
close to the 0.69444 that we expected.

This is the sampling distribution for the \emph{number} of 1s out of
five rolls. However, we generall deal with the \emph{probability} of a 1
out of 5 rolls.

\hypertarget{exampling-distribution}{%
\subsection{Exampling Distribution}\label{exampling-distribution}}

The following code is not testable - you are \emph{not} expected to
write anything like this. I'm taking repeated samples from a B(75, 0.4)
distribution and calculating the proportion of successes for each
sample.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{4}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{75}
\NormalTok{p }\OtherTok{\textless{}{-}} \FloatTok{0.4}

\NormalTok{binom\_proportions }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{() }\CommentTok{\# empty vector, to be filled later}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{1000}\NormalTok{)\{ }\CommentTok{\# repeat this 1000 times:}
    \CommentTok{\# This is confusing: I\textquotesingle{}m getting *one* sample of size n,}
    \CommentTok{\# but R labels the number of samples as n}
\NormalTok{    new\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\AttributeTok{n =} \DecValTok{1}\NormalTok{, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{prob =}\NormalTok{ p)}
    
    \CommentTok{\# Add the proportion of successes to the vector}
\NormalTok{    binom\_proportions[i] }\OtherTok{\textless{}{-}}\NormalTok{ new\_sample}\SpecialCharTok{/}\NormalTok{n}
\NormalTok{\}}

\FunctionTok{hist}\NormalTok{(binom\_proportions, }
    \AttributeTok{breaks =} \DecValTok{13}\NormalTok{, }\CommentTok{\# what happens if you make this larger?}
    \AttributeTok{freq =} \ConstantTok{FALSE}\NormalTok{) }\CommentTok{\# Divide the heights of bars by the number of obs.}
\FunctionTok{curve}\NormalTok{(}\FunctionTok{dnorm}\NormalTok{(x, }\AttributeTok{mean =}\NormalTok{ p, }\AttributeTok{sd =} \FunctionTok{sqrt}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{/}\NormalTok{n)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{col =} \DecValTok{3}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L10-Sampling_Distributions_files/figure-pdf/unnamed-chunk-8-1.pdf}

}

\end{figure}

Copy and paste the code above into a script file and observe what
happens when you increase the number of breaks. Why does this
happen?\footnote{Hint: What are the possible values of \(\hat p\)?}

Each sample has a 40\% chance to be a success, and this is indeed shown
in the sampling distribution. However, due to random sampling, we can
get sample proprtions as low as 0.25 and has high as 0.55! Because of
randomness, we'll \emph{very} rarely (if ever) get a sample value that
perfectly matches the population value.

The lesson is this: Even if the true population proportion is 0.4, a
sample value of, say, 0.5 is still consistent with the true proportion.
This is analogous to saying that the true population mean is 162.3, but
our random sample had a mean of 165. The sample value is different from
the population value, but still close enough (\textbf{releative to the
variance}) to be reasonable.

\hypertarget{conclusion-statistics-is-the-study-of-variance}{%
\section{Conclusion: Statistics is the Study of
Variance}\label{conclusion-statistics-is-the-study-of-variance}}

In both of the sampling distributions above, the mean of the sampling
distribution was the mean of the population. The difference between the
population and the sampling distribution is the \textbf{variance}. In
both sampling distributions, the variance \emph{decreases} as n
\emph{increases}. If you sample the entire population every time you do
a sample, there will be no variance in your estimate!

\hypertarget{self-study-questions-2}{%
\section{Self-Study Questions}\label{self-study-questions-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  When do we use \(N(\mu, \sigma/\sqrt{n})\) versus \(N(\mu, \sigma)\)?
  When do we use \(N(p, \sqrt{p(1-p)/n})\) versus
  \(N(np, \sqrt{np(1-p)})\)? This distinction is extremely important.
\item
  If the population is \(N(2,4)\) and we take a sample of size 10,
  explain why \(\frac{\bar X - 2}{4/\sqrt{10}}\) follows a standard
  normal distribution. This is extremely important.
\item
  What does it mean for the sample mean to be the same as the population
  mean? Will they be the same every time you take a sample?
\item
  Play around with the ``normBinom'' app shown above. Why is the normal
  distribution not appropriate when np\textless10 \emph{or}
  n(1-p)\textless10?
\item
  In the ``Histogram of binom\_proportions'', what happens when you
  increase the number of breaks? What causes this phenomenon?
\end{enumerate}

\hypertarget{exercises-2}{%
\section{Exercises}\label{exercises-2}}

For these questions, suppose we know that Candian womens' heights are
normal with a mean of 163cm and a standard deviation of 7cm

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What's the probability of an individual woman, randomly sampled from
  the population, being taller than 170 cm?
\item
  What's the probability that the \emph{sample mean} is larger than
  170cm if:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    \(n = 9\)
  \item
    \(n = 16\)
  \item
    \(n = 25\)
  \end{enumerate}
\item
  What do you notice about the probabilities in question 2?
\item
  Given heights are Normal with a mean of 163 and a standard deviation
  of 7, what sample size do we need to ensure that 95\% of potential
  sample means are within 2cm of the population mean (that is, 2cm on
  either side of the mean)?
\end{enumerate}

\textbf{Answer to Questions 1 and 2}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Question 1}
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{170}\NormalTok{, }\AttributeTok{mean =} \DecValTok{163}\NormalTok{, }\AttributeTok{sd =} \DecValTok{7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1586553
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Alternate solution:}
\CommentTok{\# Find the Z{-}score:}
\NormalTok{(}\DecValTok{170} \SpecialCharTok{{-}} \DecValTok{163}\NormalTok{) }\SpecialCharTok{/} \DecValTok{7} 
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# A z{-}score of 1 means that 170 is 1 sd away from the mean}
\CommentTok{\# Probability of being more than 1sd above the mean:}
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{1}\NormalTok{) }\CommentTok{\# Can also use the z{-}table for pnorm(1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1586553
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Question 2}
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{170}\NormalTok{, }\AttributeTok{mean =} \DecValTok{163}\NormalTok{, }\AttributeTok{sd =} \DecValTok{7}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{9}\NormalTok{)) }\CommentTok{\# (a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.001349898
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{170}\NormalTok{, }\AttributeTok{mean =} \DecValTok{163}\NormalTok{, }\AttributeTok{sd =} \DecValTok{7}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{16}\NormalTok{)) }\CommentTok{\# (b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.167124e-05
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{170}\NormalTok{, }\AttributeTok{mean =} \DecValTok{163}\NormalTok{, }\AttributeTok{sd =} \DecValTok{7}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{25}\NormalTok{)) }\CommentTok{\#(c)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.866516e-07
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Solution to Question 3}

As the sample size increases, the variance decreases (since we're
dividing by the square root of \(n\)). This means that values further
away from the mean are less and less likely.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Solution to Question 4}

We know that the middle 95\% of any normal distribution is within 2
standard deviations of its mean. Because of this, we need 2cm to be
equal to 2 standard deviations of the sampling distribution. (Well,
technically, it should be \texttt{-qnorm((1\ -\ 0.95)/2)\ =\ 1.96}.)

We know that the sample mean will have a normal distribution with a mean
of \(\mu\) and a standard deviation of \(\sigma/\sqrt{n}\), so we're
using \(\sigma/\sqrt{n}\) as the standard deviation. Because we don't
have the sample size, we don't have a value to put into \texttt{qnorm()}
and we'll need to do some math ourselves.

The two paragraphs above tell us that 2cm is equal to 1.96 standard
deviations, and the standard deviation of the sampling distribution (the
\textbf{standard error}) is \(7/\sqrt{n}\). Setting these equal, we get
\(2 = 1.96 *7/\sqrt{n}\) which means \(n = (1.96 * 7/2)^2 = 47.0596\).

We're not done yet! We can't sample 47.0596 people! We want to be
\emph{within} two standard deviations of the mean, so we want to make
sure that when we round, we don't go above 2cm. Since the variance of
the sampling ditribution decreases as \(n\) increase, the confidence
interval is smaller when \(n\) is larger. Because of this, we always
want to round \textbf{up}. Even if our answer came to 12.0001, we would
round up to 48 to get our final answer.

A short version of this solution: Using R or the normal table, the
middle 95\% is within 1.96 standard deviations of the mean. Since we're
dealing with a sampling distribution, the standard deviation is
\(7/\sqrt{n}\). Setting these two numbers equal, we get
\(2 = 1.967/\sqrt{n}\) and we solve for \(n\). We round up, because we
want our interval to be less than 2cm on either side and because a
larger sample has lower variance.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{crowdsourced-questions-5}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-5}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What factor primarily contributes to the sampling distribution having
  a lower variance than the population distribution?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    reduction in standard deviation within the sample
  \item
    the wider range of possible values in the population
  \item
    utilization of a different statistical methodology for sampling
  \item
    summarization of multiple observations into a single value during
    sampling
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  is the correct answer. When creating a sampling distribution, multiple
  samples from a population are taken to create a statistic for each
  sample. As more samples are taken, the statistic will represent the
  true population parameter better. Essentially, as more values are
  summarized into one, there is a reduced variability in the sampling
  distribution compared to the population.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Let X represent the heights, in metres, of white birch trees in
  Saskatchewan. Given that it follows a normal distribution with a mean
  of 8 and a standard deviation of 5, the heights of a randomly selected
  group of n=6 trees are measured. Find the probability that the sample
  mean tree height is at most 10 m.
\end{enumerate}

\textbf{Solution}

First, let's label all of the information we have been provided:

\begin{itemize}
\tightlist
\item
  sample size: \(n = 6\)
\item
  population mean: \(\mu = 8\)
\item
  population stdev: \(\sigma = 5\)
\end{itemize}

Since there is a sample size of 6 trees, the mean of the sampling
distribution will still remain 8 but the standard deviation of the
sampling distribution is \(\sigma/\sqrt{n} = 5 / \sqrt{6} = 2.04\)

Since the height can be a maximum of 10m, we are trying to find
P(\(\bar x\) \textless{} 10). We can find this by standardizing and
using the z-table:

P(x6 \textless{} 10) = P(Zx6 \textless{} (10-8) / 2.04) = P(Zx6
\textless{} 0.98) = 0.8365

Therefore, in a sample of 6 trees, there is a 83.65\% (or 0.8365) chance
that a silver birch tree in Saskatchewan is at most 10 m tall.

In R:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \DecValTok{8}\NormalTok{, }\AttributeTok{sd =} \DecValTok{5} \SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.8364066
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\part{Post-Midterm}

\hypertarget{welcome-to-inference}{%
\chapter{Welcome to Inference!}\label{welcome-to-inference}}

Please pay attention to the margin notes.\footnote{These things!} They
often contain important information.\footnote{Or silliness.}

\hypertarget{inference-basics}{%
\section{Inference Basics}\label{inference-basics}}

\hypertarget{probability-vs.-inference}{%
\subsection{Probability vs.~Inference}\label{probability-vs.-inference}}

In probability, we have distributions and calculate how likely given
values are. In inference, we have a value that came from a distribution
and try to determine things about that distribution.

Recall: Sampling Distributions

\begin{itemize}
\tightlist
\item
  If the population is \(N(\mu,\sigma)\), the sampling distribution of
  the sample mean is \(\bar X\sim N(\mu,\sigma/\sqrt{n})\).
\item
  Assuming an SRS, 95\% of sample means should be within
  2\(\sigma/\sqrt{n}\) of the population mean.\footnote{This is using
    the empirical rule - the actual value is closer to 1.96.}
\end{itemize}

\hypertarget{one-last-silly-example}{%
\subsection{One Last Silly Example}\label{one-last-silly-example}}

Suppose the average heart rate of a population is 70bpm, with a standard
deviation of 5bpm. What's the probability of getting a mean heart rate
that's further than 4bpm away from the mean when using samples of size
9?

Let's solve this the same way as before, just for some practice. A
population standard deviation of 7 and a sample size of 9 means the
standard deviation of the sampling distribution - also known as the
\textbf{standard error}, is \(7/\sqrt{9}\) = 2.33.

We're looking for values below 66bpm or above 74bpm in the
\emph{sampling distribution}. Since we know the normal distribution is
symmetric, we can just find the probability of a heart rate below
66\footnote{We prefer problems with \(\le\) in them.} and then double
it.

Solution 1: We can find the z-score as
\((x-\mu)/\sigma = (70-66)/2.33 \approx -1.71\)\footnote{Note that we're
  using the standard error, so we divide by the square root of the
  sample size.}, then we can calculate the probability of a Z value less
than -3. In R\footnote{You're also welcome to try this with the Z-table,
  but R will be used on exams.}, this is \texttt{pnorm(-1.71)} = 0.046.
Doubling this, there is a 8.72 percent chance of a heart rate below
66bpm.

Solution 2: Let's jump straight to R. We know we're looking for
\(2*P(\bar X \le 66)\) where \(X\sim N(70, 7/\sqrt{9})\), and this can
be plugged in directly:
\texttt{2\ *\ pnorm(66,\ mean\ =\ 70,\ sd\ =\ 7/sqrt(9))} = 0.0865, or
an 8.65\%\footnote{This differs from our previous answer due to rounding
  - R is always more accurate than rounding yourself and using the
  Z-table!}

\hypertarget{flippin-it-confidence-intervals}{%
\subsection{Flippin' it: Confidence
intervals}\label{flippin-it-confidence-intervals}}

Let's flip this on it's head. Suppose you have a sample and calculate
the mean and standard deviation. Let's say you're looking at the average
heart rate of people who have started a treatment for heart issues. We
want their heart rates to go to 70bpm but our sample mean is 77bpm with
a standard deviation across patients of 5bpm. Is it reasonable to say
that this mean came from a population centered at 70bpm? In other words,
there's a difference between 70 and 77, but is the variance high enough
that this difference is simply due to random variation?

Instead of asking ``Using known population parameters, what's the
probability that a sample mean is further than 2\(\sigma\) away?'', we
can ask ``If your sample mean is further than 2\(\sigma\) from a
proposed population mean, is it reasonable to say that our sample came
from that particular population?''

Notice the subtle shift - we're now talking about something that we can
do with \emph{just a sample}. The Sampling Distributions section always
assumed that the population mean was known and told us about potential
sample means. We're now shifting our perspective: given a sample mean,
what are the potential population values?

The basic idea in this lecture is as follows: the sample should be
similar to the population but a little bit off. What are the potential
values of the population mean that are compatible with what we observed?

\hypertarget{confidence-intervals}{%
\section{Confidence Intervals}\label{confidence-intervals}}

\hypertarget{background}{%
\subsection{Background}\label{background}}

Given data, we want to make an \textbf{inference} about the population.
Since \(P(\bar X = \mu) = 0\), we can't just calculate the probability
that we have the correct population mean. It's always going to be 0!

However, we can make guesses based on ranges! With confidence intervals,
we create a range around our estimate that (hopefully) contains the true
population mean. It won't contain the true mean every time, but if we do
things right, we can quantify our \textbf{confidence} that it does.

All CI's that we learn in this class have the form\footnote{Note that
  there are many other kinds of confidence intervals beyond this class!
  We're just going to stick to these ones.}: \[
\text{Estimate} \pm \text{Margin of Error}
\]

\hypertarget{the-margin-of-error-moe}{%
\subsection{The Margin of Error (MoE)}\label{the-margin-of-error-moe}}

If the population is normal with mean \(\mu\) and sd \(\sigma\), then
the \textbf{Margin of Error} is

\[
MoE = (z^*)*(\sigma/\sqrt{n}) = \text{Critical Value}*\text{Standard Error}
\]

\begin{itemize}
\tightlist
\item
  \(z^*\) is a \textbf{critical value}. This is where we get our
  ``confidence'' from. This value is \emph{always positive}.
\item
  \(\sigma/\sqrt{n}\) is the standard deviation of the sampling
  distribution, which is also called the \textbf{Standard Error}.
\end{itemize}

\hypertarget{critical-values}{%
\subsection{Critical Values}\label{critical-values}}

If \(z^* = \infty\), it means that the confidence interval is infinitely
wide. That is, we're 100\% confident that the true population mean is in
the interval!

If \(z^* = 0\), it means the CI is just the \textbf{point estimate}. In
other words, we're 0\% confident.

Usually, we choose a confidence level in between 0 and 100. Values of
90\%, 95\%, or 97.5\% are common. These values strike a nice balance
between being useful and being less than infinity.

\hypertarget{calculating-critical-values-0.95}{%
\subsection{Calculating critical values:
0.95\%}\label{calculating-critical-values-0.95}}

If \(X\sim N(\mu, \sigma)\), then the sampling distribution is
\(\bar X\sim N(\mu,\sigma/\sqrt{n})\).

To make a confidence interval, we want a range of values \((L, U)\) such
that \(P(L < \bar X < U) = 0.95\).

The normal distribution is symmetric. If we want 95\% in the middle,
then we need 0.025 below L and 0.025 above U. This is equivalent to
values such that \(P(\bar X < L) = 0.025\) and
\(P(\bar X < U) = 0.975\).

We can find a \(z^*\) value such that \(P(Z < -z^*) = 0.025\), then use
the formula \(x = z\sigma+\mu\). However, since we're using \(\bar X\)
instead (which has a standard deviation of
\(\sigma/\sqrt{n}\)\footnote{the \textbf{standard error}} instead of
\(\sigma\)), this is \(\bar x = z^*\sigma/\sqrt{n} + \mu\).

We can do the same with \(P(Z < z^*) = 0.975\) and find
\(\bar x = z^*\sigma/\sqrt n + \mu\).

\hypertarget{what-is-z}{%
\subsection{\texorpdfstring{What is
\(z^*\)?}{What is z\^{}*?}}\label{what-is-z}}

For \(P(\bar X < L) = 0.025\), \(-z^* = -1.96\) (almost -2).

For \(P(\bar X < U) = 0.975\), \(z^* = 1.96\) (almost 2).

In other words, it's symmetric!

\hypertarget{building-a-confidence-interval}{%
\subsection{Building a Confidence
Interval}\label{building-a-confidence-interval}}

A Confidence Interval is an interval of ``reasonable'' values for the
population mean based on what we got in a sample. In other words, it's a
collection of values for \(\mu\) that are within 2 standard deviations
of the sampling distribution, but using the estimated value of the mean.

For simplicity, we're still going to use the population standard
deviation to construct this interval. The sample standard deviation will
be used later, but it adds a level of complexity that we're going to
ignore for now.

For the standard normal distribution, 95\% of the distribution is in the
interval (-1.96, 1.96)\footnote{This is standard notation for intervals:
  (lower bound, upper bound).}. Instead of standardizing (calculating
the Z-score), we're going backwards from a Z score to the distribution
of \(\bar X\).

We use the Z-score formula \(Z = \frac{\bar X-\mu}{\sigma/sqrt{n}}\),
which uses \(\sigma/\sqrt{n}\) instead of \(\sigma\) because
\(\sigma/\sqrt{n}\) is the standard deviation of the distribution of
\(\bar X\)\footnote{To be clear, the formula is the exact same: it's
  (value - mean)/standard deviation, we just need the right values for
  the mean and standard deviation!}.

The lower bound for the interval for \(Z\) is -1.96. To un-standardize
this, we can rearrange the formula and get
\(\bar x = z\sigma/\sqrt{n} + \mu\). However, we're actually interested
in \(\mu\)! Our formula for the lower bound is
\(\mu = \bar x-1.96\sigma/\sqrt{n}\). By a similar argument, we can find
that the upper bound is \(\mu = \bar x + 1.96\sigma/\sqrt{n}\).

For any value of \(z^*\), the two ends of the interval can be written in
one expression: \[
\bar x\pm z^*\sigma/\sqrt{n}
\]

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Confidence Interval for the Population Mean}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

The confidence interval is defined as:

\[
\text{all values of } \mu \text{ that are in the range } \bar x \pm z^*\sigma/\sqrt{n}
\]

This is the middle 95\% of the sampling distribution \emph{if it were
centered at the sample mean.} It gives a range of population means that
could reasonably have resulted in our observed sample mean.

\end{tcolorbox}

\hypertarget{some-notation-alpha}{%
\subsection{\texorpdfstring{Some notation:
\(\alpha\)}{Some notation: \textbackslash alpha}}\label{some-notation-alpha}}

A \((1-\alpha)\%\)CI is is defined as \[
\bar x \pm z^*\sigma/\sqrt{n}
\]

where \(P(Z < z^*) = \alpha/2\).\newline

\begin{itemize}
\tightlist
\item
  For a 95\%CI, \(\alpha = 0.05\) and \(\alpha/2= 0.025\).

  \begin{itemize}
  \tightlist
  \item
    \(z^*\) is found by finding the value such that
    \(P(Z < z^*) = 0.025\).
  \item
    \texttt{qnorm(0.025)} = -1.96, so \(z^* = 1.96\).
  \end{itemize}
\item
  For a 89\%CI, \(\alpha = 0.11\) and \(\alpha/2 = 0.055\).

  \begin{itemize}
  \tightlist
  \item
    \texttt{qnorm(0.055)} = -1.56, so \(z^* = 1.6\).
  \end{itemize}
\end{itemize}

\hypertarget{example-3}{%
\subsection{Example}\label{example-3}}

For the heart rates example, suppose we got a sample mean of
\(\bar x = 77\) in a sample with 9 participants. Further suppose that we
know from a previous study that the standard deviation of heart rates is
7bpm. Construct a 95\% CI for the population mean.

To do this, we must calculate \(\bar x \pm z^*\sigma/\sqrt{n}\). Let's
gather the values we need.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\bar x\) and \(\sigma\) are given.
\item
  \(\sqrt{n} = \sqrt{9} = 3\).
\item
  The critical value defines the two values on a standard normal curve
  such that 95\% is in the middle. In other words, we need 2.5\% below
  \(-z^*\) and 2.5\% above \(z^*\). It's easiest to calculate
  probabilities of the form \(P(Z\le z^*) = 0.025\), so we'll go with
  that.

  \begin{itemize}
  \tightlist
  \item
    Since we hav \(P(Z\le q) = p\) and we're given \(p\), we use the
    \texttt{qnorm()} function\footnote{You could also find the closest
      thing to 0.025 in the body Z-table, if that's easier for you - but
      be careful that you're looking at the body rather than the
      margins!}. \texttt{qnorm(0.025)} = -1.96, so \(z^*=1.96\).
  \end{itemize}
\end{enumerate}

All together, this means our 95\%CI is: \[
\bar x \pm z^*\sigma/\sqrt{n} = 77 \pm 1.96 * 7/\sqrt{9}
\] Using R as a fancy calculator, we get a 95\% CI of (72.43, 81.57).

Let's take a moment to consider what this means.

\begin{itemize}
\tightlist
\item
  If \(\bar x\) were the true center of the sampling distribution, then
  the middle 95\% would be between 72.43 and 81.57.

  \begin{itemize}
  \tightlist
  \item
    In terms of our empirical rule, 72.43 to 81.57 is within two
    standard \textbf{errors} of the mean. Again, we're using standard
    errors because this is a sampling distribution, i.e.~the sd of the
    means is the population sd divided by the square root of \(n\).
  \end{itemize}
\item
  We defined the CI as ``all reasonable proposed values of \(\mu\)''. In
  our original question, we were inquring about whether 70bpm is a
  reasonable population mean. According to this CI, it is not.
\item
  If we had used a different confidence level, we would have had a
  different CI. Try this example again to get the following results:

  \begin{itemize}
  \tightlist
  \item
    A 90\% CI is (73.16201, 80.83799)\footnote{I used R with no rounding
      for these - it's fine if your values are slightly off. Rounding
      errors will not be distractors on the exam.}
  \item
    An 89\%\footnote{Why do I use 89 in so many examples? The 95\% CI is
      standard, but 95 is also chosen completely arbitrarily. Some
      authors have argued that 89\% is less affected by outliers, and if
      we're going with an arbitrary number then it might as well be a
      prime number!} CI is (73.27088, 80.72912)
  \item
    An 85\% CI is (73.64109, 80.35891)
  \item
    An 80\% CI is (74.00971, 79.99029)
  \item
    A 50\% CI is (75.42619, 78.57381)
  \end{itemize}
\end{itemize}

Notice how the interval gets smaller as I lower the confidence?

\begin{itemize}
\tightlist
\item
  A 0\% CI would be a single value. As we've seen, there's a 0\% chance
  of any single value in a normal distribution, and the 0\% CI
  communicates this: We are 0\% confident that the sample mean is
  exactly equal to the population mean.
\item
  A 100\% CI would be infinitely wide. That means we would accept any
  population value as ``reasonable'', and we're 100\% confident that the
  true population mean is in our interval. This is true that we're 100\%
  confident, but this isn't useful at all! We must accept risk of
  failure in order to make progress.\footnote{Sorry for the dad advice
    (aka dadvice).}
\end{itemize}

\hypertarget{interpretations}{%
\subsection{Interpretations}\label{interpretations}}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Interpretation of the CI}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

Our particular sample mean is almost surely \textbf{not} exactly equal
to the population mean. However, 95\% of all possible samples will
result in a 95\% CI that includes the population mean.

\end{tcolorbox}

What does that mean? Let's start by imagining a CI that was actually
centered at the population mean. We know that there's a 95\% chance of a
value from the middle 95\% of a normal distribution, so 95\% of sample
means are in the middle 95\% of the sampling distribution. This of
course leaves a 5\% chance that any given sample will result in a mean
that is unusually far from the population mean - it's good to remember
this as a possiblity!

Now let's imagine taking a random sample and getting a mean. That is, we
took a random value from the sampling distribution. Now take that 95\%
interval that's centered at the population mean, and shift it so it's
centered at our new sample mean. If our sample mean is within the middle
95\%, then that interval still contains \(\mu\). If the sample mean is
outside the middle 95\% of the sampling distribution, then that interval
does not include \(\mu\). This will happen 5\% of the time, and there's
nothing we can do about that.

For the heart rate example, we have a sample that has a mean of 77bpm.
If the population were truly normal with a mean of 70 and a sd of 7,
then the sampling distribution of \(\bar X\) with samples of size 9 is
N(70, \(7/\sqrt{9}\)) with a middle 95\% of the true sampling
distribution being defined as (65.42675, 74.57325)\footnote{This is a CI
  centered at the population mean - try it yourself!}. If the sampling
distribution is truly N(70, \(7/\sqrt{9}\)), then 95\% of the sample
means we might get are in the interval (65.42675, 74.57325). To get the
CI from data, we take an interval with the same width (74.57325 -
65.42675 = 9.1465) and center it on our sample mean\footnote{Verify that
  the width of the CI above is 9.1465}. Since 95\% of the means are
withon 2 sd of the population mean, then 95\% of the intervals that are
centered at \(\bar x\) will contain the population mean.

To put this another way: We find the width of the middle 95\% of the
sampling distribution. If this width were centered at \(\mu\), then 95\%
of all sample means will be contained in this interval. Instead, we have
a single sample mean, so we center it there. We're not sure whether this
sample mean was actually in the interval, so we say that we're 95\%
confident that this interval contains the population mean.

A couple of important notes:

\begin{itemize}
\tightlist
\item
  There is no randomness in a 95\% CI. The mean is fixed, the sd is
  fixed, the population mean is fixed.
\item
  It is \textbf{NOT} true that ``95\% of the time, the population mean
  falls in the CI''.

  \begin{itemize}
  \tightlist
  \item
    This is a classic gotcha. Everything here is fixed. 95\% of the
    intervals we construct will contain the population mean, we're just
    not sure if this particular one actually does.
  \end{itemize}
\item
  By the way the CI is constructed, it will contain the population mean
  95\% of the time. We have no idea whether any particular one does, but
  95\% of them do.

  \begin{itemize}
  \tightlist
  \item
    On any given day, there's a 10\% chance of rain. However, it either
    rained yesterday or it didn't. There's \textbf{not} a 10\% chance
    that it rained yesterday - it's either 0\% or 100\%.
  \end{itemize}
\end{itemize}

\hypertarget{summary-4}{%
\subsection{Summary}\label{summary-4}}

If \(X\sim N(\mu,\sigma)\), then a \((1-alpha)\%\)CI is \[
\bar x \pm z^*\sigma/\sqrt{n}
\] where \(P(Z < z^*) = \alpha/2\) can be found with \texttt{qnorm()}
(or a z-table).

\begin{itemize}
\tightlist
\item
  A 95\% is based on finding the middle 95\% of the sampling
  distribution, but centering it around \(\bar x\).
\item
  95\% of the intervals constructed this way will contain the true
  population mean.

  \begin{itemize}
  \tightlist
  \item
    A given interval has either a 0\% chance or a 100\% chance
  \end{itemize}
\item
  A point of sillyness: This assumes that \(\sigma\) is \emph{known}.
\end{itemize}

\hypertarget{exercises-3}{%
\section{Exercises}\label{exercises-3}}

Verify the following CIs.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A 95\% CI when \(\bar x = 160\), \(X\sim N(162.3, 7.11)\) and \(n=25\)
\item
  A 99.7\% CI when \(\bar x = 160\), \(X\sim N(162.3, 7.11)\) and
  \(n=25\)
\item
  A 95\% CI when \(\bar x = 160\), \(X\sim N(162.3, 7.11)\) and
  \(n = 36\)
\item
  A 95\% CI when \(\bar x = 160\),
  \(\bar X\sim N(162.3, 7.11/\sqrt{49})\)
\end{enumerate}

\textbf{Solution}

The answers to the above are:

\begin{verbatim}
A1: (157.21, 162.79)
\end{verbatim}

\begin{verbatim}
A2: (155.78, 164.22)
\end{verbatim}

\begin{verbatim}
A3: (157.68, 162.32)
\end{verbatim}

\begin{verbatim}
A4(158.01, 161.99)
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  The CIs in questions 1-4 all the same sample mean and population sd,
  but different sample sizes and/or confidence levels (\(\alpha\)).
  Comment on the width of the intervals and how this relates to the
  sample size/\(\alpha\) value.
\item
  Explain every part of the following R code, which calculates a 95\% CI
  for the heart rate example:
  \texttt{77\ -\ qnorm((1\ -\ 0.95)/2)\ *\ 7\ /\ sqrt(9)}.

  \begin{itemize}
  \tightlist
  \item
    Why 77, not 70?
  \item
    Why qnorm, not pnorm?
  \item
    Why (1 - 0.95)/2, not just 0.95 or 0.05?
  \item
    Why is it divided by the square root of 9?
  \item
    Why is this the \textbf{upper} limit of the interval?\footnote{Hint:
      run \texttt{qnorm((1-0.95)/2)} yourself, then explain why it's
      negative.}
  \end{itemize}
\item
  Similarly, explain why
  \texttt{qnorm((1\ -\ 0.95)/2,\ mean\ =\ 77,\ sd\ =\ 7/sqrt(9))} will
  produce the same lower bound as question 5. Write a similar
  calculation to get the same upper bound.
\item
  Explain why, after we've collected our sample, the 95\% is
  \textbf{not} a probability.
\item
  A group of researchers is studying the reaction time of a species of
  birds to changes in environmental stimuli. They collect a sample of 36
  birds and record their reaction times. The sample mean reaction time
  is found to be 2.5 seconds, and the standard deviation is 0.8 seconds.
  Calculate a 95\% confidence interval for the true mean reaction time
  of the entire population. Provide the interval and interpret the
  results in the context of the study.
\end{enumerate}

\textbf{Solution}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{2.5} \SpecialCharTok{+} \FunctionTok{qnorm}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.95}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.8} \SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{36}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.238671
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{2.5} \SpecialCharTok{{-}} \FunctionTok{qnorm}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.95}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.8} \SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{36}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.761329
\end{verbatim}

Our 95\% CI is (2.23, 2.76). We are 95\% confident that the true
population reaction time is in this interval.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{9}
\tightlist
\item
  The CI we calculated in the question above was 0.265 on either side,
  which leaves a lot of possible values. Suppose we want the width of
  the 95\% CI to be 0.05 seconds on either side (for a total width of
  0.1 seconds). We only care about the width, so it doesn't matter what
  the sample mean is. We can't change the population sd or the
  confidence level, so all that's left to work with is the sample size.
  Find \(n\) to make the CI half-width equal to 0.05.
\end{enumerate}

\textbf{Solution}

The half-width of the interval is also called the Margin of Error, or
MoE. We want MoE = 0.05, and we know that MoE = \(z^*\sigma/\sqrt{n}\).
Setting these equal,

\(0.05 = 1.96 * 0.8 / sqrt{n} \implies \sqrt{n} = 1.96 * 0.8 / 0.05 \implies n = 31.36^2 = 983.4\)

Since the sample size can't be a fraction, we must round this number. If
we round \textbf{down}, we have a smaller sample size and therefore a
wider interval. Instead, we must round up! 983.4 is the \emph{minimum}
sample size, so if we want a round number we always have to go
up\footnote{Even if we got 983.0001, we would round up!}. The final
answer is that we need 984 birbs to get a 95\% CI that has a total width
of 0.1.

Without rounding:
\texttt{(-qnorm(0.025)\ *\ 0.8\ /\ 0.05)\^{}2\ =\ 983.4135}, and so our
answer doesn't change!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{crowdsourced-questions-6}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-6}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A survey is conducted to estimate the average number of hours
  university students spend per week. A 95\% confidence interval for the
  mean number of study hours is calculated to be (6.3, 8.8). What does
  this confidence interval imply?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    There is a 95\% chance that the true mean number of study hours
    falls between 6.3 and 8.8.
  \item
    The mean number is study hours fall between 6.3 and 8.8 with 95\%
    confidence
  \item
    95\% of students spend between 6.3 and 8.8 hours studying per week
  \item
    There is a 5\% chance that the true mean number of study hours is
    outside the 6.3 to 8.8 range.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

b is the correct answer - a 95\% confidence interval means that if we
were to repeat this study multiple times and calculate confidence
intervals for each sample study, then around 95\% of these intervals
would contain the true population mean. We could be 95\% confident that
the true mean number of study hours falls between 6.3 and 8.8.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  A research study estimates a 95\% confidence interval for the mean
  height of students at Ganton Heights Public High School to be between
  160 cm and 170 cm. What does this confidence interval represent over
  the long run?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    There is a 95\% chance that the true mean height of students falls
    between 160 cm and 170 cm.
  \item
    95\% of the students in the school have heights between 160 cm and
    170 cm.
  \item
    If we were to repeat this study multiple times and calculate a 95\%
    confidence interval each time, 95\% of those intervals would contain
    the true mean height of students.
  \item
    The mean height of students in the school is exactly between 160 cm
    and 170 cm.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

The correct answer is (c). The confidence interval represents the long
term frequency that intervals generated from independent random samples
of fixed size will contain the true population mean. In this situation,
a 95\% confidence interval represents that if the study was repeated
multiple times, 95\% of those intervals constructed from random sample
statistics would contain the true mean height of students at Ganton
Heights Public High School. Option (a) would also be correct, if we were
not looking at the long run frequency of this 95\% confidence interval.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Concerning Margin of Error, which of the following statements about
  critical values is \emph{true}?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    \(z^*\) value can only be 1, 2, or 3, as per the Empirical rule
  \item
    \(z^* = 0\) means that the confidence interval can not be found
  \item
    \(z^* = \infty\) means that the true population mean is 100\% within
    the confidence interval
  \item
    Standard deviation is different from standard error
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

The correct statement is c).

Equation for Margin of Error is \(MoE = (z^*) \frac{\sigma}{\sqrt{n}}\)

The (\(z^*\)) represents the critical value which indicates how many
standard deviations from the mean the confidence interval lies. A
z-score can not be negative therefore it can not be any integer. A
z-score of 0 does not indicate that the confidence interval cant be
found, it tells us that the true population mean is definitely not
within the confidence interval. As mentioned in Devan Beckers course
notes, an infinite z score means that the confidence interval is
infinitely wide. That tells us that we would be 100\% confident that the
true population mean is within the confidence interval.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{tests-of-significance}{%
\chapter{Tests of Significance}\label{tests-of-significance}}

\hypertarget{overview-of-tests-of-significance}{%
\section{Overview of Tests of
Significance}\label{overview-of-tests-of-significance}}

\hypertarget{philosophy}{%
\subsection{Philosophy}\label{philosophy}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We start with a ``null'' hypothesis, \(H_0\), which states that
  nothing ``interesting'' is going on.

  \begin{itemize}
  \tightlist
  \item
    The mean is exactly what we guessed, \(H_0: \mu = \mu_0\)\footnote{Notation
      note: \(\mu_0\) will always refer to the proposed population
      value.}
  \item
    The effect of the drug is the same in both groups.
  \item
    Something something ``same as'' something something.
  \end{itemize}
\item
  We have an alternative hypothesis - things are different.

  \begin{itemize}
  \tightlist
  \item
    \(H_A: \mu > \mu_0\) (or \(<\), or \(\ne\))
  \end{itemize}
\item
  We do our study and get our mean (for now, assume \(\sigma\) known)
\item
  We check if our observed mean is ``too unlikely'' under the null.

  \begin{itemize}
  \tightlist
  \item
    If the null hypothesis is true, is our observed mean preposterous?
  \item
    This is where the dreaded p-value comes in.
  \end{itemize}
\item
  We make a decision - reject or don't reject \(H_0\) - based on our
  p-value.
\end{enumerate}

To summarize: We make a ``guess'' about the population. We collect data,
and we determine whether or not our data is compatible with our guess.
If it isn't, then it's the \emph{guess} that must be wrong; not the
data\footnote{Unless it's a bad sample/study design}.

The assumptions are the same as the assumptions for CIs:

\begin{itemize}
\tightlist
\item
  Normal population (or large sample size)
\item
  \(\sigma\) known

  \begin{itemize}
  \tightlist
  \item
    We will get away from this assumption later; for now it's nice to
    ease into the concepts.
  \end{itemize}
\item
  Simple Random Sample (Independent Observations)
\end{itemize}

\hypertarget{p-value-by-example-trailmaking-test-for-fatigue}{%
\section{p-value by Example: Trailmaking Test for
Fatigue}\label{p-value-by-example-trailmaking-test-for-fatigue}}

The following image shows the output of a ``trailmaking'' app. Subjects
are shown the numbers on a touch screen and are tasked with drawing a
line\footnote{``trail''} starting at 1, then 2, and so on without
touching the other numbers. The time is recorded.

\includegraphics{figs/Trails.jpg}

In my research, this app was given to aerial forest fire fighters.
Flying a plane is a very challenging task to begin with, made much more
challenging when there's an active fire! The hypothesis is that pilots
are measurably fatigued after a fire. However, this hypothesis must be
converted into a mathematical construct that we can do something with!

Pilots perform the test many times before a long flight and once after.
In samples from the aerial firefighters who were non-fatigued, it was
found that completion time follows a normal distribution with mean 15
seconds and standard deviation 1.2 seconds\footnote{These numbers
  actually come from the data of pre-flight trails, but we're going to
  treat them as the population for now.}. We hypothesize that it took
longer than that after the flight. \begin{align*}
H_0: \mu &= 15\\
H_A: \mu &> 15
\end{align*} The hypotheses above are created entirely based on the
research question. We can (must) write the hypothesis before collecting
data. \(\bar x\) does \emph{NOT} appear in hypotheses. Instead, ``15''
(\(\mu_0\)) and the ``\textgreater{}'' come from the hypotheses that
fatigued pilots take \emph{longer} than the population.

\hypertarget{results}{%
\subsection{Results}\label{results}}

We caclulated a mean of 15.9 seconds from 16 pilots. Is this slower than
15 seconds? Obviously, these numbers are different, but is this a big
difference? To tell whether two numbers are ``far apart'', we need some
sense of scale. In statistics, scale is given to us in the form of
\textbf{variance}.

The population standard deviation is given as 1.2 seconds. How many
standard deviations away from the hypothesized value is our
\emph{sample} mean? Well, since it's a \textbf{SAMPLE MEAN}, the
standard deviation is \(1.2/\sqrt{16} = 0.3\) (again, this is also
called the \textbf{standard error}). Our sample mean of 15.9 is 3
standard deviations\footnote{15.9 is 3 steps of 0.3 above 15; (15.9 -
  15)/0.3 = 3} \emph{above} the hypothesized means.

The \textbf{p-value} for this is the probability of observing a value at
least as far from the hypothesized mean, assuming that the hypothesized
mean is the true mean\footnote{This is the definition. The description
  must always include the part about ``assuming that the hypothesized
  value is the true value''}.

Using \texttt{pnorm()}, our p-value is P(Z \textgreater{} 3) = 1 - P(Z
\textless{} 3) = 0.0013\footnote{We can only use a standard normal
  distrubution because the mean of the sampling distribution is assumed
  to be \(\mu_0\), our hypothesized mean. If this weren't the case, then
  we would not get a standard normal distribution and thus we wouldn't
  be able to use this method. This is why the ``assuming the null is
  true'' bit is important.}. Is our sample mean ``unlikely'' assuming
that the null hypothesis is true?

The definition of ``unlikely'' will generally need to be given in the
question. Usually, a \textbf{significance level} of
\(\alpha = 0.05\)\footnote{The symbol \(\alpha\) refers to the
  significance level, but also comes up in a \((1-\alpha)\)\%CI. Perhaps
  this is foreshadowing.} is used\footnote{Please read the APA's
  statement on p-values, found on OWL. At least one short answer
  question will be based on this.}.

Since our p-value is 0.0013 \textless{} 0.05, our observed mean is ``too
unlikely.'' So our hypothesis must be wrong!\footnote{Again: if our
  guess is incompatible with our data, then it's our guess that's wrong,
  not the data.} We conclude that the average time to complete the trail
has increased, i.e.~\(\mu > 15\)\footnote{Notice how this conclusion
  brings back the context of the question.}. In this case, we say our
result is \textbf{statistically significant}.

\hypertarget{summary-5}{%
\subsection{Summary}\label{summary-5}}

From the question, we got our hypotheses:\vspace{-7mm}

\begin{align*}
H_0: &\mu = 15\\
H_A: &\mu > 15
\end{align*}

We caclulated our \textbf{test statistic}\footnote{Labelled \(z_{obs}\).},
which is the z-score of our observed mean \textbf{assuming that the null
hypothesis is true}:

\[ z_{obs} = \frac{\bar x - \mu_0}{\sigma/\sqrt{n}}  = \frac{15.9 - 15}{1.2/\sqrt{16}} = 0.9/0.3 = 3\]

We found up P(Z \textgreater{} \(z_{obs}\))\footnote{We used \(>\)
  rather than \(<\) because \(>\) appears in our alternate hypothesis.}
using \texttt{1\ -\ pnorm(3)} to get our p-value of 0.0013.

Since this is a small probability (our p-value is less than our
significance value of \(\alpha = 0.05\)), we reject the null hypothesis
in favour of the alternative.

This is the general approach to hypothesis testing: hypotheisize,
calculate, find a normal value, then conclude.

\hypertarget{two-sided-p-values}{%
\section{Two Sided p-values}\label{two-sided-p-values}}

If your hypotheses are: \vspace{-4mm}

\begin{align*}
H_0: &\mu = 15\\
H_A: &\mu \ne 15
\end{align*}

then you're going to need to change things. In particular, you need to
\emph{double} the p-value for a one-sided test\footnote{If you do this
  and find a p-value that is larger than 1, you used the wrong tails!}.
This is where the phrase ``at least as extreme'' comes in - we would
reject anything this far away on either side.

The following shiny app demonstrates this. In particular, note what
happens when you have a two sided alternative hypothesis and you double
the wrong tails\footnote{In the app, it's denoted ``Use absolute
  value''. This is because you can find \(P(Z > |z_{obs}|)\) so that you
  always get the upper tail}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DB7\_OER/TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Tools/pvalues"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{two-sided-example}{%
\subsection{Two Sided Example}\label{two-sided-example}}

Given \(\sigma = 2\), \(n = 25\), and \(\bar x = 6.6\), test the
hypothesis that the true population mean is not equal to 6 at the 10\%
level\footnote{That is, at the \(\alpha=0.1\) significance level.}.\vspace{-4mm}

\begin{align*}
H_0: \mu = 6\\
H_A: \mu \ne 6
\end{align*}

test stat:
\(z_{obs} = \frac{6.6 - 6}{2/\sqrt{5}} = \frac{0.6}{0.4} = 1.5\)

Find using R: P(Z \textgreater{} 1.5) = P(Z \textless{} -1.5) =
\texttt{pnorm(-1.5)} = 0.0668

p-value = 2*0.0668 = 0.1336

Conclude: p \textgreater{} \(\alpha\), therefore do not reject. The
p-value is not significant.

\hypertarget{critical-values-1}{%
\subsection{Critical Values}\label{critical-values-1}}

For a two-sided test at the 5\% level, what is the largest test
statistic that would not be rejected?

Since it's a two-sided test at 5\%, we would reject anything in the
2.5\% area in either tail. Using the Z-table (or qnorm(0.05/2)), this
would come from a test-statistic of 1.96. So if our test stat is 1.97,
it would have a p-value below 0.05, and if it's 1.95 it would have a
p-value above 0.05.

In hypothesis testing, the critical value denotes the point at which z
statistics\footnote{\(z_{obs}\)} are significant. If your z statistic is
larger than 1.96, it will be statistically significant at the 5\% level
(for a two-sided test). This way, we can test significance without even
calculating the p-value. Our conclusion will simply be that \(p<0.05\),
but this is often sufficient - it's not important if the p-value is
0.044 versus 0.045.\footnote{If we had taken a different sample, we
  would have gotten a different p-value - p-values have a sampling
  distribution as well!!!}

\hypertarget{hard-exam-style-question}{%
\subsection{Hard Exam-Style Question}\label{hard-exam-style-question}}

\begin{itemize}
\tightlist
\item
  A study reported that their two-sided p-value for \(H_0:\mu = 0\) was
  significant at the 5\% level, but not the 1\% level.
\item
  They reported a mean of 10 and a sample size of 36
\end{itemize}

What values could their standard deviation be?

Solution:

\begin{itemize}
\tightlist
\item
  At the 5\% level, \(z^* = 1.96\), so:

  \begin{itemize}
  \tightlist
  \item
    \(1.96 = \frac{x - \mu_0}{\sigma/\sqrt{n}} = \frac{10 - 0}{\sigma/6}\)
  \item
    Rearranging, \(\sigma= \frac{6*10}{1.96} = 30.61\)
  \item
    Sanity check: \texttt{pnorm(10,\ 0,\ 30.61/sqrt(36))} = 0.975, as
    expected.
  \end{itemize}
\item
  At the 1\% level, \(z^*\) = \texttt{-qnorm(0.01/2)} = 2.576

  \begin{itemize}
  \tightlist
  \item
    \(\sigma= \frac{6*10}{2.576} = 23.292\)
  \item
    Sanity check: \texttt{pnorm(10,\ 0,\ 23.292/sqrt(36))} = 0.995, as
    expected.
  \end{itemize}
\end{itemize}

Conclusion: The standard deviation is between 23.3 and 30.6.

In this example, notice how a \emph{smaller} standard deviation means a
\emph{smaller} significance level!

\hypertarget{ci-vs.-p-value}{%
\subsection{CI vs.~p-value}\label{ci-vs.-p-value}}

Recall the following two facts:

\begin{itemize}
\tightlist
\item
  CI: \(\mu\) is in the interval \(\bar x \pm z^*\sigma/\sqrt{n}\)
\item
  Test statistic: \(z_{obs} = \frac{\bar x - \mu_0}{\sigma/\sqrt{n}}\)
\end{itemize}

As homework, rearrange the test statistic equation for \(\mu_0\).

A new definition of confidence intervals: A \((1-\alpha)\)\% CI contains
every \(\mu_0\) that would \textbf{NOT} be rejected by a test at the
\(\alpha\)\% significance level.

This is why we don't say that we ``accept'' the null hypothesis. There
are an infinite number of hypothesis values in the CI - we can't
``accept'' them all! Also, our tests only work in reference to the
alternate hypothesis. We can only reject/not reject in reference to
\(H_A\).

\hypertarget{self-study-questions-3}{%
\section{Self-Study Questions}\label{self-study-questions-3}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain the logic behind hypothesis testing in your own words. Make
  particular reference to the ``at least as extreme as'' part of the
  definition of a p-value.
\item
  Explain why p-values are sample statistics.\footnote{This implies that
    p-values have sampling distributions!}
\item
  What happens if a sample or study design is biased? In particular,
  suppose that the sample will systematically result in higher values
  that the population, and we're testing \(H_A:\mu > \mu_0\). What
  happens to the p-value?\footnote{While you're at it, what happens to
    the CI?}
\item
  For CIs, I was adamant that we cannot speak of the probability that
  the population mean is inside the interval. We have now learned about
  the duality of CI and Hypothesis Testing, but we \emph{can} speak of
  probability for test statistics\footnote{``p-value'' is literally
    short for ``Probability Value''.}. What gives?\footnote{Hint: what
    are we calculating probabilities for?}
\item
  Suppose we are testing \(H_A:\mu > 10\) and we get a sample statistic
  \(\bar x = 10\). What would the p-value for this be?
\item
  For a one-sided hypothesis test, what does it mean for our p-value to
  be larger than 0.5? Does this mean we did something wrong?\footnote{Hint:
    refer to the previous question.}
\end{enumerate}

\hypertarget{exercises-4}{%
\section{Exercises}\label{exercises-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Suppose we know that \(\sigma = 10\) and that the population is
  normally distributed, but we don't know the mean. We found a sample
  mean of 150 from a sample of size 25. Test the hypothesis that
  \(\mu_0 < 155\) at the 5\% level.
\end{enumerate}

\textbf{Solution}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{150}\NormalTok{, }\AttributeTok{mean =} \DecValTok{155}\NormalTok{, }\AttributeTok{sd =} \DecValTok{10} \SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{25}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.006209665
\end{verbatim}

Since \(p<\alpha\), we reject the null hypothesis and conclude that the
population mean is less than 155.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  A pharmaceutical company is testing a new drug designed to lower
  cholesterol levels. In a clinical trial with 80 participants, the
  average reduction in cholesterol is found to be 15 mg/dL and the
  population standard deviation is known to be 5 mg/dL. The company
  claims that the drug will reduce cholesterol by at least 12 mg/dL on
  average. Calculate the p-value for this claim based on the sample
  data, and determine whether there is sufficient evidence to support
  the company's claim at a significance level of 0.05. Interpret the
  results in the context of the study.
\end{enumerate}

\textbf{Solution}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{15}\NormalTok{, }\AttributeTok{mean =} \DecValTok{12}\NormalTok{, }\AttributeTok{sd =} \DecValTok{5}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{80}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.012556e-08
\end{verbatim}

We reject the null hypothesis that the reduction in cholesterol is
exactly 12 mg/dL in favour of the alternative that the reduction in
cholesterol is less than 12 mg/dL. In other words, 15 is a statistically
significantly larger reduction than 12.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{crowdsourced-questions-7}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-7}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A pharmaceutical company asserts that their latest pain relief drug
  reduces the average duration of headaches by at least 30 minutes. To
  test this claim, a researcher conducts a study and gathers data from a
  sample of individuals suffering from headaches who took the
  medication. The null hypothesis (H0) states that the drug does not
  reduce headache duration by 30 minutes, whereas the alternative
  hypothesis (H1) states that it does. The research conducts a
  hypothesis test and obtains a p-value of 0.03. What inference should
  the research make at the significance level of 0.05.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Fail to reject the null hypothesis; there is insufficient evidence
    to conclude that the drug reduces headache duration by 30 minutes on
    average.
  \item
    Fail to reject the null hypothesis; there is sufficient evidence to
    conclude that the drug does not reduce headache duration by 30
    minutes on average.
  \item
    Reject the null hypothesis; there is sufficient evidence to conclude
    that the drug reduces headache duration by 30 minutes on average.
  \item
    Reject the null hypothesis; there is insufficient evidence to
    conclude that the drug reduces headache duration by 30 minutes on
    average.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

c is the correct answer - since the p-value, 0.03 is less than the
significance level, 0.05, the null hypothesis is rejected. This also
means that there is sufficient evidence to conclude that the drug does
reduce headache by at least 30 minutes on average, supporting the
company's claim.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  A basketball coach refutes the claim that the average player scores 15
  points per game. Which hypothesis is used to test the claim?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    \(H_0: \mu = 15, H_A: \mu \ne 15\)
  \item
    \(H_0: \mu \ne 15, H_A: \mu = 15\)
  \item
    \(H_0: \mu > 15, H_A: \mu \le 15\)
  \item
    \(H_0: \mu \ge 15, H_A: \mu > 15\)
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

The correct answer would be (a). The null hypothesis (\(H_0\)) in option
(a) states that the average player scores exactly 15 points per game,
which is the claim being tested by the basketball coach. The alternative
hypothesis (\(H_A\)) would then be that the average player does NOT
score exactly 15 points, which has been modeled by the HA in option (a).
This also means that the player could score less or more than 15 points
per game (allowing for a two-tailed test, which has been discussed in
our lesson regarding tests of significance).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{special-topics-in-inference}{%
\chapter{Special Topics in
Inference}\label{special-topics-in-inference}}

Now that we've covered the basics of confidence intervals and p-values,
there is a huge world of inference to explore! What follows is a small
window into the cautions and best practices of inference, especially
with regards to p-values.

\hypertarget{interpreting-p-values}{%
\section{Interpreting p-values}\label{interpreting-p-values}}

A p-value is \textbf{the probability of a result that is at least as
extreme as the one we observed, given that the null hypothesis is true.}

It's a measure of evidence against the null. We assume that the null is
true, then ask how likely our sample would be. There isn't a problem
with our sample, so if it's unlikely then it must be our assumption that
is wrong.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-important-color!10!white, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{``Given that the null hypothesis is true''}, arc=.35mm, colframe=quarto-callout-important-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

Any interpretation of a p-value that does not assume that the null
hypothesis is true is a bad interpretation.

\end{tcolorbox}

The following interpretations are \emph{not} valid:

\begin{itemize}
\tightlist
\item
  The probability of getting data like this.
\item
  Probability of our data \emph{by chance alone}.

  \begin{itemize}
  \tightlist
  \item
    Would be correct if we made reference to the null
  \end{itemize}
\item
  The probability that the null hypothesis is true

  \begin{itemize}
  \tightlist
  \item
    This is just so wrong, but it unfortunately appears in a lot of
    published papers.
  \end{itemize}
\end{itemize}

Always look for wording that assumes that the null is true, and searches
for evidence against it.

\hypertarget{statistical-versus-practical-significance}{%
\section{Statistical Versus Practical
Significance}\label{statistical-versus-practical-significance}}

Suppose a new drug claims to increase your lifespan significantly. Wow!
That sounds great!

After hearing this claim, you dig into the paper that made the claim,
and found that the drug increases the average lifespan by 3 hours. How
can they claim this was significant???

This is the difference between statistical and practical significance.
The probability of a result \emph{at least as extreme}, given that the
null hypothesis is true, says nothing of \emph{how extreme} the results
are. A very small \textbf{effect size} can be statistically significant,
even if it's not a noticable change in practice.

Furthermore, maybe this new drug costs \$1,000 per day and has intense
nausea as a side-effect. A statistically significant difference says
\emph{absolutely nothing} about the practical effects.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-important-color!10!white, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{p-values were never meant to be the goal of a study.}, arc=.35mm, colframe=quarto-callout-important-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

They are yet another tool in the health researcher's repertoire, meant
to test whether data provide enough evidence against a very particular
hypothesis.

\end{tcolorbox}

\hypertarget{choosing-a-significance-level}{%
\section{Choosing a Significance
Level}\label{choosing-a-significance-level}}

To build intuition, we start from the extremes:

\begin{itemize}
\tightlist
\item
  A significance level of \(\alpha = 0\) will \emph{never} reject the
  null hypothesis.

  \begin{itemize}
  \tightlist
  \item
    No amount of evidence will convince you.
  \end{itemize}
\item
  A siginficance level of \(\alpha = 1\) will \emph{always} reject the
  null hypothesis.

  \begin{itemize}
  \tightlist
  \item
    Any evidence will convince you.
  \end{itemize}
\end{itemize}

When setting a confidence level, you must consider how much evidence you
require. To quote Carl Sagan: ``Extraordinary claims require
extraordinary evidence.''

Here are some examples:

\begin{itemize}
\tightlist
\item
  A new cancer treatment costs 10 times as much and the patient will
  never heal back to 100\% health. To justify such a procedure, we want
  to be \emph{reeeeeaaaaalllly} sure that it works, so we might set a
  significance level of \(\alpha=0.001\) before we collect any data.
\item
  We are making a slight change to an advertising strategy that is based
  on scientific evidence. We're fairly certain it will work, and the
  consequences of it not working are very small. A larger significance
  level, perhaps \(\alpha = 0.1\), might be appropriate.

  \begin{itemize}
  \tightlist
  \item
    \(\alpha = 0.1\) is probably the largest significance level you will
    ever encounter.
  \end{itemize}
\item
   \textbf{Aliens example}: There's an abberation in an image taken by
  a digital camera. According to the manufacturer, such an abberation
  would occur in 0.0001\% of the pictures. If we think it's aliens,
  that's an extraordinary claim! We'd need some very strong evidence. Do
  you think that 0.0001\% is strong enough? (We'll return to this later
  in the chapter.)
\end{itemize}

\hypertarget{hypothesis-errors}{%
\section{Hypothesis Errors}\label{hypothesis-errors}}

When you test a hypothesis, there are two types of errors: You could
reject when the null is true or you could fail to reject when the null
is false. The following matrix summarises this:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
& H\_0 is TRUE & H\_0 is FALSE \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Don't Reject & Good! & Type 2 Error \\
Reject & Type 1 Error & Good! \\
\end{longtable}

In other words:\vspace{-3mm}

\begin{itemize}
\tightlist
\item
  \textbf{Type 1:} False Positive
\item
  \textbf{Type 2:} False Negative
\end{itemize}

There's another important point here: rejecting the null hypothesis does
\emph{not} mean that it's actually false! Any number of things might
have happened, such as including an outlier or taking a biased sample.

Similarly, failing to reject a null does \emph{not} mean that it's true.
We've already talked about this a bit - confidence intervals are all
values that would not be rejected by a hypothesis test, so there are
\emph{many} plausible null hypotheses! However, we can also fail to
reject the null \emph{even though it's false}. This can also happen for
multiple reasons:

\begin{itemize}
\tightlist
\item
  Sample size is too small.

  \begin{itemize}
  \tightlist
  \item
    The distance between the null and the sample mean is calculated
    relative to the standard error. The standard error \emph{decreases}
    with a larger sample, so if our sample isn't big enough then we
    might not have collected enough evidence to reject the null,
    regardless of whether it's true.
  \end{itemize}
\item
  Large variability in the data.

  \begin{itemize}
  \tightlist
  \item
    This is the other thing that can increase the standard error. With
    more variation, the distance between the null and the sample mean
    doesn't seem as large!
  \item
    We can fix this with better sampling strategies and with better
    study designs, or by getting a larger sample size!
  \end{itemize}
\item
  Our significance level is too high.

  \begin{itemize}
  \tightlist
  \item
    This isn't really something that we can change after we've seen the
    data.\footnote{We can think long and hard about it \emph{before}
      seeing the data, but once we see the data we are commited to a
      particular significance level. Anything else is borderline fraud,
      depending on the circumstances.}
  \end{itemize}
\end{itemize}

\hypertarget{the-probability-of-type-1-errors}{%
\subsection{The Probability of Type 1
Errors}\label{the-probability-of-type-1-errors}}

What's the probability your reject the null, even though it's true?
Let's say we reject the null if the p-value is, say, less than 5\%. This
means that any value in the 5\% tails of the distribution would lead to
us rejecting the null hypothesis - even though it's true!\footnote{Recall:
  the p-value is the probability of a result that is at least as extreme
  \emph{assuming that the null hypothesis is true}!} The probability
that we do this is 5\%, since there's a 5\% chance that we'll see a
value that is ``too unlikey'' at the 5\% level.

As usual, I like to demonstrate things via simulation. Here's the setup:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set the population parameters as \(\mu = 0\) and
  \(\sigma = 1\)\newline
\item
  Simulate normal data\newline
\item
  Do a two sided test for \(H_0: \mu = 0\)

  \begin{itemize}
  \tightlist
  \item
    Note that this null hypothesis is TRUE\newline
  \end{itemize}
\item
  Count how many times we reject the null.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{21}\NormalTok{); }\FunctionTok{par}\NormalTok{(}\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)) }\CommentTok{\# unimportant}
\DocumentationTok{\#\# set an empty vector, to be filled with p{-}values}
\NormalTok{pvals }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{() }

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10000}\NormalTok{)\{ }\CommentTok{\# repeat 10,000 times}
    \CommentTok{\# Simulate 30 normal values with a population mean of 0 and sd of 1}
\NormalTok{    newsample }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{30}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}
    \CommentTok{\# Test whether the population mean is 0}
\NormalTok{    newsample\_mean }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(newsample)}
\NormalTok{    newsample\_sd }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{30}\NormalTok{) }\CommentTok{\# Assuming population sd is known}
\NormalTok{    my\_z\_test }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FunctionTok{abs}\NormalTok{(newsample\_mean), }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ newsample\_sd))}
    \CommentTok{\# record the p{-}value (the output of t.test has some hidden values)}
\NormalTok{    pvals[i] }\OtherTok{\textless{}{-}}\NormalTok{ my\_z\_test}
\NormalTok{\}}
\DocumentationTok{\#\# Testing at the 5\% level}
\FunctionTok{sum}\NormalTok{(pvals }\SpecialCharTok{\textless{}} \FloatTok{0.05}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{length}\NormalTok{(pvals) }\CommentTok{\# should be close to 0.05}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0481
\end{verbatim}

Since we're testing at the 5\% level, this value is close to 5\%! It's a
little tricky to get your head around: If we think 5\% is too unlikely,
then we reject the null. However, things that have ``only'' a 5\% chance
happen about 5\% of the time!

The histogram below shows all of the p-values we generated. The 5\%
cutoff isn't anything special - a test at the 10\% level will falsely
reject the null 10\% of the time. A test at the 90\% level will falsely
reject the null 90\% of the time!

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Fun fact: under the null hyothesis, all p{-}values are equally likely}
\DocumentationTok{\#\# this fun fact is not relevant to this course.}
\FunctionTok{hist}\NormalTok{(pvals, }\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.05}\NormalTok{))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \FloatTok{0.05}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L14-Inference_Cautions_files/figure-pdf/unnamed-chunk-2-1.pdf}

}

\end{figure}

\hypertarget{the-probability-of-type-2-errors}{%
\subsection{The Probability of Type 2
Errors}\label{the-probability-of-type-2-errors}}

For a two-sided test, our hypotheses are: \begin{align*}
H_0: \mu &= \mu_0\\
H_A: \mu &\ne \mu_0\\
\end{align*}

If the null is actually false\footnote{False in the population, not just
  rejected due to a sample.}, what's \(\mu\)? All we know is that it
\emph{isn't} \(\mu_0\).\footnote{I once saw a bag in a grocery store
  with a label that said ``It's Not Bacon''. I had no idea what was in
  that bag. In the video I said it was kale, but that turns out to be
  false.} It could be a little above \(\mu_0\), in which case it might
be hard to reject \(\mu_0\). It could be a far above \(\mu_0\), in which
case it might be easy to reject \(\mu_0\).

\begin{itemize}
\tightlist
\item
  Ex1: \(\mu = 0.001\), \(\sigma = 1\), and \(\mu_0 = 0\).

  \begin{itemize}
  \tightlist
  \item
    Hard to reject \(\mu_0\) since it's so close to \(\mu\) (low
    \textbf{power})
  \item
    Easy to \emph{not} reject the false \(\mu_0\) (high probability of
    type 2 error)
  \item
    Most \(\bar x\)'s would be close to \(\mu_0\), relative to the
    standard error.
  \end{itemize}
\item
  Ex2: \(\mu = 0.001\), \(\sigma = 0.00000001\), and \(\mu_0 = 0\).

  \begin{itemize}
  \tightlist
  \item
    Easy to reject \(\mu_0\) since it's so far from \(\mu\) (high
    \textbf{power})
  \item
    Hard to \emph{not} reject the false \(\mu_0\) (low Type 2)
  \end{itemize}
\end{itemize}

\textbf{Power} is our ability to correctly reject a false null
hypothesis, and is defined as 1 - P(Type 2 Error)

Note that these examples are both missing the \textbf{Standard Error},
which incorporates sample size. The power depends on the distance
between \(\mu\) and \(\mu_0\) relative to the standard error, not just
the population standard deviation. We can partially control the standard
error by having a better study design\footnote{to reduce \(s\)} and a
larger sample size, both of which would give us more power.

\hypertarget{power-by-simulation-diy}{%
\subsection{Power by Simulation (DIY)}\label{power-by-simulation-diy}}

The following code calculates the power. Run it many times, changing
\(\mu_0\), \(\sigma\), and \(n\) to see what happens to the power.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Set parameters}
\NormalTok{mu }\OtherTok{\textless{}{-}} \DecValTok{0} \CommentTok{\# don\textquotesingle{}t change this, but change the other parameters}
\NormalTok{mu\_0 }\OtherTok{\textless{}{-}} \FloatTok{0.1}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{50}

\DocumentationTok{\#\# Record p{-}vals}
\NormalTok{p\_vals }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10000}\NormalTok{)\{}
\NormalTok{    newsample }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, mu, sigma)}
\NormalTok{    p\_vals[i] }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\FunctionTok{mean}\NormalTok{(newsample)), }\DecValTok{0}\NormalTok{, sigma}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n)))}
\NormalTok{\}}
\DocumentationTok{\#\# The proportion of times the null was (correctly) rejected}
\FunctionTok{mean}\NormalTok{(p\_vals }\SpecialCharTok{\textless{}} \FloatTok{0.05}\NormalTok{) }\CommentTok{\# Power}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0483
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(p\_vals }\SpecialCharTok{\textgreater{}} \FloatTok{0.05}\NormalTok{) }\CommentTok{\# P(Type 2 Error)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9517
\end{verbatim}

\hypertarget{multiple-comparisons}{%
\section{Multiple Comparisons}\label{multiple-comparisons}}

Suppose we have a coin that's heads 5\% of the time. What's the
probability of at least one heads in 10 flips?

As we saw in previous lectures: P(at least 1 heads in 10 flips) = 1 -
P(no heads in 10 flips). We can calculate this in R:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{dbinom}\NormalTok{(}\DecValTok{0}\NormalTok{, }\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.05}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.4012631
\end{verbatim}

Why did I do go back to flipping coins? Did I forget which chapter I'm
in?

Consider the following problem:

Suppose you're testing 10 hypotheses at the 5\% level. Assuming all of
the null hypotheses are true, what's the probability that at least one
of them is significant?

Since we're testing at the 5\% level, P(Type 1 Error) = 0.05, so

P(\(\ge\) 1 rejection in 10 hypotheses) =

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{dbinom}\NormalTok{(}\DecValTok{0}\NormalTok{, }\AttributeTok{size =} \DecValTok{10}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.05}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.4012631
\end{verbatim}

In other words, there's about a 40\% chance that we'd get at least one
significant result \emph{even though all of the null hypotheses are
true}.\footnote{Note that if the hypotheses are all based on the same
  data then they're probably not independent.}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-important-color!10!white, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{The Multiple Comparisons Problem}, arc=.35mm, colframe=quarto-callout-important-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

When checking more than one hypothesis, the probability of an error
increases!

This happens for both Type 1 and Type 2 errors, but is especially
important for Type 1 errors. If you test \(n\) errors at the
\(\alpha\)\% level, then the probability of a Type 1 error is
\(1 -(1 - \alpha)^n\).

\end{tcolorbox}

So how do we avoid the multiple comparisons problem? There are generally
two ways to do it:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set a \textbf{Family-Wise Error Rate}, rather than an error rate for
  individual hypothesis tests.

  \begin{itemize}
  \tightlist
  \item
    If you're going to check 10 p-values, use a smaller cutoff.
  \item
    There are several ways to do this, with the most popular being the
    Bonferroni correction: for m values, a cutoff of \(\alpha/m\) will
    result in rejecting at least one test \(\alpha\)\% of the time. For
    example, if you want a test at the 5\% level but you're testing 10
    values, you should reject any individual hypothesis only if the
    p-value is less than \(\alpha/m = 0.05/10\).
  \end{itemize}
\item
  Only check one p-value!

  \begin{itemize}
  \tightlist
  \item
    For most studies, you should have single, well-defined hypothesis.
    State this hypothesis ahead of time, do all of your data preparation
    and get it loaded into R, then only test that hypothesis.
  \item
    If you check a second hypothesis, then your significance level is a
    lie! Testing two true null hypotheses at the 5\% level will result
    in a significant result 9.75\% of the time.
  \end{itemize}
\end{enumerate}

Failure to account for multiple hypothesis testing is bad science and
it's a path to the dark side. Consider this fantastic tool by
\href{https://projects.fivethirtyeight.com/p-hacking/}{fivethirtyeight}.
Play around with it - by checking a bunch of hypotheses, you can hack
your way into finding one that supports your own point of view! In this
particular example, your goal is to prove that either (a) the economy
does better when a democrat in the white house or (b) the economy does
better when a republican is in the white house. Both of these can be
demonstrated with a statistically significant result if you check enough
hypotheses!

Let's return to the  \textbf{aliens} example. We observed an
abberation that only happens in 0.0001\% of the pictures taken. However,
\emph{we took thousands of pictures}! Even though this event is rare, it
had many chances to happen. This is exactly what multiple hypothesis
testing is demonstrating: rare events will happen if you give them
enough chances! Rejecting the null when it is actually true is a rare
event, but it can easily happen if we check a lot of p-values!

\hypertarget{summary-6}{%
\section{Summary}\label{summary-6}}

\begin{itemize}
\tightlist
\item
  \textbf{Type 1 Error:} Reject a true null

  \begin{itemize}
  \tightlist
  \item
    Probability is \(\alpha\)
  \end{itemize}
\item
  \textbf{Type 2 Error:} Fail to reject a false null

  \begin{itemize}
  \tightlist
  \item
    Probability depends on the distance between \(\mu\) and \(\mu_0\),
    relative to the \textbf{standard error}. In more advanced classes,
    you will calculate this or have something to calculate it for you.
  \end{itemize}
\item
  \textbf{Multiple comparisons problem:} The more hypotheses you test,
  the more likely it is that at least one of them is falsely labelled
  significant.

  \begin{itemize}
  \tightlist
  \item
    To prevent this, stop checking so many p-values or adjust your
    expectations!
  \end{itemize}
\end{itemize}

\hypertarget{self-study-questions-4}{%
\section{Self-Study Questions}\label{self-study-questions-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We set up the null hypotheses as ``nothing interesting is going on''.
  In light of this, explain why power is a good thing.
\item
  If we're testing 5 hypotheses, what significance level should we use
  for each such that P(at least one type 1 error) = 0.05?
\item
  In simple (non-mathy) terms, explain why increasing sample size
  increases power.
\item
  If we have the hypotheses \(H_0:\mu = 1\) versus \(H_0:\mu = 2\), we
  can directly calculate the power. Run the following code to open the
  Shiny app, and interpret the results.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shiny}\SpecialCharTok{::}\FunctionTok{runGitHub}\NormalTok{(}\AttributeTok{repo =} \StringTok{"DBecker7/DB7\_TeachingApps"}\NormalTok{, }
    \AttributeTok{subdir =} \StringTok{"Tools/SimplePower"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{participation-questions}{%
\section{Participation Questions}\label{participation-questions}}

\hypertarget{q1}{%
\subsection{Q1}\label{q1}}

p-values are the probability of observing our data \emph{by chance
alone}.

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  True
\item
  False
\end{enumerate}

\hypertarget{q2}{%
\subsection{Q2}\label{q2}}

p-values are the probability of getting data at least this extreme under
the null hypothesis.

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  True
\item
  False
\end{enumerate}

\hypertarget{q3}{%
\subsection{Q3}\label{q3}}

p-values are a measure of evidence against the null hypothesis.

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  True
\item
  False
\end{enumerate}

\hypertarget{q4}{%
\subsection{Q4}\label{q4}}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
& \(H_0\) is TRUE & \(H_0\) is FALSE \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Don't Reject & Good! & Type 2 Error \\
Reject & Type 1 Error & Hooray! \\
\end{longtable}

In a particular hypothesis test, rejecting the null means diagnosing a
patient with cancer.

Select \emph{all} that are true.

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A low significance level means that I require strong evidence before I
  declare cancer.
\item
  A high power means that I'm more likely to diagnose someone with
  cancer, assuming they actually have cancer.
\item
  Low type 2 error means that I am less likely to miss true cancer
  diagnoses.
\item
  The probability of type 1 error is equal to the significance level
  \(\alpha\).
\end{enumerate}

\hypertarget{q5}{%
\subsection{Q5}\label{q5}}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
& \(H_0\) is TRUE & \(H_0\) is FALSE \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Don't Reject & Good! & Type 2 Error \\
Reject & Type 1 Error & Hooray! \\
\end{longtable}

In a particular hypothesis test, rejecting the null means diagnosing a
patient with cancer.

Which of the following is true about Type 1 and Type 2 error?

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increasing \(\alpha\) means I'm less likely to diagnose someone with
  cancer.
\item
  High power means I'm more likely to diagnose someone with cancer who
  actually has cancer.
\item
  The probability that my diagnosis is correct is 1 - P(Type 2 error).
\item
  A smaller significance level means I'll have less power.
\end{enumerate}

\hypertarget{crowdsourced-questions-8}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-8}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A type 1 error occurs when?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    A null hypothesis is not rejected but should be rejected
  \item
    A null hypothesis is rejected but should not be rejected
  \item
    A test statistic is incorrect
  \item
    None of the above are correct
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  is the correct answer -- In statistical hypothesis testing, a type 1
  error (also known as a ``false positive'') refers to the situation
  where the null hypothesis is incorrectly rejected when it is actually
  true. This means that the test concludes there is a significant effect
  or difference when, in reality, there is none.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Bottles of water have a label stating that the volume is 14 oz. A
  ST231 class suspects the bottles are underfilled and plans to conduct
  a test. A Type I error in this situation would mean:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    The ST231 class concludes the bottle has less than 14 oz, when the
    mean actually is 14 oz
  \item
    The ST231 class concludes the bottles has less than 14 oz when the
    mean actually is less than 14 oz
  \item
    The ST231 class has evidence that the label is incorrect
  \item
    A type 1 error does not occur but a Type 2 error does
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  is the correct answer because it aligns with the definition of a Type
  I error, which occurs when the null hypothesis (in this case, that the
  bottles have 14 oz) is incorrectly rejected, leading to the conclusion
  that the bottles have less than 14 oz when, in fact, they do have 14
  oz.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  A researcher conducts a hypothesis test with a significance level of
  0.05. What does this significance level represent?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    There is a 5\% chance of making a Type l error.
  \item
    There is a 5\% chance of making a Type ll error.
  \item
    There is a 95\% confidence level in the results
  \item
    There is a 95\% chance of the null hypothesis being true.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

a is the correct answer - the significance level 0.05 meant that there
is a 5\% chance of committing a Type l error, which means to reject the
null hypothesis when it is actually true. The significance level is
usually chosen by researchers to control the risk of making a Type l
error, it does not directly represent the probability of Type ll error.
The significance level does not specifically represent the confidence
interval.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  A researcher is designing a study to determine the effectiveness of a
  new drug in reducing blood pressure. They want to make sure that their
  study has enough power to detect a clinically meaningful difference in
  blood pressure if it actually exists. Which of the following actions
  would increase the statistical power of the study.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Increasing the sample size
  \item
    Decreasing the significance level
  \item
    Lowering the effect size
  \item
    Using a one-tailed test instead of a two-tailed test
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

a is the correct answer - increasing the sample size would increase the
statistical power. A larger sample size gives more information and
reduces the variability in the estimate of the population parameter
(mean or the effect size), making it more precise and easier to detect
smaller effects. The rest of the options don't increase the statistical
power.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  A new production procedure, according to the corporation, lowers the
  average product fault rate to less than 1\%. To assess this assertion,
  a statistical test is performed. A defect rate of less than 1\% is
  suggested by the alternative hypothesis (H1), contrary to the null
  hypothesis (H0), which maintains that the defect rate stays at 1\% or
  higher. The business rejects the null hypothesis after determining
  that the new manufacturing procedure effectively lowers the defect
  rate based on its analysis of the data. In this case, what kind of
  mistake might the corporation have made?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    The company correctly rejected the null hypothesis when the defect
    rate remains at 1\% or higher.
  \item
    The company erroneously rejected the null hypothesis when the defect
    rate remains at 1\% or higher.
  \item
    The company correctly failed to reject the null hypothesis when the
    defect rate is less than 1\%.
  \item
    The company erroneously failed to reject the null hypothesis when
    the defect rate is less than 1\%.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

The right answer is option (b). In this instance, the corporation made a
Type 1 error by mistakenly rejecting the null hypothesis (H0) when it
was true (the failure rate is still 1\% or greater). Due to a Type 1
error, the business came to the false conclusion that the new
manufacturing method effectively lowers the failure rate, which could
have led to poor resource allocation and decision-making.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  A team of experts is looking into how a new teaching strategy affects
  maths students' performance. In order to identify any significant
  changes in test results between the old and new teaching approaches,
  they want to make sure that their study has enough statistical power.
  Which of the following steps would most effectively boost their
  study's statistical power?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Increasing the sample size of students participating in the study.
  \item
    Decreasing the alpha level (significance level) used for hypothesis
    testing.
  \item
    Reducing the effect size of the difference in test scores between
    the teaching methods.
  \item
    Changing from a two-tailed test to a one-tailed test.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

A is the right answer. The study's statistical power would be improved
by expanding its sample size. More information is available and the
estimate of the population parameter's variability is decreased with a
larger sample size, which facilitates the detection of minor impacts.
There would be no direct increase in statistical power with options B,
C, and D. While it wouldn't impact statistical power, lowering the alpha
threshold would lessen the possibility of Type I mistakes. Reducing the
effect size would make it more difficult to identify differences, and
switching from a two-tailed test to a one-tailed test would not
automatically result in a higher power.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{confidence-intervals-in-practice}{%
\chapter{Confidence Intervals in
Practice}\label{confidence-intervals-in-practice}}

\hypertarget{recap}{%
\section{Recap}\label{recap}}

\hypertarget{silly-confidence-intervals}{%
\subsection{Silly confidence
intervals}\label{silly-confidence-intervals}}

If \(X\sim N(\mu,\sigma)\), where \(\sigma\) \emph{is known}, then a
\((1-\alpha)\)CI for \(\mu\) based on \(\bar x\) is: \[
\bar x \pm z^*\frac{\sigma}{\sqrt{n}}
\] where \(z^*\) is found such that \(P(Z < -z^*) = \alpha/2\),

\begin{itemize}
\tightlist
\item
  or we could have found \(z^*\) such that \(P(Z > z^*) = \alpha/2\),
\item
  or \(P(Z < z^*) = 1 - \alpha/2\),
\item
  or \(P(Z > -z^*) = 1 - \alpha/2\).
\end{itemize}

A natural question is: why not use \(s\), the \textbf{sample standard
deviation}?

To demonstrate why we can't just use \(s\), I have set up a simulation.
I like simulations.

You can safely skip the simulations if you're the type who wants to just
memorize a fact and will be sure to perfectly remember it later on. The
upshot is this: since we're estimating the standard deviation, the
normal distribution doesn't apply. Instead we use the \(t\) distribution
whenever we use \(s\).

\hypertarget{simulation-setup}{%
\subsection{Simulation Setup}\label{simulation-setup}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Take random values from the standard normal distribution.
\item
  Calculate the mean and sd.
\item
  Calculate the 95\% confidence interval with \(\sigma\) and with \(s\),
  both using a \(z\) value.
\item
  Record whether the population mean is in the interval.
\item
  Count how many intervals contain the population mean.

  \begin{itemize}
  \tightlist
  \item
    Should be 95\% of them!
  \end{itemize}
\end{enumerate}

Before we begin, I want to show some R code for finding confidence
intervals. If you're given that \(\bar x = 7.28\), \(n=15\),
\(\sigma = 1.24\), and you want to calculate a 95\% CI:\footnote{You'll
  need to do this sort of thing on a test/assignment.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z\_star }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{lower\_bound }\OtherTok{\textless{}{-}} \FloatTok{7.28} \SpecialCharTok{{-}}\NormalTok{ z\_star}\SpecialCharTok{*}\FloatTok{1.24}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{15}\NormalTok{)}
\NormalTok{upper\_bound }\OtherTok{\textless{}{-}} \FloatTok{7.28} \SpecialCharTok{+}\NormalTok{ z\_star}\SpecialCharTok{*}\FloatTok{1.24}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{15}\NormalTok{)}
\FunctionTok{c}\NormalTok{(lower\_bound, upper\_bound)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 6.652485 7.907515
\end{verbatim}

Alternatively, we can use \texttt{c(-1,\ 1)} to stand in for
``\(\pm\)''. The code is a little weird to get your head around, but
trust me - it works!

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{7.28} \SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{z\_star}\SpecialCharTok{*}\FloatTok{1.24}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 6.652485 7.907515
\end{verbatim}

Suppose that, unbeknownst to us, the true population mean was 7. To
check if this is in our calculated confidence interval, we have to check
that it's larger than the lower bound AND less than the upper bound:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{7} \SpecialCharTok{\textgreater{}} \FloatTok{7.28} \SpecialCharTok{{-}}\NormalTok{ z\_star}\SpecialCharTok{*}\FloatTok{1.24}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{15}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{7} \SpecialCharTok{\textless{}} \FloatTok{7.28} \SpecialCharTok{+}\NormalTok{ z\_star}\SpecialCharTok{*}\FloatTok{1.24}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{15}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

This can be combined into code as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{7} \SpecialCharTok{\textgreater{}} \FloatTok{7.28} \SpecialCharTok{{-}}\NormalTok{ z\_star}\SpecialCharTok{*}\FloatTok{1.24}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{15}\NormalTok{)) }\SpecialCharTok{\&}\NormalTok{ (}\DecValTok{7} \SpecialCharTok{\textless{}} \FloatTok{7.28} \SpecialCharTok{+}\NormalTok{ z\_star}\SpecialCharTok{*}\FloatTok{1.24}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{15}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

This is enough to set up the simulation. Basically, we're going to
generate a random data set from a known population, then check if the
confidence interval contains the true mean. We'll do this thousands of
times, and check which proportion contain the true mean. We're hoping
it's 95\%!

\hypertarget{simulation-code}{%
\subsection{Simulation Code}\label{simulation-code}}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Set up empty vectors, to be filled with TRUE or FALSE}
\DocumentationTok{\#\# if the population mean is in the interval}
\NormalTok{sigma\_does }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{() }\CommentTok{\# CI based on sigma does contain mu}
\NormalTok{s\_does }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{() }\CommentTok{\# CI based on s does contain mu}

\NormalTok{pop\_sd }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{pop\_mean }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{15} \CommentTok{\# sample size}

\NormalTok{z\_star }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.05} \SpecialCharTok{/} \DecValTok{2}\NormalTok{))}

\DocumentationTok{\#\# You aren\textquotesingle{}t expected to understand "for" loops, but}
\DocumentationTok{\#\# you need to be able to find CIs}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{100000}\NormalTok{) \{ }\CommentTok{\# repeat this code a bunch of times}
\NormalTok{    new\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{mean =}\NormalTok{ pop\_mean, }\AttributeTok{sd =}\NormalTok{ pop\_sd)}
\NormalTok{    xbar }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(new\_sample)}
\NormalTok{    samp\_sd }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(new\_sample)}

\NormalTok{    CI\_sigma }\OtherTok{\textless{}{-}}\NormalTok{ xbar }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ z\_star }\SpecialCharTok{*}\NormalTok{ pop\_sd }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)}
\NormalTok{    CI\_s }\OtherTok{\textless{}{-}}\NormalTok{ xbar }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ z\_star }\SpecialCharTok{*}\NormalTok{ samp\_sd }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)}
    \CommentTok{\# Do they contain the population mean?}
    \CommentTok{\# in other words, is the lower bound less than pop\_mean}
    \CommentTok{\# *and* is the upper bound larger than pop\_mean?}
    \CommentTok{\# (Not testable)}
\NormalTok{    sigma\_does[i] }\OtherTok{\textless{}{-}}\NormalTok{ (CI\_sigma[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\textless{}}\NormalTok{ pop\_mean) }\SpecialCharTok{\&}\NormalTok{ (CI\_sigma[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{\textgreater{}}\NormalTok{ pop\_mean)}
\NormalTok{    s\_does[i] }\OtherTok{\textless{}{-}}\NormalTok{ (CI\_s[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\textless{}}\NormalTok{ pop\_mean) }\SpecialCharTok{\&}\NormalTok{ (CI\_s[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{\textgreater{}}\NormalTok{ pop\_mean)}
\NormalTok{\}}

\DocumentationTok{\#\# The mean of a bunch of TRUEs and FALSEs is}
\DocumentationTok{\#\# the proportion of TRUEs (TRUE == 1, FALSE == 0)}
\FunctionTok{mean}\NormalTok{(sigma\_does)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.94887
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(s\_does)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.92991
\end{verbatim}

The CI based on \(s\) only contains \(\mu\) 93\% of the time! This is a
pretty big discrepancy. What happens when you increase the sample size,
n?\footnote{Re-run the code and try it!}

The reason for this discrepancy is shown in the next section:

\hypertarget{the-variance-has-variance}{%
\section{The Variance has Variance}\label{the-variance-has-variance}}

Recall that the \textbf{Sampling distribution} is all possible values of
a statistic when sampling from a population. We've covered the sampling
distribution for the sample mean: Every time you take a sample, you get
a different mean. The distribution of these sample means is
\(N(\mu,\sigma/\sqrt{n})\).

The same idea applies to the sample variance! Every time you take a
sample, you get a different variance. The sampling distribution is
\textbf{not} a normal distribution. In the next section, we'll
demonstrate this fact.

\hypertarget{simulation-sample-statistics}{%
\subsection{Simulation: sample
statistics}\label{simulation-sample-statistics}}

I'm going to generate a bunch of samples from a \(N(0, 0.2)\)
distribution. I'll calculate the mean and variance from each
distribution, then plot the histogram.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{pop\_mean }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{pop\_sd }\OtherTok{\textless{}{-}} \FloatTok{0.2}
\NormalTok{sample\_means }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{sample\_vars }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{100000}\NormalTok{) \{}
\NormalTok{    new\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{mean =}\NormalTok{ pop\_mean, }\AttributeTok{sd =}\NormalTok{ pop\_sd)}
\NormalTok{    sample\_means[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(new\_sample)}
\NormalTok{    sample\_vars[i] }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(new\_sample)}
\NormalTok{\}}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{hist}\NormalTok{(sample\_means, }\AttributeTok{breaks =} \DecValTok{25}\NormalTok{, }\AttributeTok{freq =} \ConstantTok{FALSE}\NormalTok{,}
    \AttributeTok{main =} \StringTok{"Sampling Dist of Sample Means"}\NormalTok{)}
\FunctionTok{curve}\NormalTok{(}\FunctionTok{dnorm}\NormalTok{(x, pop\_mean, pop\_sd }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{col =} \DecValTok{4}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\DocumentationTok{\#\# (n{-}1)s\^{}2/sigma\^{}2 follows a chi{-}square distribution on}
\DocumentationTok{\#\# n{-}1 degrees of freedom. If you understand this, you are}
\DocumentationTok{\#\# far too qualified to be taking this course. This fact}
\DocumentationTok{\#\# is outside the scope of the course.}
\FunctionTok{hist}\NormalTok{(sample\_vars }\SpecialCharTok{*}\NormalTok{ (n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (pop\_sd}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{), }\AttributeTok{breaks =} \DecValTok{25}\NormalTok{, }\AttributeTok{freq =} \ConstantTok{FALSE}\NormalTok{,}
    \AttributeTok{main =} \StringTok{"Sampling Dist of Sample Vars"}\NormalTok{)}
\FunctionTok{curve}\NormalTok{(}\FunctionTok{dchisq}\NormalTok{(x, n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{), }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{col =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L15-CI_for_Means_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\end{figure}

As you can tell from the fact that I knew how to draw the correct curve
on the plots, the sampling distributions for the mean and variance are
well known. Also, the sampling distribution for the variance is skewed,
and therefore cannot be normal!

When we use \(\bar x+ z^*s/\sqrt{n}\), \(\bar x\) has variance, but so
does \(s\).\footnote{Both are \textbf{random variables.}} This is why
the CI changes. When we know \(\sigma\), the \textbf{Margin of Error}
(MoE) is always the same. When the standard deviation changes for each
sample, so does the MoE.

\hypertarget{simulation-the-distribution-of-the-margin-of-error}{%
\subsection{Simulation: The Distribution of the Margin of
Error}\label{simulation-the-distribution-of-the-margin-of-error}}

The sampling distribution of the Margin of Error is interesting to look
at. This section is entirely optional - you just need to know that each
sample has a different margin of error.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{pop\_mean }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{pop\_sd }\OtherTok{\textless{}{-}} \FloatTok{0.2}
\NormalTok{sample\_MoEs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{z\_star }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.5}\SpecialCharTok{/}\DecValTok{2}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{100000}\NormalTok{)\{}
\NormalTok{    new\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n=}\NormalTok{n, }\AttributeTok{mean=}\NormalTok{pop\_mean, }\AttributeTok{sd=}\NormalTok{pop\_sd)}
\NormalTok{    sample\_MoEs[i] }\OtherTok{\textless{}{-}}\NormalTok{ z\_star}\SpecialCharTok{*}\FunctionTok{sd}\NormalTok{(new\_sample)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n)}
\NormalTok{\}}

\FunctionTok{hist}\NormalTok{(sample\_MoEs, }\AttributeTok{breaks =} \DecValTok{25}\NormalTok{,}
    \AttributeTok{main =} \StringTok{"Sampling Dist of MoE"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ z\_star}\SpecialCharTok{*}\NormalTok{pop\_sd}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n), }\AttributeTok{col =} \DecValTok{6}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L15-CI_for_Means_files/figure-pdf/sim_MoE-1.pdf}

}

\end{figure}

The vertical purple line is \(z^*\sigma/\sqrt n\).\footnote{Recall that
  this never changes since \(\sigma\) is fixed.} This is just a
re-scaling of the sampling distribution of the sample variance, so it's
also skewed! Furthermore, the average MoE using \(s\) is \emph{smaller}
than the MoE using \(\sigma\), even though it's right-skewed:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\StringTok{"MoE (sigma)"} \OtherTok{=}\NormalTok{ z\_star}\SpecialCharTok{*}\NormalTok{pop\_sd}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n),}
    \StringTok{"Average MoE (s)"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(sample\_MoEs))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    MoE (sigma) Average MoE (s) 
     0.04265848      0.04148352 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\StringTok{"MoE (sigma)"} \OtherTok{=}\NormalTok{ z\_star}\SpecialCharTok{*}\NormalTok{pop\_sd}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n),}
    \StringTok{"Median MoE (s)"} \OtherTok{=} \FunctionTok{median}\NormalTok{(sample\_MoEs))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   MoE (sigma) Median MoE (s) 
    0.04265848     0.04104300 
\end{verbatim}

This is why the CI using \(s\) doesn't capture the true mean as often -
it's giving us smaller intervals!

\hypertarget{removing-the-silliness}{%
\section{Removing the Silliness}\label{removing-the-silliness}}

The distribution of the sample variance is not important.\footnote{And
  very complicated.} Instead, we care about the confidence intervals.

I'm going to write this yet again: since
\(\bar X\sim N(\mu,\sigma/\sqrt{n})\)), \[
\frac{\bar X - \mu}{\sigma/\sqrt{n}} \sim N(0, 1)
\] That is, you take the sample means, subtract the mean of the means,
and divide by the \textbf{standard error}\footnote{the standard
  deviation of the sampling distribution}, and you get a standard normal
distribution.\footnote{The word ``standard'' shows up way too much.
  Statisticians are bad at naming things.}

On the other hand, if we use \(s\) (which has it's own variance), \[
\frac{\bar X - \mu}{s/\sqrt{n}} \sim t_{n-1}
\] where \(n-1\) is the \textbf{degrees of freedom} (or
\textbf{df}).\footnote{This is another example of statisticians being
  bad at naming things.} This is called the \(t\) distribution, and is a
lot like the normal distribution but it has higher variance.

Before we move on, notice how the formula with \(\sigma\) results in
N(0,1), which does not require any information for our sample. In the
\(t\) distribution, we need to know the sample size!

\hypertarget{the-t-distribution}{%
\subsection{The t distribution}\label{the-t-distribution}}

There are two main features of the \(t\) distribution that I want you to
know:

\begin{itemize}
\tightlist
\item
  It's centered at 0, just like N(0,1).
\item
  It's more variable than the normal distribution.
\end{itemize}

The second point is demonstrated in the following plot:

\includegraphics{L15-CI_for_Means_files/figure-pdf/unnamed-chunk-7-1.pdf}

The red line corresponds to a sample size of 2.\footnote{The degrees of
  freedom is \(n-1\).} As the colours move through red to blue, we
increase the sample size. At \(df = \infty\), the \(t\) distribution is
exactly the same as the N(0,1) distribution. For anything smaller, the
\(t\) distribution puts more probability in the tails.

This shows up in the critical values:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{abs}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)) }\CommentTok{\# z\^{}*}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.959964
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{abs}\NormalTok{(}\FunctionTok{qt}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{df =} \DecValTok{15} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\CommentTok{\# t\^{}* n = 15}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.144787
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{abs}\NormalTok{(}\FunctionTok{qt}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{df =} \DecValTok{30} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\CommentTok{\# n = 30}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.04523
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{abs}\NormalTok{(}\FunctionTok{qt}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{df =} \DecValTok{50} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\CommentTok{\# n = 50}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.009575
\end{verbatim}

Note that, just like how \texttt{qbinom} finds the value such of a
binomial distribution such that 0.025\% of the distribution is to the
left and \texttt{qnorm} finds the z-values such that 0.025 is to the
left, \texttt{qt}\footnote{The person reading this is a cutie.} finds
the t-value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_seq }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{100}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{)}
\NormalTok{t\_seq }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{qt}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{df =}\NormalTok{ n\_seq}\DecValTok{{-}1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(n\_seq, t\_seq, }\AttributeTok{type =} \StringTok{"b"}\NormalTok{,}
    \AttributeTok{ylab =} \StringTok{"abs(qt(0.05/2, df = n {-} 1))"}\NormalTok{,}
    \AttributeTok{xlab =} \StringTok{"n"}\NormalTok{,}
    \CommentTok{\# the code for the title is not important.}
    \AttributeTok{main =} \FunctionTok{bquote}\NormalTok{(}\StringTok{"As df {-}\textgreater{} infinity, t"}\SpecialCharTok{\^{}}\StringTok{"*"}\SpecialCharTok{*}\StringTok{" {-}\textgreater{} z"}\SpecialCharTok{\^{}}\StringTok{"*"}\NormalTok{))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \FunctionTok{abs}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)), }\AttributeTok{col =} \DecValTok{3}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\DocumentationTok{\#\# this code just puts a label on the axis {-} not important}
\FunctionTok{axis}\NormalTok{(}\DecValTok{2}\NormalTok{, }\FunctionTok{abs}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)), }\StringTok{"z*"}\NormalTok{, }\AttributeTok{col =} \DecValTok{3}\NormalTok{, }\AttributeTok{font =} \DecValTok{2}\NormalTok{, }\AttributeTok{col.axis =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L15-CI_for_Means_files/figure-pdf/unnamed-chunk-9-1.pdf}

}

\end{figure}

Since there's more probability in the tails, you have to go further out
to find the point such that 0.025 of the distribution is to the
left.\footnote{Try this for other \(\alpha\) values and larger \(n\).}
The \(t\) distribution allows for more variance due to the variance of
\(s\), and it does this by having larger critical values.

\hypertarget{the-t-distribution-1}{%
\subsection{\texorpdfstring{The
\(t\)-distribution}{The t-distribution}}\label{the-t-distribution-1}}

The \(t\) distribution has higher variance than the Normal distribution
due to the extra uncertainty in estimating \(s\).

\hypertarget{the-t-confidence-interval}{%
\section{\texorpdfstring{The \(t\) Confidence
Interval}{The t Confidence Interval}}\label{the-t-confidence-interval}}

Now that you understand the reasoning behind using wider confidence
intervals, I can show you the formula/ \[
\bar x \pm t_{n-1}^*s/\sqrt{n}
\]

where \(t^*_{n-1}\) comes from
\texttt{abs(qt(alpha/2,\ df\ =\ n-1))}.\footnote{Note: I'm not even
  going to bother writing out the \(P()\) notation for \(t^*_{n-1}\)
  because you'll never use it. You'll only ever need to find
  \(t^*_{n-1}\) in this course.}

This has the same interpretation as the Z CI: 95\% of the intervals
constructed this way will contain the true population mean. This does
\textbf{NOT} mean that there's a 95\% chance that the interval contains
the true mean.

What's that? Of course, I can demonstrate by simulation! Thanks for
asking! The following code is copied and pasted from above, only the
critical value has been changed.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Set up empty vectors, to be filled with TRUE or FALSE}
\DocumentationTok{\#\# if the population mean is in the interval}
\NormalTok{sigma\_does }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{() }\CommentTok{\# CI based on sigma does contain mu}
\NormalTok{s\_does }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{() }\CommentTok{\# CI based on s does contain mu}

\NormalTok{pop\_sd }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{pop\_mean }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{15} \CommentTok{\# sample size}

\NormalTok{z\_star }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{t\_star }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{qt}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\CommentTok{\# NEW}

\DocumentationTok{\#\# You aren\textquotesingle{}t expected to understand "for" loops, but}
\DocumentationTok{\#\# you need to be able to find CIs}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{100000}\NormalTok{)\{ }\CommentTok{\# repeat this code a bunch of times}
\NormalTok{    new\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n, }\AttributeTok{mean =}\NormalTok{ pop\_mean, }\AttributeTok{sd =}\NormalTok{ pop\_sd)}
\NormalTok{    xbar }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(new\_sample)}
\NormalTok{    samp\_sd }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(new\_sample)}

\NormalTok{    CI\_sigma }\OtherTok{\textless{}{-}}\NormalTok{ xbar }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{z\_star}\SpecialCharTok{*}\NormalTok{pop\_sd}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n)}
\NormalTok{    CI\_s }\OtherTok{\textless{}{-}}\NormalTok{ xbar }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{t\_star}\SpecialCharTok{*}\NormalTok{samp\_sd}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n) }\CommentTok{\# NEW}
    \CommentTok{\# Do they contain the population mean?}
    \CommentTok{\# in other words, is the lower bound less than pop\_mean}
    \CommentTok{\# *and* is the upper bound larger than pop\_mean?}
    \CommentTok{\# (Not testable)}
\NormalTok{    sigma\_does[i] }\OtherTok{\textless{}{-}}\NormalTok{ (CI\_sigma[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\textless{}}\NormalTok{ pop\_mean) }\SpecialCharTok{\&}\NormalTok{ (CI\_sigma[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{\textgreater{}}\NormalTok{ pop\_mean)}
\NormalTok{    s\_does[i] }\OtherTok{\textless{}{-}}\NormalTok{ (CI\_s[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\textless{}}\NormalTok{ pop\_mean) }\SpecialCharTok{\&}\NormalTok{ (CI\_s[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{\textgreater{}}\NormalTok{ pop\_mean)}
\NormalTok{\}}

\DocumentationTok{\#\# The mean of a bunch of TRUEs and FALSEs is}
\DocumentationTok{\#\# the proportion of TRUEs (TRUE == 1, FALSE == 0)}
\FunctionTok{mean}\NormalTok{(sigma\_does)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.95069
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(s\_does)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.95091
\end{verbatim}

Now both of them contain the mean 95\% of the time!\footnote{This means
  it's working!} The difference between them is that the t CI doesn't
have as much information as the Z CI - the Z CI knows what the
population sd is, but the t CI doesn't. This is kinda magical: using
math, we can get the truth with fewer assumptions!

\hypertarget{examples-5}{%
\section{Examples}\label{examples-5}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\bar x = 0.4\), \(n = 100\), \(\sigma = 0.01\), find the 92\%CI.

  \begin{itemize}
  \tightlist
  \item
    This is a bit of a trick: I gave you \(\sigma\)! This always refers
    to the population standard deviation, so that's what it is here. The
    Z CI can be found with the R code:
  \end{itemize}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{0.4} \SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{abs}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.08}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{*} \FloatTok{0.01}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3982493 0.4017507
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \(\bar x = 0.4\), \(n = 100\), \(s = 0.01\), will a 92\%CI be
  \emph{wider than} or \emph{smaller than} the CI from Example 1?

  \begin{itemize}
  \tightlist
  \item
    We use \(t\) to account for the extra variance we have when we
    estimate \(s\). More variance means wider tails! The CI will be
    wider!
  \end{itemize}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{0.4} \SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{abs}\NormalTok{(}\FunctionTok{qt}\NormalTok{(}\FloatTok{0.08}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{df =} \DecValTok{100{-}1}\NormalTok{)) }\SpecialCharTok{*} \FloatTok{0.01}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3982312 0.4017688
\end{verbatim}

It's only slightly wider. The sample size is large enough that the
variance in the estimate is small.\footnote{Recall: For both the sample
  mean and the sample proportion, the variance of the sampling
  distribution decreases as \(n\) increases.} Try this again with a
smaller \(n\) and see what happens to the difference!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  If \(n=16\) and the 95\%CI for \(\mu\) is (10, 15), what's the
  variance?

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    A general form of the CI is \(\bar x \pm t^* s/\sqrt{n}\).

    \begin{itemize}
    \tightlist
    \item
      \(\bar x\) is in the centre, so \(\bar x\) is 12.5
    \end{itemize}
  \item
    The MoE is 2.5, so \(t^* s/\sqrt{n} = 2.5\).

    \begin{itemize}
    \tightlist
    \item
      \(t^*\) is \texttt{qt(0.05/2,\ 16\ -\ 1)} = 2.131
    \end{itemize}
  \item
    \(2.131s/\sqrt{16} = 2.5\), so \(s = 2.5\sqrt{16}/2.131 = 4.69\)
  \item
    The variance is \(4.69^2 = 21.9961\)
  \end{enumerate}
\end{enumerate}

\hypertarget{real-example}{%
\section{Real Example}\label{real-example}}

The following heights were collected from Laurier's athletics page.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# }
\NormalTok{ft }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{inch }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{11}\NormalTok{)}

\NormalTok{heights }\OtherTok{\textless{}{-}} \FloatTok{30.48} \SpecialCharTok{*}\NormalTok{ ft }\SpecialCharTok{+} \FloatTok{2.54} \SpecialCharTok{*}\NormalTok{ inch}
\FunctionTok{hist}\NormalTok{(heights)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \FloatTok{162.3}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L15-CI_for_Means_files/figure-pdf/unnamed-chunk-13-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(heights)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 170.7573
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{length}\NormalTok{(heights)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 22
\end{verbatim}

Assuming that we know the population standard deviation
\(\sigma = 7.1\), we can make a 89\% CI:

\[
\bar x \pm z^*\frac{\sigma}{\sqrt{n}}
\]

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(heights) }\SpecialCharTok{+} \FunctionTok{qnorm}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.89}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2}\NormalTok{) }\SpecialCharTok{*} \FloatTok{7.1} \SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{length}\NormalTok{(heights))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 168.338
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(heights) }\SpecialCharTok{{-}} \FunctionTok{qnorm}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.89}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2}\NormalTok{) }\SpecialCharTok{*} \FloatTok{7.1} \SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{length}\NormalTok{(heights))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 173.1765
\end{verbatim}

But is it reasonable to say that the standard deviation of athletic
women's heights is the same as the standard deviation of the heights in
the population of all the women?

\hypertarget{the-t-ci}{%
\subsection{The t CI}\label{the-t-ci}}

It's probably silly that we think that the standard deviation for all
Canadian women applies here.

With a different sample, we would have gotten a different sample
standard deviation! We need to account for this extra source of variance
while creating the CI - we do this with the t distribution.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(heights) }\SpecialCharTok{+} \FunctionTok{qt}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.89}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\AttributeTok{df =} \FunctionTok{length}\NormalTok{(heights) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{sd}\NormalTok{(heights) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{length}\NormalTok{(heights))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 168.0833
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(heights) }\SpecialCharTok{{-}} \FunctionTok{qt}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.89}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\AttributeTok{df =} \FunctionTok{length}\NormalTok{(heights) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{sd}\NormalTok{(heights) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{length}\NormalTok{(heights))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 173.4313
\end{verbatim}

We'll rarely have to go through this calculation again in this class.
Instead, R does the calculations for us and we do the hard work
(interpretations).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(heights, }\AttributeTok{conf.level =} \FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  heights
t = 106.57, df = 21, p-value < 2.2e-16
alternative hypothesis: true mean is not equal to 0
89 percent confidence interval:
 168.0833 173.4313
sample estimates:
mean of x 
 170.7573 
\end{verbatim}

\hypertarget{bonus---webscraping}{%
\subsection{Bonus - Webscraping}\label{bonus---webscraping}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rvest)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(ggplot2)}

\CommentTok{\# Read in web pages}
\NormalTok{basketball }\OtherTok{\textless{}{-}} \FunctionTok{read\_html}\NormalTok{(}\StringTok{"https://laurierathletics.com/sports/womens{-}basketball/roster"}\NormalTok{)}
\NormalTok{soccer }\OtherTok{\textless{}{-}} \FunctionTok{read\_html}\NormalTok{(}\StringTok{"https://laurierathletics.com/sports/wsoc/roster"}\NormalTok{)}
\NormalTok{hockey }\OtherTok{\textless{}{-}} \FunctionTok{read\_html}\NormalTok{(}\StringTok{"https://laurierathletics.com/sports/whock/roster"}\NormalTok{)}

\CommentTok{\# Extract the stats tables}
\NormalTok{bstats }\OtherTok{\textless{}{-}} \FunctionTok{html\_table}\NormalTok{(basketball)[[}\DecValTok{3}\NormalTok{]]}
\NormalTok{sstats }\OtherTok{\textless{}{-}} \FunctionTok{html\_table}\NormalTok{(soccer)[[}\DecValTok{3}\NormalTok{]]}
\NormalTok{hstats }\OtherTok{\textless{}{-}} \FunctionTok{html\_table}\NormalTok{(hockey)[[}\DecValTok{3}\NormalTok{]]}

\CommentTok{\# Combine into one data frame}
\NormalTok{bstats}\SpecialCharTok{$}\NormalTok{Sport }\OtherTok{\textless{}{-}} \StringTok{"Basketball"}
\NormalTok{hstats}\SpecialCharTok{$}\NormalTok{Sport }\OtherTok{\textless{}{-}} \StringTok{"Hockey"}
\NormalTok{sstats}\SpecialCharTok{$}\NormalTok{Sport }\OtherTok{\textless{}{-}} \StringTok{"Soccer"}
\CommentTok{\# There are, like 5 things here that experienced R users might not know.}
\NormalTok{stats }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(bstats, hstats, sstats) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{select}\NormalTok{(}\AttributeTok{Number =}\NormalTok{ No., }\AttributeTok{Pos =}\NormalTok{ Pos., }\AttributeTok{Height =}\NormalTok{ Ht.,}
        \AttributeTok{Year =} \StringTok{\textasciigrave{}}\AttributeTok{Academic Year}\StringTok{\textasciigrave{}}\NormalTok{, Major, Sport,}
        \AttributeTok{EligYear =} \StringTok{\textasciigrave{}}\AttributeTok{Elig. Yr.}\StringTok{\textasciigrave{}}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
\NormalTok{    tidyr}\SpecialCharTok{::}\FunctionTok{separate}\NormalTok{(Height, }\AttributeTok{sep =} \StringTok{"{-}"}\NormalTok{,}
        \AttributeTok{into =} \FunctionTok{c}\NormalTok{(}\StringTok{"ft"}\NormalTok{, }\StringTok{"inch"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Height =} \FunctionTok{as.numeric}\NormalTok{(ft) }\SpecialCharTok{*} \FloatTok{30.48} \SpecialCharTok{+} \FunctionTok{as.numeric}\NormalTok{(inch) }\SpecialCharTok{*} \FloatTok{2.24}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{ft, }\SpecialCharTok{{-}}\NormalTok{inch)}
\FunctionTok{head}\NormalTok{(stats)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 6 x 7
  Number Pos   Year  Major         Sport      EligYear Height
   <int> <chr> <chr> <chr>         <chr>         <int>  <dbl>
1     14 G     4th   Business      Basketball       NA   168.
2      9 F     2nd   Kin/Phys. Ed. Basketball       NA   175.
3     11 F     3rd   Poli Sci      Basketball       NA   183.
4      4 G     2nd   Philosophy    Basketball       NA   166.
5      5 G     3rd   Business      Basketball       NA   168.
6     13 G     2nd   Kin/Phys. Ed. Basketball       NA   175.
\end{verbatim}

The code above gets all of the heights from the hockey, soccer, and
basketball teams (thank you Laurier Athletecs for having well-structured
wed pages!).

Let's take a minute to explore these data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(stats) }\SpecialCharTok{+}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Sport, }\AttributeTok{y =}\NormalTok{ Height) }\SpecialCharTok{+}
    \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Heights by sport"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L15-CI_for_Means_files/figure-pdf/gg_stats-1.pdf}

}

\end{figure}

For now, let's focus on the basketball team. The following code finds a
95\%CI. It also tests the hypothesis that the true mean height is 0, so
we'll ignore that for now.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Just the heights of basketball players}
\NormalTok{ballers }\OtherTok{\textless{}{-}}\NormalTok{ stats}\SpecialCharTok{$}\NormalTok{Height[stats}\SpecialCharTok{$}\NormalTok{Sport }\SpecialCharTok{==} \StringTok{"Basketball"}\NormalTok{]}
\FunctionTok{mean}\NormalTok{(ballers)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 172.1771
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(ballers)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.641504
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{length}\NormalTok{(ballers)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 14
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ ballers) }\SpecialCharTok{+}
    \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{bins =} \DecValTok{15}\NormalTok{, }\AttributeTok{fill =} \StringTok{"dodgerblue"}\NormalTok{, }\AttributeTok{colour =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \FloatTok{162.3}\NormalTok{, }\AttributeTok{colour =} \StringTok{"red"}\NormalTok{, }\AttributeTok{linewidth =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L15-CI_for_Means_files/figure-pdf/gg_ballers-1.pdf}

}

\end{figure}

In the histogram above, our data look somewhat normal. If this sample is
representative of the population, then we might guess that the
population\footnote{In this example, the population refers to the
  population of female varsity basketball players.} looks somewhat
normal. However, a sample size of 14 is probably too small to make
reliable conclusions.

I put a red line at the height of 163.2, the height of women in the
general population. It seems like 163.2 would be not be a reasonable
value in this sample, but could it be a reasonable guess at the overall
mean? Let's use a CI and a t-test to find out:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(ballers, }\AttributeTok{conf.level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  ballers
t = 138.8, df = 13, p-value < 2.2e-16
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 169.4972 174.8571
sample estimates:
mean of x 
 172.1771 
\end{verbatim}

A 95\% CI is (169.5, 174.9), which clearly does not contain 163.2. Since
we're 95\% confident that the true population mean is in our CI, so
162.3 is unlikely to be the true mean.

To test the hypothesis that this is greater than the general population,
we still do a t-test. We just have to tell R what kind of test we want
to do. As always, we have to set the significance level. Since we're not
skeptical about the alternate hypothesis, let's set it to 10\%. This
says that we don't need particularly strong evidence before we reject
the null hypothesis.

We are testing whether the basketball players are taller than the
general population. In symbols:

\[
H_0: \mu = 163.2 \text{ versus } H_A: \mu > 163.2
\]

The R code to test this is below:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(ballers, }\AttributeTok{mu =} \FloatTok{162.3}\NormalTok{, }\AttributeTok{alternative =} \StringTok{"greater"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  ballers
t = 7.9623, df = 13, p-value = 1.177e-06
alternative hypothesis: true mean is greater than 162.3
95 percent confidence interval:
 169.9803      Inf
sample estimates:
mean of x 
 172.1771 
\end{verbatim}

Our p-value is 0.00000177. This is a very small p-value, which means we
have strong evidence against the null. We reject the null hypothesis,
and conclude that the average of female varisty basketball players is
taller than the general population (an unsurprising result, but nice to
have confirmation).

\hypertarget{summary-7}{%
\section{Summary}\label{summary-7}}

This lesson could have been two sentences: The sample standard deviation
has variance, so each confidence interval based on \(s\) is slightly
different. To account for this, we use the \(t\) distribution. Then
again, when someone tells me their name at a party I immediately forget
it. Hopefully this long-winded exploration helps you understand why
these facts are true and how they're relevant to the course.

Note that all of the best practices for inference still apply! We can
still get smaller intervals by taking better samples with larger sample
sizes, and we still have to be careful to \emph{never} speak of a
calculated confidence interval in terms of chance.

The \(t\) confidence interval is actually used in practice. We saw some
code that calculates the interval for us in this lecture, and we'll
never have to use \texttt{qt()} again! (Except possibly to demonstrate
knowledge on tests.)

\hypertarget{self-study-questions-5}{%
\chapter{Self-Study Questions}\label{self-study-questions-5}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain the confidence interval that we found in the basketball player
  example.

  \begin{itemize}
  \tightlist
  \item
    For feedback, try the following in ChatGPT, Google Gemini, or Bing
    Chat: ``In a sample of basketball players, a 95\%CI was calculated
    as (169.5, 174.9). My explanation is: !!!!!put your explanation
    here!!!!!. Please rate my explanation as if it's an answer on an
    exam in an introductory statistics course.''
  \end{itemize}
\item
  Explain very clearly why we checked whether 162.3 was in our interval.
\item
  Repeat the example of creating a CI for basketball players, except for
  hockey players. The code below creates the data for hockey players. If
  you'd prefer to use a calculator, I also provide the mean and sd
  (you'll still need to calculate critical value from the \(t\)
  distribution).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pucks }\OtherTok{\textless{}{-}}\NormalTok{ stats}\SpecialCharTok{$}\NormalTok{Height[stats}\SpecialCharTok{$}\NormalTok{Sport }\SpecialCharTok{==} \StringTok{"Hockey"}\NormalTok{]}
\FunctionTok{mean}\NormalTok{(pucks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 165.2128
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(pucks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.55038
\end{verbatim}

A plot of the values is below to help with your interpretation:

\includegraphics{L15-CI_for_Means_files/figure-pdf/unnamed-chunk-24-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  In 2014,
  \href{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4128611/}{Dr.~S.
  Hooker published a paper} claiming to find a link between vaccines and
  autism, but only for African American boys. In the paper, Dr.~Hooker
  tested 35 p-values and found 2 were less than the significance level
  of 0.05.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Using the binomial distribution, find the probability of at least 2
    successes in 35 trials when the probability is 0.05\%.
  \item
    Interpret the probability in part (a) in terms of the vaccines
    study.
  \item
    The 35 trials came from not just testing for a link, but splitting
    up the data by race, gender, and vaccine timing so that there were
    more hypothesis tests. This is known as ``p-hacking''. Explain why
    this will often lead to statistically significant results, even when
    the null hypothesis is true.
  \end{enumerate}
\end{enumerate}

\textbf{Q4 Solution}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{size =} \DecValTok{35}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.05}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5279735
\end{verbatim}

This calculation assumes that all of the null hypotheses are true (as we
should do when calculating p-values). Under this assumption, there's
about a 50\% chance of getting 2 or more significant results, even if
there's nothing going on. This is vastly different than the ``5\% risk
of rejecting a true null'' that we get when setting our significance
level.

Use \href{https://projects.fivethirtyeight.com/p-hacking/}{this app} to
play around with p-hacking and see why it's so dangerous!

\hypertarget{crowdsourced-questions-9}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-9}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Which of the following statements is false about degrees of freedom
  (df) for a one-sample t-test?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    df = n - 1, where n is the number of items in your sample.
  \item
    Degrees of freedom refer to how many values in your data can change
    without breaking any rules.
  \item
    The higher the degrees of freedom, the more the t-distribution
    resembles a normal distribution.
  \item
    Degrees of freedom always equal the number of items in your dataset.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

D is false because degrees of freedom (df) are calculated based on the
sample size minus the number of parameters estimated. For example, in a
simple t-test, df = n - 1, where n is the sample size. Degrees of
freedom are not simply equal to the number of items but reflect the
number of values that are free to vary in the calculation of a
statistic, taking into account any constraints such as parameters
estimated.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  A survey was carried out to estimate the average daily screen time of
  university students. A 90\% confidence interval for the mean daily
  screen time was found to be (3 hours, 5 hours). How should this
  confidence interval be interpreted?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    The true average daily screen time of all university students is
    between 3 hours and 5 hours.
  \item
    There is a 90\% confidence that the average daily screen time for
    university students is within the 3 to 5 hours range.
  \item
    90\% of university students have a daily screen time between 3 and 5
    hours.
  \item
    There is a 10\% chance that the true average daily screen time for
    university students is not between 3 and 5 hours.
  \end{enumerate}
\end{enumerate}

\textbf{Solution}

b is the correct answer - The 90\% confidence interval means that if we
were to replicate this survey multiple times, each time calculating a
new 90\% confidence interval for the mean daily screen time from
different samples, about 90\% of these intervals would be expected to
contain the true mean daily screen time for the population. It
demonstrates our level of confidence in the interval's ability to
capture the true population parameter, not the distribution of
individual screen times.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{t-tests-for-a-mean}{%
\chapter{t-Tests for a Mean}\label{t-tests-for-a-mean}}

\hypertarget{when-we-use-s-we-use-t}{%
\section{\texorpdfstring{When we use \(s\), we use
\(t\)}{When we use s, we use t}}\label{when-we-use-s-we-use-t}}

We've been over this in confidence intervals, and the same thing applies
to hypothesis tests! If the population is normal (or the sample size is
large enough) and we have an SRS, then \[
\frac{\bar X - \mu}{s/\sqrt{n}}\sim t_{n-1}
\]

Again, the \(t\) distribution is used to account for the extra
variability from the estimated standard deviation.\footnote{Which is
  used in the caclulation of the Estimated Standard Error.}

This means our test statistic is \[
t_{obs} = \frac{\bar x - \mu}{s/\sqrt{n}}
\]

Since this is a \(t\) distibution, we use
\texttt{pt(t\_obs,\ df\ =\ n\ -1)}, possibly one minus and/or double,
depending on the alternate hypothesis.\footnote{Like \texttt{pnorm()},
  it always calculates the probability below the test statistic.}

That's it. That's the big difference. When we estimate the standard
deviation, we use the t-distribution.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{The t-test for a population mean}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

Given a sample mean \(\bar x\) and a sample standard deviation \(s\),
our test statistic is: \[
t_{obs} = \frac{\bar x - \mu}{s/\sqrt{n}}
\] Our hypotheses and calculations of the p-value work the same as they
did for the z-test.

\end{tcolorbox}

\hypertarget{examples-6}{%
\section{Examples}\label{examples-6}}

\hypertarget{pilot-fatigue}{%
\subsection{Pilot Fatigue}\label{pilot-fatigue}}

In the pilot fatigue example from the Understanding p-values lecture, we
assumed that we had the population sd. I lied - it was actually a sample
statistic! We should have used a t-test, not a z test.

Recall:

\begin{itemize}
\tightlist
\item
  \(H_0: \mu = 15\) versus \(H_A: \mu > 15\) with
\item
  \(n = 16\), \(\bar x = 15.9\), \(s = 1.2\) (not \(\sigma\)) \[
  t_{obs} = \frac{15.9 - 15}{1.2/\sqrt{16}} = 3
  \]
\end{itemize}

Using the \(t\) distribution, our p-value is:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pt}\NormalTok{(}\DecValTok{3}\NormalTok{, }\AttributeTok{df =} \DecValTok{16} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.004486369
\end{verbatim}

This is \emph{larger} than our previous p-value of 0.0013. This will
always be the case: if the \(z_{obs}\) test statistic is the same as the
\(t_{obs}\) test statistic, then the p-value for \(t_{obs}\) will be
wider.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{p-values from a t-test are larger than a z-test (if you have
\(\sigma=s\))}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

We almost never know the population standard deviation, so we have extra
uncertainty. With extra uncertainty, we require more \emph{evidence}!
Recall that a p-value is a measure of evidence against a null.

\end{tcolorbox}

\hypertarget{matched-pairs}{%
\section{Matched Pairs}\label{matched-pairs}}

A matched pairs design allows us to use a one-sample t-test when it
looks like we have two samples\footnote{We'll learn about two-sample
  t-tests in the next lecture.}. Since the pairs are matched, we can
calculate the differences between pairs and treat this like a single
vector of observations. It is honkey tonk ridonkulous to say that we
know the true population standard deviation for the difference in
observations, so a \(z\) test could never be appropriate.

Consider the following example of a matched pairs experiment. Given a
sample of brave volounteers, we create a small cut on both hands and put
ointment on one of the two cuts\footnote{And most likely a bandage on
  both.}. This study design eliminates the variation in healing times
for different people since both cuts are on the same person! For each
individual, we observe a \emph{difference}. That is, one observation per
person!

\begin{longtable}[]{@{}lllllllll@{}}
\toprule\noalign{}
& Subject 1 & S2 & S3 & S4 & S5 & S6 & S7 & S8 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
With Ointment & 6.44 & 6.06 & 4.22 & 3.3 & 6.5 & 3.49 & 7.01 & 4.22 \\
Without & 7.22 & 6.05 & 4.55 & 4 & 6.7 & 2.88 & 7.88 & 6.32 \\
Difference & -0.78 & 0.01 & -0.33 & -0.7 & -0.2 & 0.61 & -0.87 & -2.1 \\
\end{longtable}

\emph{Note}: Differences were calculated as ``With minus Without''! This
will be important for setting up the alternative hypothesis later.

The important thing here is that last row of this table now represents
our data - we can forget that the other two rows exist! In other words,
we have \emph{one} observation per person, rather than two sets of
observations.

This is where the assumption that we know the population standard
deviation is especially preposterous: we're looking just at the
differences! Even if there's a true value of the sd for healing time for
all people, the standard deviation of the difference between healing
times isn't a reasonable quantity to speak of.

Since we're looking at the \emph{difference}, we no longer have a
hypothesized value of \(\mu_0\). Instead, we hypothesize that the
average pairwise difference is 0,
i.e.~\(\mu_{with\; minus\; without} = \mu_{diff} = 0\)\footnote{In other
  words, the healing times are the same for each subject}. The
alternative is ``with'' \textless{} ``without'',
i.e.~\(\mu_{diff} < 0\).\footnote{This is where it's important to know
  that we did ``with minus without''; we could have done without minus
  with, but then our alternate hypotheses would need to be
  ``\textgreater{}''.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.78}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.33}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.7}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.61}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.87}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{2.1}\NormalTok{)}
\NormalTok{xbar }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(x)}
\NormalTok{s }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(x)}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(x)}

\NormalTok{t\_obs }\OtherTok{\textless{}{-}}\NormalTok{ (xbar }\SpecialCharTok{{-}} \DecValTok{0}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(s}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n)) }\CommentTok{\# xbar is with {-} w/out}
\CommentTok{\# Notice that we use pt() instead of pnorm()}
\FunctionTok{pt}\NormalTok{(t\_obs, }\AttributeTok{df =}\NormalTok{ n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\CommentTok{\# Alternative is \textless{}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.04662624
\end{verbatim}

So our p-value is approximately 0.04. At the 5\% level, the null
hypothesis would be rejected and we would conclude that the ointment
works\footnote{A p-value says \emph{nothing} about the effect size, so
  we can't say whether it's \textbf{practically significant}}. At the
1\% level, we would conclude that it doesn't have a significant effect.
This is why it's important to know the significance level before
calculating the p-value - we shouldn't get to choose whether our results
are statistically significant!

\hypertarget{t-tests-in-practice}{%
\subsection{t-tests in Practice}\label{t-tests-in-practice}}

Do you think that researchers in the field are typing test statistics
into their calculator? Of course not! We're finally at the point in this
class where the methods are so commonly used that the built-in functions
in R can calculate them.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{with\_oint }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{6.44}\NormalTok{, }\FloatTok{6.06}\NormalTok{, }\FloatTok{4.22}\NormalTok{, }\FloatTok{3.3}\NormalTok{, }\FloatTok{6.5}\NormalTok{, }\FloatTok{3.49}\NormalTok{, }\FloatTok{7.0}\NormalTok{, }\FloatTok{4.22}\NormalTok{)}
\NormalTok{without }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{7.22}\NormalTok{, }\FloatTok{6.05}\NormalTok{, }\FloatTok{4.55}\NormalTok{, }\DecValTok{4}\NormalTok{  , }\FloatTok{6.7}\NormalTok{, }\FloatTok{2.88}\NormalTok{, }\FloatTok{7.8}\NormalTok{, }\FloatTok{6.32}\NormalTok{)}
\NormalTok{difference }\OtherTok{\textless{}{-}}\NormalTok{ with\_oint }\SpecialCharTok{{-}}\NormalTok{ without}
\FunctionTok{t.test}\NormalTok{(difference, }\AttributeTok{alternative =} \StringTok{"less"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  difference
t = -1.9199, df = 7, p-value = 0.04817
alternative hypothesis: true mean is less than 0
95 percent confidence interval:
         -Inf -0.007063183
sample estimates:
mean of x 
 -0.53625 
\end{verbatim}

Notice that the output shows a \textbf{one-sided confidence interval}.
This isn't a big leap from what you know: a confidence interval consists
of all of the values that would \emph{not} be rejected by a hypothesis
test, and this works for one-sided as well as two-sided alternate
hypotheses!

To get a two-sided confidence interval, we can either leave
\texttt{alternative} at it's default value or set it to
\texttt{"two.sided"}. We can also change the significance level with the
\texttt{conf.level} argument. For an 89\%CI:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(difference, }\AttributeTok{alternative =} \StringTok{"two.sided"}\NormalTok{, }\AttributeTok{conf.level =} \FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  difference
t = -1.9199, df = 7, p-value = 0.09635
alternative hypothesis: true mean is not equal to 0
89 percent confidence interval:
 -1.04730428 -0.02519572
sample estimates:
mean of x 
 -0.53625 
\end{verbatim}

Notice that this calculated a two-sided p-value, which is twice what we
saw before (and no longer significant at the 5\% level!).

\hypertarget{recap-1}{%
\section{Recap}\label{recap-1}}

\hypertarget{hypothesis-tests-in-general}{%
\subsection{Hypothesis Tests in
General}\label{hypothesis-tests-in-general}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Decide on a hypothesis.

  \begin{itemize}
  \tightlist
  \item
    \(H_0: \mu = \mu_0\) versus
    \(H_a: \mu [\ne,>,\text{ or }<] \mu_0\)\lspace
  \end{itemize}
\item
  Choose a significance level \(\alpha\).

  \begin{itemize}
  \tightlist
  \item
    Smaller leverl = require more evidence to reject the null.\lspace
  \end{itemize}
\item
  Gather data

  \begin{itemize}
  \tightlist
  \item
    Independent observations from same population; random sample.\lspace
  \end{itemize}
\item
  Calculate the test statistic based on \(\bar x\), \(s\), and
  \(\mu_0\).

  \begin{itemize}
  \tightlist
  \item
    Sampling distribution is based on the \emph{null} hypothesis.\lspace
  \end{itemize}
\item
  Calculate the p-value according to the form of the \emph{alternate}
  hypothesis.

  \begin{itemize}
  \tightlist
  \item
    If \(<\), then \texttt{pnorm(z\_obs)}; if \(>\), then
    \texttt{1\ -\ pnorm(z\_obs)}; if two sided, double the correct one.
  \end{itemize}
\end{enumerate}

\hypertarget{hypothesis-test-example}{%
\subsection{Hypothesis Test Example}\label{hypothesis-test-example}}

New York is sometimes called ``the city that never sleeps''. At the 5\%
level, do the following data provide evidence that the average New
Yorker gets less than 8 hours of sleep per night?

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\(\bar x\) & \(s\) & \(n\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
7.73 & 0.77 & 25 \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  Hypotheses: \pause \(H_0: \mu = 8\), \(H_a:\mu < 8\).\lspace
\item
  \(t_{obs}\) = \pause \(\dfrac{7.73 - 8}{0.77/5} = -1.75\)\lspace
\item
  p-value = \pause \texttt{pt(-1.75,\ 24)} = 0.0464
\item
  Conclude: \pause Since p \textless{} \(\alpha\), we reject the null
  hypothesis.

  \begin{itemize}
  \tightlist
  \item
    We have found statistically significant evidence that New Yorkers
    sleep less than 8 hours per night on average.
  \end{itemize}
\end{itemize}

\hypertarget{confidence-intervals-1}{%
\subsection{Confidence Intervals}\label{confidence-intervals-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose a confidence level \(\alpha\).

  \begin{itemize}
  \tightlist
  \item
    ``100(1-\(\alpha\))\%CI\lspace
  \end{itemize}
\item
  Collect data

  \begin{itemize}
  \tightlist
  \item
    Independent observations from same population; random sample.\lspace
  \end{itemize}
\item
  Find the critical value \(t^*_{n-1}\)

  \begin{itemize}
  \tightlist
  \item
    We will not need \(z^*\) again, except possibly as
    comparison.\lspace
  \end{itemize}
\item
  Calculate \(\bar x \pm t^*s/\sqrt{n}\)\lspace
\item
  Conclude: 95\% of the intervals constructed this way will contain the
  true population mean.
\end{enumerate}

\hypertarget{confidence-interval-example}{%
\subsection{Confidence Interval
Example}\label{confidence-interval-example}}

Construct a 95\% CI for the New York sleep example.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\(\bar x\) & \(s\) & \(n\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
7.73 & 0.77 & 25 \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  \(\alpha\) = 0.05\lspace
\item
  \(t^*_{n-1}\) = \pause \texttt{qt(0.025,\ 24)} = -2.0639.\lspace
\item
  \(\bar x \pm t^*_{n-1}s/\sqrt{n} = 7.73 \pm 2.0639*0.77/5 = (7.41, 8.05)\)\lspace
\item
  Conclude: we are 95\% confident that the true average nights sleep in
  New York is between 7.41 and 8.05.

  \begin{itemize}
  \tightlist
  \item
    This interval includes 8, so 8 would \emph{not} be rejected by a
    hypothesis test?!?!
  \end{itemize}
\end{itemize}

\hypertarget{participation-questions-1}{%
\section{Participation Questions}\label{participation-questions-1}}

\hypertarget{q1-1}{%
\subsection{Q1}\label{q1-1}}

What is the standard error?

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\sigma/\sqrt{n}\)
\item
  \(\sqrt{\frac{p(1-p)}{n}}\)
\item
  \(\sqrt{s_1^2/n_1 + s_2^2/n}\)
\item
  The standard deviation of the sampling distribution.
\end{enumerate}

\hypertarget{q2-1}{%
\subsection{Q2}\label{q2-1}}

What is the standard deviation of the sampling distribution?

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The standard deviation of the population divided by the square root of
  the sample size (\(\sigma/\sqrt{n}\)).
\item
  The standard deviation of the value of a sample statistic across all
  possible samples from the population.
\item
  The same as the standard deviation of the population.
\item
  The average distance to the mean of the population.
\end{enumerate}

\hypertarget{q3-1}{%
\subsection{Q3}\label{q3-1}}

Why does the sampling distribution have a lower variance than the
population?

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Because the standard deviation is smaller than the variance.
\item
  Because the population has a larger number of possible, so the
  variance is smaller.
\item
  Because outliers are not as likely in a sample.
\item
  Because we are summarising many observations from a sample into a
  single value.
\end{enumerate}

\hypertarget{q4-1}{%
\subsection{Q4}\label{q4-1}}

After conducting a study, we found a p-value of 0.04. Did we find a
statistically significant result?

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Yes, since the p-value is less than 0.05
\item
  No, since the p-value is less than 0.05
\item
  We failed to set the significance lavel ahead of time, so we have to
  be very careful about concluding significance.
\end{enumerate}

\hypertarget{q5-1}{%
\subsection{Q5}\label{q5-1}}

After conducting a study, we found a 95\% confidence interval for
\(\mu\) from -0.1 to 1.9. What can we conclude?

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Since 0 is in the interval, a hypothesis test for \(\mu = 0\) versus
  \(\mu \ne 0\) would not be significant at the 5\% level.
\item
  Since 0 is in the interval, a hypothesis test for \(\mu = 0\) versus
  \(\mu > 0\) would not be significant at the 5\% level.
\item
  Since 0 is in the interval, a hypothesis test for \(\mu = 0\) versus
  \(\mu \ne 0\) would not be significant at the 2.5\% level.
\item
  Since 0 is in the interval, a hypothesis test for \(\mu = 0\) versus
  \(\mu > 0\) would not be significant at the 2.5\% level.
\end{enumerate}

\hypertarget{q6}{%
\subsection{Q6}\label{q6}}

Under which condition does the CLT \emph{not} apply?

\pspace

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For \(\bar x\), the sample size is between 3 and 60 but a histogram of
  the sample appears normal.
\item
  For \(\bar x\), the sample size is much larger than 60.
\item
  For \(\hat p\), the sample size is much larger than 60.
\item
  For \(\hat p\), we have checked \(np>10\) and \(n(1-p)>10\)
\end{enumerate}

\textbf{Solution}

41431

\hypertarget{self-study-questions-6}{%
\section{Self-Study Questions}\label{self-study-questions-6}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain why: If the \(z_{obs}\) test statistic is the same as the
  \(t_{obs}\) test statistic, then the p-value for \(t_{obs}\) will be
  wider.
\item
  If a test is statistically signficant, does that mean there's a large
  effect size? That is, does a hypothesis test tell you anything about
  the size of the effect?

  \begin{itemize}
  \tightlist
  \item
    Compare this to confidence intervals.
  \end{itemize}
\item
  Can we interpret a \(t\) confidence interval as ``all null hypothesis
  values that would not be rejected''?
\item
  Re-do the ointment example, but using without - with.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Draw a t distribution and mark the two test statistics, then fill in
    the area that corresponds to the p-value.
  \end{enumerate}
\end{enumerate}

\hypertarget{crowdsourced-questions-10}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-10}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A researcher believes that the average sleep duration for adults in a
  certain city is less than the national average of 8 hours. To test
  this hypothesis, the researcher collects a sample of 50 adults from
  the city and finds that the mean sleep duration in the sample is 7.5
  hours with a standard deviation of 1.2 hours. At a 5\% significance
  level, can the researcher conclude that the average sleep duration for
  adults in the city is less than 8 hours?
\end{enumerate}

\textbf{Solution}

Set up the hypotheses:

\begin{itemize}
\tightlist
\item
  Null hypothesis (H0\hspace{0pt}): The average sleep duration is 8
  hours (\(\mu = 8\)).
\item
  Alternative hypothesis (H1\hspace{0pt}): The average sleep duration is
  less than 8 hours (\(\mu < 8\)).
\end{itemize}

Calculate the test statistic using the sample mean, population mean,
standard deviation, and sample size: \$t\_\{obs\} =
\frac{\bar x - \mu_0}{s/\sqrt{n}} = \frac{7.5 - 8}{1.2 / \sqrt{50}} =
-2.946

The p-value can be found using the t-distribution on \(n-1\) degrees of
freedom:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pt}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{2.946}\NormalTok{, }\AttributeTok{df =} \DecValTok{50} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.002457447
\end{verbatim}

Since this is less than 0.05, we reject the null hypothesis. There is
evidence at the 5\% level that the true mean sleep duration is less than
8 hours.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  A nutritionist claims that the new diet plan they have designed
  results in a more significant average weight loss than the generally
  accepted average of 5 pounds after a 4-week program. To validate this
  claim, the nutritionist collects data from 40 individuals who followed
  the diet plan and finds that the mean weight loss among the
  participants is 5.8 pounds with a standard deviation of 0.9 pounds. At
  a significance level of 1\%, is there enough evidence to support the
  nutritionist's claim?
\end{enumerate}

\textbf{Solution}

Note that this is a matched pairs t-test!

Set up the hypotheses:

\begin{itemize}
\tightlist
\item
  Null hypothesis (H0): The average weight loss is 5 pounds
  (\(\mu = 5\)).
\item
  Alternative hypothesis (H1): The average weight loss is more than 5
  pounds (\(\mu > 5\)).
\end{itemize}

Calculate the test statistic using the formula for a t-test: \[
t_{obs} = \frac{\bar x - \mu_0}{s/\sqrt{n}} = \frac{5.8 - 5}{0.9/\sqrt{40}} = 5.62
\]

Using the t-distribution on \(n - 1\) degrees of freedom:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pt}\NormalTok{(}\FloatTok{5.62}\NormalTok{, }\AttributeTok{df =} \DecValTok{40} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 8.727633e-07
\end{verbatim}

We get a value much smaller than our significance level of 0.01! We
reject the null, and conclude that the average weight loss is more than
5 pounds.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  A coffee company has engineered an espresso machine that is advertised
  to make cups of espresso with an average of 80mg of caffeine. When
  being sampled, 36 cups of espresso were made and tested for their
  caffeine content. The sample mean came out to be 82mg with a standard
  deviation of 6mg. Conduct a 2-sided hypothesis test at a significance
  level of 5\%. State Null hypothesis, Alternate Hypothesis, and
  significant level. Calculate test statistic and determine whether
  claims made by the coffee company should be accepted.
\end{enumerate}

\textbf{Solution}

Our hypotheses are \(H_0:\mu = 80\) versus \(H_0:\mu \ne 80\).

\[
t_{obs} = \frac{\bar x - \mu_0}{s/\sqrt{n}} = \frac{82 - 80}{6 / \sqrt{36}} = 2
\]

The p-value can be found as:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pt}\NormalTok{(}\DecValTok{2}\NormalTok{, }\AttributeTok{df =} \DecValTok{6} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1019395
\end{verbatim}

Since our p-value is larger than alpha, we do not reject the null. We
have not gathered evidence that the claim of 80mg is incorrect.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{two-sample-t-tests}{%
\chapter{Two-Sample t-Tests}\label{two-sample-t-tests}}

\hypertarget{how-much-can-one-more-sample-complicate-things}{%
\section{\texorpdfstring{How much can \emph{one} more sample complicate
things?}{How much can one more sample complicate things?}}\label{how-much-can-one-more-sample-complicate-things}}

\hypertarget{notation-subscripts-everywhere}{%
\subsection{Notation: Subscripts
everywhere!}\label{notation-subscripts-everywhere}}

We now have two samples.

\(\bar X_1\sim N(\mu_1, \sigma_1/\sqrt{n_1})\), where \(s_1\) is the
estimated standard deviation of a given sample.

\(\bar X_2\sim N(\mu_2, \sigma_2/\sqrt{n_2})\) \pause

\quad

\emph{Goal:} Are the means the same? I.e., is \(\mu_1 = \mu_2\)?

With two samples, the difference in means has a sampling distribution.
What is that distribution? It's difficult!

The easy part is the mean of the difference. The mean of the difference
is the difference in means. \[
\bar X_1 - \bar X_2 \sim N(\mu_1 - \mu_2, ???)
\]

The hard part is the standard deviation of the difference. Take a moment
and think about what we're talking about here. What does it actually
mean for the difference in means to have variance?

It's the same as it was before, it just seems a little more complicated.
When we take a pair of samples then find their difference, we have
calculated a statistic! For every \emph{pair} of samples, we'll get a
different statistic. The variance that we seek is the variance of all of
these statistics.

\hypertarget{the-standard-deviation-of-a-difference}{%
\subsection{The standard deviation of a
difference}\label{the-standard-deviation-of-a-difference}}

Again, I'm going to use a simulation to demonstrate what happens if we
take a bunch of pairs of samples, then find their difference.

In this case, I'm sampling x1 as 22 values from a normal distribution
with a mean of 0 and a standard deviation of 2, whereas x2 has 33
observations and comes from a distribution with a mean of 0 and a
standard deviation of 3. I'm finding their means, then finding their
differences. I repeat this 10,000 times, keeping track of what the
difference in means was.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# approximating the sampling distribution}
\NormalTok{differences }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10000}\NormalTok{)\{}
\NormalTok{    m1 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{22}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{    m2 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{33}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\NormalTok{    differences[i] }\OtherTok{\textless{}{-}}\NormalTok{ m1 }\SpecialCharTok{{-}}\NormalTok{ m2}
\NormalTok{\}}
\FunctionTok{sd}\NormalTok{(differences)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6802144
\end{verbatim}

\ldots{} it's not at all obvious where this number comes from.

Both had a mean of 0, so the difference should be 0. But the standard
deviation of the differences isn't obvious. There is a nice formula for
the mean - \(\sigma/\sqrt{n}\) - but it's not obvious how this works for
two samples with different variances \emph{and} different sample sizes!

It turns out that the following equation is the correct one for the
standard deviation of the differences. Recall that the standard
deviation of a sampling distribution is known as the Standard Error
(SE).

\[
SE = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}
\]

And to verify that our simulation matches this idea:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Check}
\FunctionTok{sd}\NormalTok{(differences)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6802144
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(}\DecValTok{4}\SpecialCharTok{/}\DecValTok{22} \SpecialCharTok{+} \DecValTok{9}\SpecialCharTok{/}\DecValTok{33}\NormalTok{) }\CommentTok{\# Close enough}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6741999
\end{verbatim}

\hypertarget{putting-it-together}{%
\subsection{Putting it Together}\label{putting-it-together}}

Altogether, this means that the difference between means has the
following sampling distribution:

\[
\bar X_1 - \bar X_2 \sim N\left(\mu_1 - \mu_2, \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}\right)
\]

From this, we get the same general ideas as before. The hypothesis tests
are based on the observed test statistic: \[
t_{obs} = \frac{\text{sample statistic} - \text{hypothesized value}}{\text{standard error}} = \frac{(\bar x_1 - \bar x_2) - 0}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
\] where usually the hypothesized value is 0 so that we're testing
whether the true population means are the same.

\hypertarget{two-sample-hypotheses}{%
\subsection{Two-Sample Hypotheses}\label{two-sample-hypotheses}}

The usual null hypothesis invloves the \emph{equality} of the means,
with the alternative being ``\textgreater{}'', ``\textless{}'', or
``''. This does not change: \begin{align*}
H_0: \mu_1 = \mu_2 &\Leftrightarrow H_0:\mu_1 - \mu_2 = \mu_d = 0\\
H_0: \mu_1 < \mu_2 &\Leftrightarrow H_0:\mu_1 - \mu_2 = \mu_d < 0\\
\end{align*}

The confidence interval is also the same idea: \[
\text{sample statistic}\pm\text{critical value}*\text{standard error} = (\bar x_1 - \bar x_2)\pm t^*\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}
\]

In both of these, we still need to know the degrees of freedom! As we
saw last lecture, the \(t\)-distribution requires some information about
the sample size. In the one-sample case, this was \(n-1\). However, we
now have two potentially different sample sizes! What do we do?

Recall that the \(t\)-distribution gets closer and closer to the normal
distribution as \(n\) increases. The whole point of the \(t\) is to get
us a little further from the normal in order to account for the variance
in the sample standard deviation. For the two-sample case, there is a
``correct'' formula, but it's big and scary and everything we're doing
now is approximate anyway. Instead, we use a more conservative approach
to ensure that we're not underestimating the variance.\footnote{In
  general, we would much, much, much rather \emph{overestimate} the
  variance. The whole point of statistics is to avoid overconfidence in
  our estimates.}

\hypertarget{two-sample-t-degrees-of-freedom}{%
\subsection{\texorpdfstring{Two-Sample \(t\) degrees of
freedom}{Two-Sample t degrees of freedom}}\label{two-sample-t-degrees-of-freedom}}

When doing hand calculations, we use the smallest sample size, then
subtract 1. (R does a more accurate calculation that results in
non-integer values.)

In the simulation we did earlier, the two samples had sizes of 22 and
33. In both a CI and a hypothesis test, we would use 21 as the value in
\texttt{qt()} or \texttt{pt()} (which are the same idea as
\texttt{qnorm()} and \texttt{pnorm()}).

\hypertarget{aside-pooled-variance}{%
\subsection{Aside: ``Pooled Variance''}\label{aside-pooled-variance}}

There's another formula out there that uses a so-called ``pooled
variance'' for the standard error of the differences. This assumes that
both populations have the exact same variance, and tries to use
information from both to estimate the variance. It essentially treats
the two samples as one big sample from the same population in order to
calculate the standard deviation.

This also implicitly assumes that both populations are normal, and this
is not based on the CLT. Instead, the populations need to be normal.
This is a huge assumption - we can use normality from the CLT because
the math checks out. Assuming normality of the population is just a wild
guess that we can't really check.

It is also very, very unlikely that the two populations have the same
standard deviation.

If the two assumptions are met, then the pooled standard deviation is
the ``correct'' formula. However, the SE that we saw before still works
very well! If the assumptions are not met, then the pooled SE works
poorly and the SE we've seen is still very good!

Except in exceptional cases, the SE that we've learned should be used.
The idea of a pooled variance is a vestige of another age (and may show
up if you use another textbook or search Google).

\hypertarget{summary-8}{%
\section{Summary}\label{summary-8}}

\hypertarget{two-sample-t-test-and-ci-overview}{%
\subsection{Two-Sample t-test and CI
Overview}\label{two-sample-t-test-and-ci-overview}}

We are usually testing for the difference in means, i.e. \begin{align*}
H_0: \mu_1 = \mu_2 &\Leftrightarrow H_0:\mu_1 - \mu_2 = \mu_d = 0\\
H_a: \mu_1 < \mu_2 &\Leftrightarrow H_a:\mu_1 - \mu_2 = \mu_d < 0\\
\end{align*}\vspace{-15mm}

\[
t_{obs} = \frac{\bar x_1 - \bar x_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
\] \vspace{-10mm}

\[
\text{p-value} = P(T < t_{obs}) = \texttt{pt(t\_obs, df = min(n1, n2) - 1)}
\]

\[
\text{A $(1-\alpha)$ CI for $\mu_d$ is }\bar x_1 - \bar x_2 \pm t^*\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}
\]

where \(t^*\) is based on the smaller of \(n_1 - 1\) and \(n_2 - 1\)

The assumptions are still the same, with one notable addition:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The sampling distribution of the difference in means is approximately
  normal.

  \begin{itemize}
  \tightlist
  \item
    Normal populations, approximately normal histograms, or large sample
    size.
  \end{itemize}
\item
  The observations \emph{within} each group are independent.
\item
  The observations \emph{between} each group are independent.
\end{enumerate}

\hypertarget{example-1-two-sample-versus-matched-pairs}{%
\section{Example 1: Two-Sample versus Matched
Pairs}\label{example-1-two-sample-versus-matched-pairs}}

From the Ointment example:

\begin{longtable}[]{@{}lllllllll@{}}
\toprule\noalign{}
& Subject 1 & S2 & S3 & S4 & S5 & S6 & S7 & S8 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
With Oint & 6.44 & 6.06 & 4.22 & 3.3 & 6.5 & 3.49 & 7.01 & 4.22 \\
Without & 7.22 & 6.05 & 4.55 & 4 & 6.7 & 2.88 & 7.88 & 6.32 \\
Difference & -0.78 & 0.01 & -0.33 & -0.7 & -0.2 & 0.61 & -0.87 & -2.1 \\
\end{longtable}

First we'll do matched pairs. In this example, \textbf{this is the
correct test} to use.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{withoint }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{6.44}\NormalTok{, }\FloatTok{6.06}\NormalTok{, }\FloatTok{4.22}\NormalTok{, }\FloatTok{3.3}\NormalTok{, }\FloatTok{6.5}\NormalTok{, }\FloatTok{3.49}\NormalTok{, }\FloatTok{7.01}\NormalTok{, }\FloatTok{4.22}\NormalTok{)}
\NormalTok{without }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{7.22}\NormalTok{, }\FloatTok{6.05}\NormalTok{, }\FloatTok{4.55}\NormalTok{, }\DecValTok{4}\NormalTok{, }\FloatTok{6.7}\NormalTok{, }\FloatTok{2.88}\NormalTok{, }\FloatTok{7.88}\NormalTok{, }\FloatTok{6.32}\NormalTok{)}
\NormalTok{diff }\OtherTok{\textless{}{-}}\NormalTok{ withoint }\SpecialCharTok{{-}}\NormalTok{ without}

\FunctionTok{hist}\NormalTok{(diff)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \DecValTok{0}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L17-Two_Sample_hypothesis_Tests_files/figure-pdf/paired_oint-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(}\AttributeTok{x =}\NormalTok{ diff, }\AttributeTok{alternative =} \StringTok{"less"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  diff
t = -1.9421, df = 7, p-value = 0.04663
alternative hypothesis: true mean is less than 0
95 percent confidence interval:
        -Inf -0.01332314
sample estimates:
mean of x 
   -0.545 
\end{verbatim}

From this t-test, we can see that there's a mean difference of -0.545,
which leads to a p-value of 0.04663. At the 5\% level, the null is
rejected and we conclude that there \emph{is} a difference between the
two groups. The ointment appears to make a difference!

However, looking at the histogram, it looks like there may be an
outlier. With a data set this small, one value can completely change our
results!!! Remember that we're dealing with means, and means are
affected by outliers. This means that \textbf{p-values are affected by
outliers as well!}

\hypertarget{the-wrong-way}{%
\subsubsection{The Wrong Way}\label{the-wrong-way}}

We could instead have done a two-sample test, which ignores the fact
that the observations are paired. Since we know the pairings, this test
is leaving out valuable information.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(withoint, without)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \DecValTok{0}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L17-Two_Sample_hypothesis_Tests_files/figure-pdf/two_sample_oint-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(}\AttributeTok{x =}\NormalTok{ withoint, }\AttributeTok{y =}\NormalTok{ without, }\AttributeTok{alternative =} \StringTok{"less"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Welch Two Sample t-test

data:  withoint and without
t = -0.67584, df = 13.736, p-value = 0.2552
alternative hypothesis: true difference in means is less than 0
95 percent confidence interval:
      -Inf 0.8772719
sample estimates:
mean of x mean of y 
    5.155     5.700 
\end{verbatim}

This result should not be trusted since it misses a key aspect of the
data. The first value in the ``Ointment'' group corresponds to the first
value in the ``Without Ointment'' group, they aren't just two separate
values - they're measured on the same individual!

Regardless, take a moment to look at the differences in the results
between the two tests.

\hypertarget{example-2-body-mass-of-penguins}{%
\section{Example 2: Body Mass of
Penguins}\label{example-2-body-mass-of-penguins}}

In this example, we'll look at the difference in body mass between male
and female penguins.

In this case, there is no clear pairing between the penguins. If they
were monogomous couples, then the differences in body mass might tell us
about couples, but doesn't say much about male and female penguins in
general.\footnote{Recall: penguins are especially likely to have
  homosexual relationships and tend to be more fluid in their gender
  roles than other animals.}

This example gives us the opportunity to learn more notation in R! The
previous example used \texttt{t.test(x\ =\ ...,\ y\ =\ ...)} to denote
the two samples. If the data are neatly formatted in a data frame, then
we can use the \texttt{\textasciitilde{}} notation to demonstrate that
the body mass is split into different groups for male and female.

First, we'll draw a boxplot. This is a great way to compare two
distributions, and can be made in a small amount of space. Pause for a
moment and ask yourself whether these two groups intuitively look
different.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(palmerpenguins)}
\FunctionTok{boxplot}\NormalTok{(body\_mass\_g }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex, }\AttributeTok{data =}\NormalTok{ penguins, }\AttributeTok{horizontal =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{xlab =} \StringTok{"Body Mass (grams)"}\NormalTok{, }\AttributeTok{ylab =} \ConstantTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L17-Two_Sample_hypothesis_Tests_files/figure-pdf/penguins_t_test-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(body\_mass\_g }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex, }\AttributeTok{data =}\NormalTok{ penguins)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Welch Two Sample t-test

data:  body_mass_g by sex
t = -8.5545, df = 323.9, p-value = 4.794e-16
alternative hypothesis: true difference in means between group female and group male is not equal to 0
95 percent confidence interval:
 -840.5783 -526.2453
sample estimates:
mean in group female   mean in group male 
            3862.273             4545.685 
\end{verbatim}

Note: The notation will always be ``variable we care most about''
\textasciitilde{} ``other variables''. In linear regression, this was y
\textasciitilde{} x, and now it's continuous \textasciitilde{}
categorical.

From the output above, we get a two-sided p-value as well as a two-sided
CI, both confirming that the difference in body mass is different from
0. You can also see that it's using ``female minus male'', rather than
``male minus female''. This is because R will put them in alphabetical
order, so female comes first.

You may also be happy to hear that no, you will never have to manually
enter the standard error formula! Let's all say a big, collective thank
you to the R programming language! Thank you! (You may need to interpret
the idea of standard error in two-sample t-tests, though.)

\hypertarget{example-3-birthweights-by-hand}{%
\section{Example 3: Birthweights (by
hand)}\label{example-3-birthweights-by-hand}}

Do mothers who smoke give birth to children with a lower birthweight
than mothers who don't?

\pspace

Test this at the 5\% level using the data on the right.

We're going to do this by hand!

\vspace{-7mm}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
& Smoker & Non-Smoker \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
mean & 6.78 & 7.18 \\
sd & 1.43 & 1.60 \\
n & 50 & 100 \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  The null hypothesis is \(H_0: \mu_{smoke} = \mu_{non}\), which can be
  written as \(H_0: \mu_{non} - \mu_{smoke} = 0\).\pause\lspace
\item
  The alternate hypothesis is \(H_a: \mu_{smoke} < \mu_{non}\), which
  could be written as

  \begin{itemize}
  \tightlist
  \item
    \(H_a: \mu_{non} - \mu_{smoke} > 0\), or
  \item
    \(H_a: \mu_{smoke} - \mu_{non} < 0\)
  \end{itemize}
\end{itemize}

It doesn't matter which we choose, but we have to know which we chose in
order to calculate the corresponding p-value! Let's use \(\mu_{n-s}\).

The sample mean difference is
\(\bar x_{non} - \bar x_{smoke} = 7.18 - 6.78 = 0.4\). The standard
error is: \[
SE = \sqrt{\dfrac{s_s^2}{n_s} + \dfrac{s_n^2}{n_n}} = \sqrt{\dfrac{1.43^2}{50} + \dfrac{1.60^2}{100}} = 0.2578721
\]

Since we used \(\bar x_{non} - \bar x_{smoke}\), our alternate tells us
to find the p-value for a t-statistic larger than what we got.

\[
t_{obs} = \dfrac{(\bar x_{non} - \bar x_{smoke}) - (\mu_{non} - \mu_{smoke})}{SE} = \dfrac{0.4 - 0}{0.2578721} = 1.55
\]

Since we're doing a right-tailed test\footnote{If we had done a
  left-tailed test, we wouldn't need the ``1 -''. Explain why.}, we
calculate our p-value as:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pt}\NormalTok{(}\FloatTok{1.55}\NormalTok{, }\DecValTok{49}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.06378844
\end{verbatim}

To summarise:

\begin{itemize}
\tightlist
\item
  \(H_0: \mu_{non} - \mu_{smoke} = 0\) versus
  \(H_0: \mu_{non} - \mu_{smoke} > 0\)
\item
  \(t_{obs} = 1.55\)
\item
  p-value is 0.06
\end{itemize}

Since our p-value is larger than 0.5, we do not have a statistically
significant result. We fail to reject the hypothesis that smokers have
lower birthweights. We conclude that we do not have enough evidence to
say that smoking is associated with lower birthweights.

\hypertarget{example-4-basketball-versus-hockey-players}{%
\section{Example 4: Basketball versus Hockey
Players}\label{example-4-basketball-versus-hockey-players}}

In a previous lecture, we looked at the heights of female basketball
players to test whether their heights were consistent with the
population. Now that we have the tools to compare two samples, let's
compare some teams! In what follows, we're testing the the hypothesis
that the basketball team and the hockey team are different heights.
Let's test at the 5\% level since we have no strong reason to use a
smaller or larger level\footnote{A smaller level would be used if we
  required strong evidence before we reject the null, such as when a new
  treatment seems implausible.}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\NormalTok{stats }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"wlu\_female\_athletes.csv"}\NormalTok{)}
\NormalTok{baskey }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(stats, Sport }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"Hockey"}\NormalTok{, }\StringTok{"Basketball"}\NormalTok{))}
\FunctionTok{boxplot}\NormalTok{(Height }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Sport, }\AttributeTok{data =}\NormalTok{ baskey)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L17-Two_Sample_hypothesis_Tests_files/figure-pdf/baskey-1.pdf}

}

\end{figure}

From the boxplot, I would be absolutely flabbergasted if the two groups
had the same mean! Astonished! Befuddled, even! This is an important
part of any analysis: have expectations! You should know your data well
before diving into a study. For example, looking at these boxplots
reveals that there are no apparent outliers, and both groups look
approximately symmetric. This is good.

Let's do the t-test.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(Height }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Sport, }\AttributeTok{data =}\NormalTok{ baskey)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Welch Two Sample t-test

data:  Height by Sport
t = 4.5266, df = 26.588, p-value = 0.0001121
alternative hypothesis: true difference in means between group Basketball and group Hockey is not equal to 0
95 percent confidence interval:
  3.805256 10.123430
sample estimates:
mean in group Basketball     mean in group Hockey 
                172.1771                 165.2128 
\end{verbatim}

From the output, we can conclude that there is a statistically
significant difference in the average height of female hockey and
basketball players at Laurier.

Some caveats:

\begin{itemize}
\tightlist
\item
  These are small samples!!!

  \begin{itemize}
  \tightlist
  \item
    Recall that R uses a more accurate value for \texttt{df} (we just
    use the smaller sample size then subtract one for hand
    calculations). It's 26.588, which can be interpreted as something
    like the average of the two sample sizes.
  \end{itemize}
\item
  This isn't exactly a random sample!

  \begin{itemize}
  \tightlist
  \item
    The data were taken from the current seasons' full teams. We don't
    exactly have a wel--defined population here. Is the population all
    women? Only femal athletes? Only female varsity athletes? Only
    Canadian female varsity athletes in these particular sports? Or is
    it only female varsity athletes in these particular sports at
    Laurier? It's hard to say what these results apply to.
  \end{itemize}
\item
  We just tested hockey versus basketball. What about soccer? What about
  heights by position?

  \begin{itemize}
  \tightlist
  \item
    If we start testing many hypotheses, we run afoul of the multiple
    comparisons problem. Before collecting the data, this test had a 5\%
    chance of being significant if the null hypothesis were true. So do
    all of the other tests. If we test enough times, we'll eventually
    reject a true null hypothesis.
  \end{itemize}
\end{itemize}

\hypertarget{conclusion-1}{%
\section{Conclusion}\label{conclusion-1}}

\begin{itemize}
\tightlist
\item
  If you can have matched pairs, you should use a matched pairs test.
\item
  Most of the time, you'll need to use a two-sample t-test.

  \begin{itemize}
  \tightlist
  \item
    Don't get fooled by equal sample sizes! Just because the sample
    sizes are the same doesn't mean that the observations are paired!
  \end{itemize}
\item
  A two-sample t-test is based on the difference in means

  \begin{itemize}
  \tightlist
  \item
    The standard error is tricky - software will do this for you.
  \item
    The degrees of freedom is the \emph{smallest} sample size minus 1.

    \begin{itemize}
    \tightlist
    \item
      Used for the p-value for hypothesis tests and the critical value
      for confidence intervals.
    \item
      R uses a better value.
    \end{itemize}
  \item
    The null hypothesis is usually 0, and the alternate depends on the
    order in which you subtract the means.
  \end{itemize}
\end{itemize}

\hypertarget{self-study-questions-7}{%
\section{Self-Study Questions}\label{self-study-questions-7}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write out the null and alternate hypotheses for the ``Ointment''
  example and the ``Penguins'' example, and comment on the difference
  between the two examples. Make sure the alternate has the same
  ``\textgreater{}'' or ``\textless{}'' or ``'' that was used in R's
  calculation! Hint: It matters if you do Group 1 minus Group 2 or if
  you do Group 2 minus Group 1!
\item
  Veryify the p-values in the Ointment and Penguins examples. Use the
  t-value reported in the R output, and find the p-value using either
  \texttt{pt()}, \texttt{1\ -\ pt}, or \texttt{2\ *\ (1\ -\ pt())}, as
  appropriate. Explain your answer.
\item
  Explain why t-tests can only be used for comparing two groups, not
  three. (Hint: write out the null hypothesis - what value are we using
  in \(\mu = \mu_0\)?)
\item
  Explain why the 95\% CI still has the same interpretation as before.
\item
  Explain why there is only one sampling distribution in a two-sample
  t-test, even though there are two populations.
\item
  Provide a conclusion based on the following output (suppose you're
  testing at the 10\% level). The \texttt{mpg} variable is the miles per
  gallon of a vehicle, while \texttt{am} is the transmission type, with
  0 = Automatic and 1 = Manual. \texttt{mtcars} is just the name of the
  data that these variables are in.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(mpg }\SpecialCharTok{\textasciitilde{}}\NormalTok{ am, }\AttributeTok{data =}\NormalTok{ mtcars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Welch Two Sample t-test

data:  mpg by am
t = -3.7671, df = 18.332, p-value = 0.001374
alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0
95 percent confidence interval:
 -11.280194  -3.209684
sample estimates:
mean in group 0 mean in group 1 
       17.14737        24.39231 
\end{verbatim}

\textbf{Selected Solutions}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Ointment: \(H_0: \mu_{without-with} = 0\) versus and
  \(H_A: \mu_{without-with} < 0\). Note that we can tell that it's
  \texttt{without-with} by looking at the means of the two groups and
  the sign of the t-statistic.

  \begin{itemize}
  \tightlist
  \item
    Penguins: \(H_0: \mu_{female} - \mu_{male} = 0\) versus
    \(H_A: \mu_{female} - \mu_{male} \ne 0\).
  \item
    The ointment example had \(\mu_{without - with}\) as a single
    number, whereas the penguins example used
    \(\mu_{female} - \mu_{male}\), which is the difference between two
    numbers. This is because the ointment example was a \emph{one-sample
    t-test} since we were treating the set of differences as a single
    sample; the penguins example is a two-sample t-test.
  \end{itemize}
\end{enumerate}

\hypertarget{large-sample-test-for-a-proportion}{%
\chapter{Large sample test for a
proportion}\label{large-sample-test-for-a-proportion}}

\hypertarget{refresher}{%
\section{Refresher}\label{refresher}}

In the lecture on sampling distributions, we learned that the sampling
distribution of a sample proportion can be found as follows:

If \(X\sim B(n,p)\) and \(np>10\) and \(n(1-p)>10\),\footnote{That is,
  we have a \textbf{large sample}} then we can approximate the sampling
distribution of \(\hat p\) as follows: \[
\hat p \sim N\left(p, \sqrt{\frac{p(1-p)}{n}}\right)
\]

This relies on the population proportion \(p\) to find the standard
error, but this is never available. If it was, then why are we trying to
do inference?

\hypertarget{hypothesis-tests-for-proportions}{%
\section{Hypothesis tests for
proportions}\label{hypothesis-tests-for-proportions}}

As before, we write our hypotheses: \[
H_0:p = p_0 \text{ vs. } H_A: p \{>or<or\ne\} p_0
\]

We always write \(H_0:p = p_0\) and then fill in the value for \(p_0\),
then we use that same value in the alternate hypothesis but use either
\(>\), \(<\), or \(\ne\) based on the wording of the question.

As before, we use the sampling distribution to find our p-value. In this
case, though, we have a hypothesized value for the population
proportion. In fact, we \emph{must} assume that the null is
true.\footnote{We want to be strict about this so that it's more
  convincing if we prove it wrong.} If this is the case, we \emph{do
have} the standard error!

I swear, this is the last time I introduce a new standard error for the
sampling distribution of the sample proportion.\footnote{I'm lying.}
Assuming \(H_0\) is true (and the conditions are met), \[
\hat p \sim N\left(p_0, \sqrt{\frac{p_0(1-p_0)}{n}}\right)
\]

\hypertarget{the-test-statistic}{%
\subsection{The Test Statistic}\label{the-test-statistic}}

As you can guess from the sampling distribution, the test statistic is:

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Test Statistic for a Test for Proportions}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

\[
z_{obs} = \frac{\text{observed} - \text{hypothesized}}{\text{standard error}} = \frac{\hat p - p_0}{\sqrt{p_0(1-p_0)/n}}
\]

\end{tcolorbox}

and then we can use the normal distribution as usual: \[
P(Z \{>or<or\text{ further away than}\} z_{obs}) = \dots
\]

where we use \(>\) if the alternate hypothesis uses \(>\), \(<\) if the
alternate hypothesis uses \(<\), and we look at the two tails if the
alternate hypothesis is \(\ne\).

A common question is: which \(p\) do we use to check normality? We're
supposed to check \(np\) and \(n(1-p)\), but do we use \(\hat p\) or
\(p_0\)?

For a hypothesis test, we assume the null is true, i.e.~\(p=p_0\). We
should use this assumption \emph{everywhere}! For a hypothesis test
about a proportion, we check whether \(np_0>10\) and
\(n(1-p_0)>10\)\footnote{As before, both conditions must be true; it's
  not enough for just \(np_0>10\) alone.}.

From here, we proceed as usual. We check the observed test statistic
against a \emph{normal} distribution\footnote{We do not use a t
  distribution for this. The \(t\) distribution was used to account for
  the variance in the sampling distribution for \(s\) - the standard
  error for proportions is still based on \(p\), which means that there
  is no added variance!} and see whether our data are too extreme to
come from the distribution assumed in the null hypothesis.

\hypertarget{example-4}{%
\section{Example}\label{example-4}}

\hypertarget{mendelian-genetics}{%
\subsection{Mendelian Genetics}\label{mendelian-genetics}}

To test his theory that 75\% of plants would inheret a dominant gene,
Gregor Mendel cross bred pure breeds of pea plants. Out of 7324 plants,
5474 showed the dominant trait. At the 4.5\% level, is this compatible
with the hypothesis of 75\% dominant?

\textbf{Solution:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Check: \(np_0 = 7324*0.75 > 10\) and \(n(1-p_0) = 7324*0.25 > 10\).
\item
  \(z_{obs} = \frac{\hat p - p_0}{\sqrt{p_0(1-p_0)/n}} = \frac{0.747 - 0.75}{\sqrt{0.75*0.25/7324}} = -0.513\)
\item
  \(p-val = 2 *P(Z < z_{obs})\) = \texttt{2*pnorm(-0.513)} = 0.608

  \begin{itemize}
  \tightlist
  \item
    We doubled the \(P(Z < z_{obs})\) because we want both tails. If you
    do this and your p-value is larger than 1, do \(1 - P(Z < z_{obs})\)
    first and then double it.
  \end{itemize}
\item
  Conclusion: Since our p-value is larger than \(\alpha\), we do not
  reject the null. The hypothesis that 75\% of plants inherent the
  dominant trait is compatible with the data.
\end{enumerate}

The last step is important: always word your conclusion in the context
of the study.

These methods are extremely widespread, so of course they're implemented
in R. Here's a verification of our results:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.test}\NormalTok{(}\AttributeTok{x =} \DecValTok{5474}\NormalTok{, }\AttributeTok{n =} \DecValTok{7324}\NormalTok{, }\AttributeTok{p =} \FloatTok{0.75}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    1-sample proportions test with continuity correction

data:  5474 out of 7324, null probability 0.75
X-squared = 0.24923, df = 1, p-value = 0.6176
alternative hypothesis: true p is not equal to 0.75
95 percent confidence interval:
 0.7372578 0.7572926
sample estimates:
        p 
0.7474058 
\end{verbatim}

The output should look familiar - it's very similar to the t-test
output.

We can see that the p-value (be careful not to mix up the
\texttt{p-value} and the estimate of \(p\), labelled \texttt{p} - these
are very different things!) is a little different. Maybe it's because of
rounding errors? We calculated the z test statistic to the nearest 3
decimal places, maybe that wasn't enough?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{5474}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{7324}
\NormalTok{phat }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{se }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FloatTok{0.75} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.75}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ n)}
\DecValTok{2} \SpecialCharTok{*} \FunctionTok{pnorm}\NormalTok{((phat }\SpecialCharTok{{-}} \FloatTok{0.75}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ se)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6081484
\end{verbatim}

Nope, it's not a rounding problem!

The actual answer is that R uses a \emph{continuity correction factor}
(which isn't going to be on the test for this course). The correction
factor ``shifts'' the data so that the normal distribution aligns with
the center of the bar, rather than the edge. See the following plot for
why.

\includegraphics{L18-Hypothesis_Tests_for_Proportions_files/figure-pdf/unnamed-chunk-3-1.pdf}

As you can see, the normal distribution aligns with the side of the bar.
For values below the mean (in this case, \(n=10\) and \(p=0.4\), so the
mean is 4), the normal distribution is overestimating the areas to the
left, whereas above the mean it's underestimating the areas to the left.
The correction factor shifts the normal distribution to the right by 0.5
so that it's a better estimate of the areas below the curve.

If we run \texttt{prop.test()} without the correction factor, we get the
exact same p-value that we saw before.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.test}\NormalTok{(}\AttributeTok{x =} \DecValTok{5474}\NormalTok{, }\AttributeTok{n =} \DecValTok{7324}\NormalTok{, }\AttributeTok{p =} \FloatTok{0.75}\NormalTok{, }\AttributeTok{correct =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    1-sample proportions test without continuity correction

data:  5474 out of 7324, null probability 0.75
X-squared = 0.26288, df = 1, p-value = 0.6081
alternative hypothesis: true p is not equal to 0.75
95 percent confidence interval:
 0.7373269 0.7572253
sample estimates:
        p 
0.7474058 
\end{verbatim}

These details are not important, just be aware that almost all tests for
proportions are run \emph{with} the continuity correction factor. You
will not be doing this by hand on a test, so you can assume that R did
the right things to make the calculations as correct as possible (but R
will \emph{not} do anything to make sure that the test is appropriate
for the data).

\hypertarget{mendelian-genetics-confidence-interval}{%
\subsection{Mendelian Genetics Confidence
Interval}\label{mendelian-genetics-confidence-interval}}

Recall from last lecture the duality of the CI and the hypothesis test.
For this question, a 95.5\%\footnote{\(\alpha = 0.045\), so
  \(1 - \alpha = 0.955\).} CI matches what we used before.

In order to find the confidence interval, we again need the standard
error! In the hypothesis test, we assumed that \(p_0\) was the true
population proportion in order to proceed with the test. However, we
don't make this assumption for confidence intervals. In other words,
there \emph{is no \(p_0\) value that we can use}. We haven't made any
hypotheses for a p CI.

What can we do? We don't have \(p\) or \(p_0\), so we're left with
\(\hat p\), the sample proportion that we calculated. In the t-test,
this meant that we needed to switch to the \(t\) distribution. However,
that was because there was really good theory to say that the \(t\)
distribution is the correct distribution to use. There's no such theory
here.

The standard error is still the same, we just use \(\hat p\) in place of
\(p\): \[
SE = \sqrt{\dfrac{\hat p(1 - \hat p)}{n}}
\] and our confidence interval is, again, \[
\text{Point Estimate }\pm\text{ Critical Value} * \text{Standard Error} = \hat p \pm z^*\sqrt{\dfrac{\hat p(1 - \hat p)}{n}}
\]

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{CIs for Proportions Only Work When the CLT Applies}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

The \(t\)-distribution allows us to do hypothesis tests and make CIs
even for smaller samples when we're not sure that the CLT applies. For
proportions, we need a ``large'' sample.

\end{tcolorbox}

Now that we know all this, the CI can be found as: \[
\hat p \pm z^*\sqrt{\frac{\hat p(1-\hat p)}{n}} = 0.747 \pm 2.005\sqrt{\frac{0.747(1-0.747)}{7324}}
\]

which results in the CI (0.737, 0.757). This matches the CI shown in the
output of \texttt{prop.test()} above (double check this!).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Non-Duality of Hypotheses and CIs}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

For the t-test, a CI can be interpreted as ``every value that would not
be rejected by a hypothesis test.''

For proportions, it is \emph{not} true. This is because the CI and the
hypothesis test use \emph{different standard errors}. This is a very
important point: the hypothesis test uses \(p_0\) in the standard error
formula, while CIs use \(\hat p\), and thus the standard errors will be
different.

\end{tcolorbox}

\hypertarget{exact-test-for-binomial}{%
\section{Exact Test for Binomial}\label{exact-test-for-binomial}}

In this course, we have used the normal approximation to the binomial in
order to do hypothesis tests. This is not the only way to do it: we
don't always need to use the approximation! There's something called the
``exact binomial test'', which is a hypothesis test that uses the
binomial distribution rather than the normal approximation (this will
not be on tests).

There are two main reasons why we might prefer the approximation, rather
than using the exact test:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If we have a large sample, then the approximation and the exact test
  are very very close. The approximation is computationally simpler.

  \begin{itemize}
  \tightlist
  \item
    If we have a small sample, neither tests can accurately approximate
    the variance of the population, and thus the estimated standard
    error isn't well estimated either.
  \end{itemize}
\item
  Because the binomial distribution is discrete, the p-values for many
  different test statistics will be the same. By setting \(\alpha\), we
  might not actually be getting \(\alpha\).

  \begin{itemize}
  \tightlist
  \item
    This is a technical point that can be safely ignored when studying
    for tests.
  \end{itemize}
\end{enumerate}

The exact test can be performed using the \texttt{binom.test()} function
in R. You will \emph{never} have to choose between the two on an exam in
this course. You will be given only the one that you need (usually
\texttt{binom.test()} for one sample proportions, and
\texttt{prop.test()} for two-sample proportions).

\hypertarget{example-titanic-survivors}{%
\section{Example: Titanic Survivors}\label{example-titanic-survivors}}

Did women have a 50\% chance of surviving the sinking of the titanic?
Let's test this at the 10\% level, since we'd be pretty easily
convinced.

Since this is \textbf{categorical} data, we'll use a bar plot.

\includegraphics{L18-Hypothesis_Tests_for_Proportions_files/figure-pdf/Titanic_plots-1.pdf}

From the bar plot, it's pretty clear that the prportion of survivors is
different from 50\%. Let's confirm this statistically!

We're only interested in the female survivors for this analysis, so
we'll focus on that aspect of the bar plot.

\begin{verbatim}
# A tibble: 4 x 3
# Groups:   Sex [2]
  Sex    Survived  Freq
  <fct>  <fct>    <dbl>
1 Male   No        1329
2 Male   Yes        338
3 Female No         109
4 Female Yes        316
\end{verbatim}

From this output, we know that there were 316 female survivors out of
316 + 109 = 425 women total. Let's report these numbers to R:

\begin{verbatim}

    1-sample proportions test with continuity correction

data:  316 out of 425, null probability 0.5
X-squared = 99.849, df = 1, p-value < 2.2e-16
alternative hypothesis: true p is not equal to 0.5
95 percent confidence interval:
 0.698733 0.783840
sample estimates:
        p 
0.7435294 
\end{verbatim}

The default hypothesis is that the proportion is equal to 0.5, so we
didn't have to change anything. From this, it is clear that the null
hypothesis should be rejected. We conclude that the percentage of women
who survived the sinking of the Titanic is \emph{different from}
50\%\footnote{We can only conclude what we see in our hypotheses!!!}.

\hypertarget{summary-9}{%
\section{Summary}\label{summary-9}}

CIs and Hypothesis Tests work exactly as they did before, but now we're
dealing with proportions. Just like the change from one sample to two
sample \(t\) tests, the standard error is important and difficult.

\begin{itemize}
\tightlist
\item
  For hypothesis tests, the standard error uses \(p_0\).
\item
  For CIs, the standard error uses \(\hat p\).
\end{itemize}

Interpreting these confidence intervals and hypothesis tests is very
similar to before, but you must keep in mind that they're proportions.
This mainly affects how you describe the end results.

There are two other wrinkles to consider when using proportions:

\begin{itemize}
\tightlist
\item
  The default test for proportions is the normal approximation with
  continuity correction.

  \begin{itemize}
  \tightlist
  \item
    It is possible, but not recommended, to not use continuity
    correction.
  \end{itemize}
\item
  There is also an exact test, but for large samples the approximation
  is faster and easier.
\end{itemize}

\hypertarget{self-study-questions-8}{%
\section{Self-Study Questions}\label{self-study-questions-8}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  When do we use \(\hat p\) in the standard error? When do we use
  \(p_0\)?
\item
  Explain why we don't estimate the standard error in a hypothesis test
  about a proportion.
\item
  Explain in your own words why there's no \(t\) version of a hypothesis
  test for proportions.
\item
  Write a good summary of the Mendelian genetics example. What did we
  conclude, and how is this knowledge useful?
\item
  Repeat the Titanic survivors example but with male passengers.
\end{enumerate}

\hypertarget{crowdsourced-questions-11}{%
\section{Crowdsourced Questions}\label{crowdsourced-questions-11}}

The following questions are added from the Winter 2024 section of ST231
at Wilfrid Laurier University. The students submitted questions for
bonus marks, and I have included them here (with permission, and
possibly minor modifications).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Michael is interested in studying farmers' preferences for a new
  variety of genetically modified (GM) corn. He plans to survey 100
  farmers to see if more than 60\% prefer the GM variety over
  traditional varieties. Can he use the normal approximation to analyze
  his survey results?
\end{enumerate}

\textbf{Solution}

Michael can use the normal approximation in his study. The criteria for
using the normal approximation for proportions are that both \(np_0\)
and \(n(1 - p_0)\) must be greater than 5. Here, (the number of farmers
surveyed) and (the hypothesized proportion of farmers prefer the GM
variety).

Let's check if the conditions are met:

\begin{itemize}
\tightlist
\item
  \(np_0 = 100 * 0.6 = 60\), which is greater than 5.
\item
  \(n(1 - p_0) = 100 * 0.4 = 40\), which is also greater than 5.
\end{itemize}

Since both conditions are satisfied, the normal approximation can be
used to analyze the survey results.

A demonstration of this is shown below. Note how closely the normal
approximation applies to the binomial. However, it's a little bit off.
This is why R uses ``continuity correction'' (although we don't discuss
the details of this in this course).

\includegraphics{L18-Hypothesis_Tests_for_Proportions_files/figure-pdf/normal-approx-with-continuity-1.pdf}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  To study the cross breeding of heterozygous plants, Alex wants to
  perform a study on 8 Hamelin pea plants to test if 75\% of the plants
  are of the dominant type after breeding. Can she assume the normal
  approximation in her study?
\end{enumerate}

\textbf{Solution}

No! To use the normal approximation \(np \gt 10\) and \(n(1-p) \gt 10\)
must be obeyed. \(8*0.75\lt 10\) and \(8*(1-0.75) \lt 10\), thus Alex
should increase her sample size prior to using a normal approximation.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{confidence-intervals-for-a-proportion}{%
\chapter{Confidence Intervals for a
Proportion}\label{confidence-intervals-for-a-proportion}}

\hypertarget{introduction-6}{%
\section{Introduction}\label{introduction-6}}

\hypertarget{this-is-the-same-as-the-last-lesson}{%
\subsection{This is the same as the last
lesson}\label{this-is-the-same-as-the-last-lesson}}

\begin{itemize}
\tightlist
\item
  Based on our data, we make an interval that we think describes the
  population.\lspace\pause
\item
  In this case, we just have a different population distribution?
\end{itemize}

\hypertarget{assumptions}{%
\subsection{Assumptions}\label{assumptions}}

In stats, assumptions give us power, \pause but only if they're good
assumptions.

\pause

Assumptions for a CI for \(p\) are the same as the assumptions for the
binomial distribution, with the addition of an SRS.

\hypertarget{the-ci-for-p}{%
\section{\texorpdfstring{The CI for
\(p\)}{The CI for p}}\label{the-ci-for-p}}

\hypertarget{sampling-distribution-of-hat-p}{%
\subsection{\texorpdfstring{Sampling Distribution of
\(\hat p\)}{Sampling Distribution of \textbackslash hat p}}\label{sampling-distribution-of-hat-p}}

As we saw before the midterm, if the population is \(B(n,p)\), then
under certain conditions,

\[\hat p \sim N\left(p, \sqrt{\frac{p(1-p)}{n}}\right)\]

\hypertarget{deja-vu}{%
\subsection{Deja-Vu}\label{deja-vu}}

Since \(\hat p \sim N(p, \sqrt{\frac{p(1-p)}{n}})\),

\[
\frac{\hat p - p}{\sqrt{p(1-p)/n}} \sim N(0,1)
\]

\pause Again, we can use the form \(z = (x-\mu)/\sigma\), but replace
\(x\), \(\mu\), and \(\sigma\) with the correct values.\pause

A \((1-\alpha)\)CI for \(p\) is:

\[
\hat p \pm z^*\sqrt{\frac{p(1-p)}{n}}
\]

\hypertarget{we-dont-know-the-variance-why-not-t_n-1}{%
\subsection{\texorpdfstring{We don't know the variance, why not
\(t_{n-1}^*\)?}{We don't know the variance, why not t\_\{n-1\}\^{}*?}}\label{we-dont-know-the-variance-why-not-t_n-1}}

\begin{itemize}
\item
  We used \(t_{n-1}^*\) because we had to estimate \(\sigma\)\newline
\item
  There's no \(\sigma\) to estimate!\newline
\item
  The variance of the Binomial distribution is entirely determined by
  \(p\)!

  \begin{itemize}
  \tightlist
  \item
    Binom be crazy.
  \end{itemize}
\end{itemize}

\hypertarget{but-devan-we-still-dont-know-p}{%
\subsection{\texorpdfstring{\ldots{} but Devan, we still don't know
\(p\)!}{\ldots{} but Devan, we still don't know p!}}\label{but-devan-we-still-dont-know-p}}

The \((1-\alpha)\)CI for \(p\) is:

\[
\hat p \pm z^*\sqrt{\frac{p(1-p)}{n}}
\] which needs \(p\) in the second part of the equation.\pause

\quad

Why not just plug in \(\hat p\)?\pause

Okay fine. \pause

\(\sqrt{\hat p(1-\hat p)/n}\) is called the \textbf{estimated standard
error}, since its the sd of the sampling distribution, but it's based on
an estimate.

\hypertarget{final_version_v2_update_lasttry_srsly.docx.pdf}{%
\subsection{Final\_Version\_V2\_Update\_LastTry\_Srsly.docx.pdf}\label{final_version_v2_update_lasttry_srsly.docx.pdf}}

The \((1-\alpha)\)CI for \(p\) is:

\[
\hat p \pm z^*\sqrt{\frac{\hat p(1-\hat p)}{n}}
\]

where \(z^*\) is chosen such that \(P(Z < -z^*) = \alpha/2\).

\hypertarget{devan-style-simulation}{%
\subsection{Devan Style: Simulation}\label{devan-style-simulation}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{p }\OtherTok{\textless{}{-}} \FloatTok{0.7}
\NormalTok{SE\_true }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{/}\NormalTok{n)}
\NormalTok{p\_does }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{phat\_does }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{that\_does }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{z\_star }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{t\_star }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{qt}\NormalTok{(}\FloatTok{0.05}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{df =}\NormalTok{ n}\DecValTok{{-}1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{devan-style-simulation-1}{%
\subsection{Devan Style: Simulation}\label{devan-style-simulation-1}}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10000}\NormalTok{)\{}
\NormalTok{    new\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\AttributeTok{n=}\DecValTok{1}\NormalTok{, }\AttributeTok{size=}\NormalTok{n, }\AttributeTok{prob=}\NormalTok{p)}
\NormalTok{    phat }\OtherTok{\textless{}{-}}\NormalTok{ new\_sample}\SpecialCharTok{/}\NormalTok{n}
\NormalTok{    SE\_est }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(phat}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{phat)}\SpecialCharTok{/}\NormalTok{n)}
    
\NormalTok{    pCI }\OtherTok{\textless{}{-}}\NormalTok{ phat }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{z\_star}\SpecialCharTok{*}\NormalTok{SE\_true}
\NormalTok{    phatCI }\OtherTok{\textless{}{-}}\NormalTok{ phat }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{z\_star}\SpecialCharTok{*}\NormalTok{SE\_est}
\NormalTok{    thatCI }\OtherTok{\textless{}{-}}\NormalTok{ phat }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{t\_star}\SpecialCharTok{*}\NormalTok{SE\_est}
    
\NormalTok{    p\_does[i] }\OtherTok{\textless{}{-}}\NormalTok{ pCI[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\textless{}}\NormalTok{ p }\SpecialCharTok{\&}\NormalTok{ pCI[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{\textgreater{}}\NormalTok{ p}
\NormalTok{    phat\_does[i] }\OtherTok{\textless{}{-}}\NormalTok{ phatCI[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\textless{}}\NormalTok{ p }\SpecialCharTok{\&}\NormalTok{ phatCI[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{\textgreater{}}\NormalTok{ p}
\NormalTok{    that\_does[i] }\OtherTok{\textless{}{-}}\NormalTok{ thatCI[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\textless{}}\NormalTok{ p }\SpecialCharTok{\&}\NormalTok{ thatCI[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{\textgreater{}}\NormalTok{ p}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{simulation-results}{%
\subsection{Simulation Results}\label{simulation-results}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(p\_does)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9371
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(phat\_does)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9502
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(that\_does)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9502
\end{verbatim}

Using the population proportion is\ldots{} worse?\pause

DIY: Change \(p\) so that the normal approximation doesn't apply.

\hypertarget{examples-and-cautions}{%
\section{Examples and Cautions}\label{examples-and-cautions}}

\hypertarget{example-1-1}{%
\subsection{Example 1}\label{example-1-1}}

It was found that 591 out of 700 people sampled supported a certain
political position. Find a 91\%CI.

Since we have R, let's use it!

Both \texttt{prop.test()} and \texttt{binom.test()} will give us a CI,
with \texttt{prop.test()} calculating an approximation using the normal
distribution and \texttt{binom.test()} calculating the exact value,
without approximation. In general, you should always use
\texttt{binom.test()} for one sample proportions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{binom.test}\NormalTok{(}\AttributeTok{x =} \DecValTok{591}\NormalTok{, }\AttributeTok{n =} \DecValTok{700}\NormalTok{, }\AttributeTok{conf.level =} \FloatTok{0.91}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Exact binomial test

data:  591 and 700
number of successes = 591, number of trials = 700, p-value < 2.2e-16
alternative hypothesis: true probability of success is not equal to 0.5
91 percent confidence interval:
 0.8192078 0.8670686
sample estimates:
probability of success 
             0.8442857 
\end{verbatim}

\hypertarget{example-2-1}{%
\subsection{Example 2}\label{example-2-1}}

It was found that 68 out of 70 people sampled supported a certain
political position. Find a 91\%CI.\pause

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{70}
\NormalTok{phat }\OtherTok{\textless{}{-}} \DecValTok{68}\SpecialCharTok{/}\DecValTok{70}
\NormalTok{se\_est }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(phat}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{phat)}\SpecialCharTok{/}\NormalTok{n)}
\NormalTok{z\_star }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.09}\SpecialCharTok{/}\DecValTok{2}\NormalTok{))}

\NormalTok{phat }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{z\_star}\SpecialCharTok{*}\NormalTok{se\_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9376692 1.0051879
\end{verbatim}

\ldots{} so it would be reasonable to say that the popluation proportion
is larger than 1???

Absolutely not! The normal approximation does not apply here since
\(n(1 - \hat p) = 70*(1 - 68/70) = 2\), and 2 is less than
10\footnote{Citation needed.}. The normal distribution can only be used
when the sample size is large enough!!!

Instead, we can use the exact test. This is much slower to calculate,
but for \(n = 70\) there's no issue.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{binom.test}\NormalTok{(}\AttributeTok{x =} \DecValTok{68}\NormalTok{, }\AttributeTok{n =} \DecValTok{70}\NormalTok{, }\AttributeTok{conf.level =} \FloatTok{0.91}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Exact binomial test

data:  68 and 70
number of successes = 68, number of trials = 70, p-value < 2.2e-16
alternative hypothesis: true probability of success is not equal to 0.5
91 percent confidence interval:
 0.9108816 0.9951927
sample estimates:
probability of success 
             0.9714286 
\end{verbatim}

Notice that

\hypertarget{example-2-2}{%
\subsection{Example 2}\label{example-2-2}}

It was found that 68 out of 70 people sampled supported a certain
political position. Find a 91\%CI.\pause

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{binom.test}\NormalTok{(}\AttributeTok{x =} \DecValTok{68}\NormalTok{, }\AttributeTok{n =} \DecValTok{70}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Exact binomial test

data:  68 and 70
number of successes = 68, number of trials = 70, p-value < 2.2e-16
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
 0.9005711 0.9965209
sample estimates:
probability of success 
             0.9714286 
\end{verbatim}

\hypertarget{inference-for-the-difference-in-proportions}{%
\chapter{Inference for the Difference in
Proportions}\label{inference-for-the-difference-in-proportions}}

\hypertarget{diy-confidence-intervals}{%
\section{DIY Confidence Intervals}\label{diy-confidence-intervals}}

This lesson is going to be a little different from the rest. I'm not
going to give you the answers, I'm going to give you the tools.

\hypertarget{standard-error-for-a-single-mean}{%
\subsection{Standard Error for a Single
Mean}\label{standard-error-for-a-single-mean}}

As we've seen many times, this is \[
SE(\bar X) = \frac{\sigma}{\sqrt{n}} = \sqrt{\frac{\sigma^2}{n}},
\] but we often use \[
\hat{SE}(\bar X) = \frac{S}{\sqrt{n}} = \sqrt{\frac{S^2}{n}},
\] which is the \textbf{estimated standard error} (the ``hat'' on top of
the letters ``SE'' indicates that it's estimated). For the rest of this
lecture, we'll always use the estimated standard error.

\hypertarget{standard-error-for-the-difference-in-means}{%
\subsection{Standard Error for the Difference in
Means}\label{standard-error-for-the-difference-in-means}}

Even though we were subtracting means, we added their variances and then
take their square root. \[
\hat{SE}(\bar X_1 - \bar X_2) = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}
\] It is an important fact that we add the variances and then take the
square root.

From this lesson, also note that we had to make the assumptions:

\begin{itemize}
\tightlist
\item
  The individuals within a group are independent of other individuals in
  that group.

  \begin{itemize}
  \tightlist
  \item
    For example, if we sample people in our own family then the samples
    are not independent. People in the same family tend to have similar
    characteristics, so knowledge of the characteristics of one family
    member are informative about the others.\footnote{Recall that
      \textbf{independence} means that knowledge of one outcome gives
      you a better guess at other outcomes.}
  \end{itemize}
\item
  The \emph{groups} are independent.

  \begin{itemize}
  \tightlist
  \item
    For example, if we're looking at the difference in mean heights
    between men and women, but we have spousal pairs. Spousal pairs have
    a smaller difference in height than the average difference in
    height.\footnote{In this example, we could find the difference in
      heights between spouses, then use this collection of differences
      in a \emph{one-sample} t-test, which gives us different
      information, but it's also interesting.}
  \end{itemize}
\end{itemize}

\hypertarget{standard-error-for-a-single-proportion}{%
\subsection{Standard Error for a Single
Proportion}\label{standard-error-for-a-single-proportion}}

This is nothing new, I'm just repeating it here: \[
\hat{SE}(\hat p) = \sqrt{\frac{\hat p(1 - \hat p)}{n}}
\]

\hypertarget{standard-error-for-the-difference-in-proportions}{%
\subsection{Standard Error for the Difference in
Proportions}\label{standard-error-for-the-difference-in-proportions}}

This is up to you to find! Keed these in mind:

\begin{itemize}
\tightlist
\item
  The standard error cannot be negative, so you probably can't subtract
  things.
\item
  Variances can be added if we assume things are independent.

  \begin{itemize}
  \tightlist
  \item
    Make these assumptions explicit!
  \end{itemize}
\end{itemize}

\hypertarget{confidence-interval-example-1}{%
\subsection{Confidence Interval
Example}\label{confidence-interval-example-1}}

This question is from \emph{OpenIntro Introductory Statistics for the
Life and Biomedical Sciences, First Edition}.

The way a question is phrased can inuence a person's response. For
example, Pew Research Center conducted a survey with the following
question:

\begin{quote}
As you may know, by 2014 nearly all Americans will be required to have
health insurance. {[}People who do not buy insurance will pay a
penalty{]} while {[}People who cannot afford it will receive financial
help from the government{]}. Do you approve or disapprove of this
policy?
\end{quote}

For each randomly sampled respondent, the statements in brackets were
randomized: either they were kept in the order given above, or the order
of the two statements was reversed. The table below shows the results of
this experiment. Calculate and interpret a 90\% condence interval of
the difference in the probability of approval of the policy.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
& Sample size \(n_i\) & Approve \% \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Original Ordering & 771 & 47 \\
Reversed Ordering & 732 & 34 \\
\end{longtable}

\textbf{Solution}

Let \(p_1\) be the proportion who approve when given the original
ordering with sample size \(n_1\), and \(p_2\) be the proportion who
approve when given the reversed ordering with sample size \(n_2\). This
question is asking us to calculate a confidence interval for
\(p_1 - p_2\).

We first check the conditions required to use the normal approximation.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pew Research Center is basically the world expert on opinion polling,
  so the samples are probably good.
\item
  We can safely assume that the samples are independent.
\item
  The two statements were randomly assigned, so it's safe to say that
  the two groups are independent.
\item
  \(n_1 * 0.47 = 771 * 0.47 = 362.37\)

  \begin{itemize}
  \tightlist
  \item
    There are \emph{three} other calculations to check. Check them!
  \end{itemize}
\end{enumerate}

Now that that's covered, we can make a confidence interval. The general
form is: \[
\text{Point Estimate}\pm\text{Critical Value}*\text{Standard Error}
\] From your homework above, verify that you can calculate the standard
error as 0.025.\footnote{This is to ensure you have the correct
  caclulation, you won't need to do this on a test.}

Our point estimate is \(\hat p_1 - \hat p_2 = 0.47 - 0.34 = 0.13\).
Since we doing a difference in proportions, our critical value comes
from the normal distribution:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qnorm}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.9}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -1.644854
\end{verbatim}

So our confidence interval is: \[
0.13 \pm 1.65*0.025 = (0.09, 0.17)
\]

We are 90\% confident that the true mean difference is between 0.09 and
0.17. This provides evidence that the two proportions are indeed
different.

\hypertarget{hypothesis-testing}{%
\section{Hypothesis Testing}\label{hypothesis-testing}}

Here's where things are a little less obvious - I'm not going to get you
to find the standard error yourself!

We are generally looking at a hypothesis test for whether two
proportions are \emph{equal}, that is, \[
H_0: p_1 = p_2\implies p_1 - p_2 = 0
\] with an alternative that they are not equal, or that one is bigger
than the other. In other words, we're looking at the
hypotheses:\footnote{There may be a time in your life where you test
  whether \(p_1 - p_2 = 0.25\) or something like that, and you'll need
  to modify the methods a little bit.} \begin{align*}
H_0: &p_{1-2} = 0\\
H_A: &p_{1-2} \ne 0\text{ or }p_{1-2} > 0\text{ or }p_{1-2} > 0\\
\end{align*}

In the lesson on proportions, we saw that the standard error depended on
the null hypothesis being \emph{true}, since we calculate p-values under
the assumption that the null hypothesis is true. How do we do that here?

\hypertarget{the-pooled-proportion}{%
\subsection{The Pooled Proportion}\label{the-pooled-proportion}}

Under the null hypothesis, \(p_1 = p_2\). That's like saying that we
observed a bunch of successes and failures from a single group, instead
of two. Let \(x_1\) be the number of successes in the first group, and
\(x_2\) the number for the second. Then \[
\hat p = \frac{x_1 + x_2}{n_1 + n_2}
\] That is, we observed \(x_1 + x_2\) successes out of \(n_1 + n_2\)
trials.

For example, if we assume that two coins have the same probability of
heads, the getting 5 heads in 9 flips for one coin and 3 heads out of 6
flips for the other. The two coins are assumed to be identical, so it's
like we flipped one coin 15 times and got 8 heads.

As before, the assumption that the null hypothesis is true is used
\emph{everywhere}. This means it's true for testing whether the normal
approximation is appropriate. We must test \(n_1\hat p\),
\(n_1(1 - \hat p)\), \(n_2\hat p\), and \(n_2(1 - \hat p)\).

From this, we might assume that our standard error is something like: \[
\hat{SE}(\hat p_1 - \hat p_2) = \sqrt{\frac{\hat p(1 - \hat p)}{???}}
\] The ??? might seem like it should be \(n_1 + n_2\), but some advanced
math shows that this doesn't quite work. Again, this is from the problem
of adding variances, but working with standard deviations. Instead, the
standard error is: \[
\hat{SE}(\hat p_1 - \hat p_2) = \sqrt{\hat p(1 - \hat p)\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}
\]

This standard error is based on the null hypothesis, specifically the
assumption that the groups are identical, so it's as if we took two
samples from the same population.

As before, the test statistic is \[
\frac{\text{sample statistic} - \text{hypothesized value}}{\text{standard error}} = \frac{(\hat p_1 - \hat p_2) - 0}{\sqrt{\hat p(1 - \hat p)\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}}
\] and this is compared to the normal distribution.

\hypertarget{hypothesis-test-example-1}{%
\subsection{Hypothesis Test Example}\label{hypothesis-test-example-1}}

Using the same example as before, we can set up our null hypothesis as
\(p_1 = p_2\), and we'll choose the alternate hypothesis
\(p_1 \ne p_2\).\footnote{You might have also chosen \(p_1 > p_2\) if
  you thought, before seeing the results of the study, that the original
  order would lead to more agreement.} We'll use the 5\% level.

The ``pooled'' estimate is based on \(x_1\) and \(x_2\), which we can
find based on \(\hat p_1\) and \(n_1\). Since \(\hat p_1 = x_1/n_1\), we
can find \(x_1 = \hat p_1 n_1 = 771 * 0.47 = 362.37\), which we'll round
to 362. Similarly, we'll use \(x_2\) as 249. \[
\hat p = \frac{362 + 249}{771 + 732} = 0.4065
\]

The test statistic is calculated as \[
\frac{(\hat p_1 - \hat p_2) - 0}{\sqrt{\hat p(1 - \hat p)\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}} = \frac{(0.47 - 0.34) - 0}{\sqrt{0.4065(1-0.4065)(1/771 + 1/732)}} = 5.12
\]

We all remember the all-important value of 1.96, right? The total area
under the normal curve above 1.96 plus the area below -1.96 adds to 5\%.
If we get a z-score above 1.96 or below -1.96, we know that the p-value
is \emph{smaller than} 5\%. Intuitively, 5.12 is a \emph{massive}
z-score, and thus will have a miniscule p-value.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FloatTok{5.12}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.055357e-07
\end{verbatim}

That's a p-value of approximately 0.0000003. We can safely reject the
null hypothesis.

This isn't surprising, the original proportions were 0.47 and 0.35, with
sample sizes of 771 and 732. Given the sample size, we expect a pretty
small standard error and thus we shouldn't be surprised that a
difference of 0.13 counts as a ``big'' difference!

\hypertarget{example-5}{%
\section{Example}\label{example-5}}

The following example comes from OpenIntro Statistics for Health and
Life Sciences.

The use of screening mammograms for breast cancer has been controversial
for decades because the overall benefit on breast cancer mortality is
uncertain. Several large randomized studies have been conducted in an
attempt to estimate the effect of mammogram screening. A 30-year study
to investigate the effectiveness of mammograms versus a standard
non-mammogram breast cancer exam was conducted in Canada with 89,835
female participants. During a 5-year screening period, each woman was
randomized to either receive annual mammograms or standard physical
exams for breast cancer. During the 25 years following the screening
period, each woman was screened for breast cancer according to the
standard of care at her health care center.

At the end of the 25 year follow-up period, 1,005 women died from breast
cancer. The results by intervention are summarized below.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
& Died & Survived \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Mammogram & 500 & 44,425 \\
Control & 505 & 44,405 \\
\end{longtable}

Assess whether the normal model can be used to analyze the study
results.

Since the participants were randomly assigned to each group, the groups
can be treated as independent, and it is reasonable to assume
independence of patients within each group. Participants in randomized
studies are rarely random samples from a population, but the
investigators in the Canadian trial recruited participants using a
general publicity campaign, by sending personal invitation letters to
women identified from general population lists, and through contacting
family doctors. In this study, the participants can reasonably be
thought of as a random sample.

The pooled proportion \(\hat{p}\) is

\[
\hat{p} = \dfrac{x_{1} + x_{2}}{n_{1} + n_{2}} = \dfrac{500 + 505}{500 + 44425 + 505 + 44405} = 0.0112
\]

Checking the success-failure condition for each group: \begin{align*}
\hat{p} \times n_{mgm} &= 0.0112 \times \text{44,925} = 503\\
(1 - \hat{p}) \times n_{mgm} &= 0.9888 \times \text{44,925} = \text{44,422} \\
\hat{p} \times n_{ctrl} &= 0.0112 \times \text{44,910} = 503\\
(1 - \hat{p}) \times n_{ctrl} &= 0.9888 \times \text{44,910} = \text{44,407}
\end{align*} All values are at least 10.\footnote{It is worth noting
  that these values are very close to the original values we were given.
  If we were doing a confidence interval where we don't use the pooled
  proportion, we could have just checked the values in the given table!}

The normal model can be used to analyze the study results.

We can use this information to do a hypothesis test for the equality of
proportions.

The standard error is still: \[
\sqrt{\hat p(1 - \hat p)\left(\frac{1}{n_1} + \frac{1}{n_2}\right)} = 0.000702
\] That's quite small, but this is to be expected with such a large
sample size.

The test statistic is \(\hat p_1 - \hat p_2 / 0.000706 = -0.17\). Again,
using our intuition, this is way lower than our 1.96 value, so this is
very much \emph{not} a significant result.

We conclude that there is insufficient evidence to reject the null
hypothesis; the observed difference in breast cancer death rates is
reasonably explained by sampling error when the two proportions are
equal.

Evaluating medical treatments typically requires accounting for
additional evidence that cannot be evaluated from a statistical test.
For example, if mammograms are much more expensive than a standard
screening and do not offer clear benefits, there is reason to recommend
standard screenings over mammograms. This study also found that a higher
proportion of diagnosed breast cancer cases in the mammogram screening
arm (3250 in the mammogram group vs 3133 in the physical exam group),
despite the nearly equal number of breast cancer deaths. The
investigators inferred that mammograms may cause over-diagnosis of
breast cancer, a phenomenon in which a breast cancer diagnosed with
mammogram and subsequent biopsy may never become symptomatic. The
possibility of over-diagnosis is one of the reasons mammogram screening
remains controversial.

\hypertarget{chi-square-test-for-multiple-proportions}{%
\chapter{Chi-Square Test for Multiple
Proportions}\label{chi-square-test-for-multiple-proportions}}

\hypertarget{differences-in-proportions-independence}{%
\section{Differences in Proportions;
Independence}\label{differences-in-proportions-independence}}

Recall the following example from the lesson on multiple
proportions.\footnote{Adapted from OpenIntro BioStats.} We were
interested in whether getting a mammogram lead to fewer deaths due to
breast cancer, and were presented the following data:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
& Died & Survived & Total \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Mammogram & 500 & 44,425 & 44,925 \\
Control & 505 & 44,405 & 44,910 \\
Total & 1,005 & 88,830 & 89,835 \\
\end{longtable}

In that lesson, we asked whether the proportion of people who died was
the same in the mammogram group and the control group. This is a very
specific approach, and in this lesson we will generalize it to many
situations.

The question can be re-worded as ``Does knowing that the patient got a
mammogram tell us more about whether they survived?'' This phrasing
should sound familiar - it's a question about \textbf{independence}!
Instead of asking about the difference in proportions, we can ask about
whether the survival of the patient is independent of the method of
screening.

In essence, we're checking \emph{all} of the potential conditional
probabilities. This includes P(Died \textbar{} Mammogram)
\(\stackrel{?}{=}\) P(Died) as well as P(Mammogram \textbar{} Died)
\(\stackrel{?}{=}\) P(Mammogram). Technically, these two statements are
equivalent, so we can think about it whichever way is more useful. The
test we're about to describe also tests for whether P(Died \textbar{}
Control) \(\stackrel{?}{=}\) P(Died) at the same time.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Test for Independence of Columns and Rows}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

The Chi-Square test that we are about to learn is a test of whether the
rows of a two-way table are independent of the columns. This works no
matter how many rows/columns there are.

\[
H_0: \text{The rows are indepenent of the columns} vs. \text{There is some form of dependence}
\] The Chi-Square test gives a significant result if there is \emph{any}
deviation from independence, even if it's just one cell in the two-way
table that doesn't fit the pattern.

\end{tcolorbox}

The interpretation of the test is that all of the rows look the same as
each other; the counts in the rows are random deviations from the same
distribution. The same interpretation applies to columns.

In this example, the test for a difference in proportions is the exact
same idea as a test for independence of rows and columns, but this will
generalize the same idea to any number of rows/columns.

\hypertarget{expected-counts}{%
\section{Expected Counts}\label{expected-counts}}

Just like in the tests for two proportions, we're going to see what
\emph{would have} happened if there was actually no difference. That is,
what would the table above look like if the outcome was
\textbf{independent} of the screening method?

As you'll clearly recall, we can multiply probabilities if they are
independent. That is, \[
P(A\text{ and }B) \stackrel{indep}{=}P(A)P(B),
\] where, again, I stress that this is only true if events A and B are
independent.

For hypothesis tests, we calculate things assuming that the null
hypothesis is true. In this case, we assume that the events are
independent and thus we can multiply their probabilities. So the
proportion of people we expect to see in the ``mammogram and died''
group is: \[
P(\text{mammogram and died}) = P(\text{mammogram})P(\text{died}) = \left(\frac{44925}{89835}\right)\left(\frac{1005}{89835}\right) \approx 0.5662
\] Where did these numbers come from? \(P(\text{mammogram})\) is the
number of people in the mammogram row divided by the total number of
people. That is, this is the proportion of people who were screened via
mammogram, regardless of whether they survived. Similarly, 10005 is the
number of people who did not survive, regardless of whether they were
screened via mammogram.\footnote{In other words, they're the row
  probabilities regardless of column and the column probability
  regardless of row.} Note that this the probability of mammogram
\emph{and} died, not the probability of death \emph{given that they}
were screened via mammogram.

This is the proportion of patients, so the expected count is just
\(np\), the sample size times the proportion. Notice what happens to the
calculation when we include this number: \[
88935 * P(\text{mammogram and died}) = 88935 \left(\frac{44925}{89835}\right)\left(\frac{1005}{89835}\right) = \frac{1005*44295}{89835} = 502.6
\]

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Expected Counts for a Two-Way Table}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

\[
\text{Expect count for the cell in row }i\text{, column }j = \frac{(\text{row }i\text{ total})(\text{column }j\text{ total})}{\text{table total}}
\]

\end{tcolorbox}

The following table shows the actual counts and expected counts in the
format actual(expected). For practice, double check the calculations!

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
& Died & Survived & Total \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Mammogram & 500 (502.6) & 44,425 (44,422.4) & 44,925 \\
Control & 505 (502.4) & 44,405 (44,407.6) & 44,910 \\
Total & 1,005 & 88,830 & 89,835 \\
\end{longtable}

\hypertarget{the-chi-square-test-statistic}{%
\subsection{The Chi-Square Test
Statistic}\label{the-chi-square-test-statistic}}

Up until this exact moment, all our test statistics have been of the
form (observed - hypothesized)/standard error. This ends here. Here
we'll introduce the Chi-Square test statistic, often written as
\(\chi^2\), which is greek letter ``chi'', pronounced ``kai''.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{The \(\chi^2\) Test Statistic}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

After gathering the observed counts and calculating the expected counts,
the ``Chi-Square'' test statistic is: \[
\chi^2 = \sum_{\text{all cells}}\frac{(\text{observed} - \text{expected})^2}{\text{expected}}
\]

\end{tcolorbox}

There are a couple important features of this value:

\begin{itemize}
\tightlist
\item
  The numbers are squared so that negatives don't cancel out wiht
  positives.
\item
  We divide by expected counts, which means that a large deviation is
  okay if it's for a large count.

  \begin{itemize}
  \tightlist
  \item
    For example, 500 is 5 away from 505 and 44425 is 20 away from 44405,
    but the 500 and the 505 ``feel'' like they're closer together
    because the counts are small. With large counts, we're more
    forgiving of observed minus expected.
  \end{itemize}
\end{itemize}

This test statistic is based on the normal approximation to the binomial
distribution, so you'd better believe that there are some conditions
before we can do a hypothesis test!

\begin{itemize}
\tightlist
\item
  Each individual must be independent of each other individual.

  \begin{itemize}
  \tightlist
  \item
    This is \emph{very} different from assuming that the clomn variable
    is independent of the row variable.
  \item
    For example, random sampling will ensure independence of individuals
    in the study.
  \end{itemize}
\item
  Each expected cell count must be larger than 10.

  \begin{itemize}
  \tightlist
  \item
    Some textbooks use the looser rule that at most 1/5th of the
    expected counts are less than 5. This gets confusing, and you really
    just need to ensure that you have a large enough sample in
    \emph{each cell} of the two-way table.
  \end{itemize}
\end{itemize}

For the mammogram example, these conditions are satisfied. Verify that
the \(\chi^2\) test stat is 0.02.

The p-value for a \(z\) test statistic is calculated from the normal
distribution, the p-value for a \(t\) test statistic is calculated from
a \(t\) distribution, and the \(\chi^2\) test statistic is calculated
from a \(\chi^2\) distribution!

The null hypothesis for this test is simply that the rows and columns
are independent, with the alternate hypothesis being that this is false.
Because of the way the \(\chi^2\) statistic is calculated, any
difference between observed and expected \emph{increases} the test
statistic. In other words, we only really care about the upper tail.

Before we can calculate a p-value, we need to know the degrees of
freedom. Again, this is a confusing concept that is often best
memorized. For a two-way table, the df is \[
df = (r-1)(c-1)
\] where \(r\) is the number of rows and \(c\) is the number of columns.

We can calculate the right-tailed p-value as follows:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pchisq}\NormalTok{(}\FloatTok{0.02}\NormalTok{, }\AttributeTok{df =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.8875371
\end{verbatim}

That's nearly 1, so there's no reasonable significance level for which
this test would be significant. We conclude that it's reasonable to
think that the rows and columns are independent\footnote{We're searching
  for evidece \emph{against} the null, we can never conclude that the
  null is true!}, and so we can say that there's no difference in
outcome across different methods of screening.\footnote{We can also say
  that there's no difference in levels of screening across outcomes, but
  this isn't meaningful given the context of the data.}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{The \(\chi^2\) Test}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

The \(\chi^2\) test calculates the difference in observed counts and
what would be expected if the rows and columns were independent, then
finds a one-tailed p-value to tell whether the observed and expected
counts are too different.

A significant p-value means there is some sort of dependence, even if
it's just one cell that is sufficiently different.

\end{tcolorbox}

\hypertarget{this-example-in-r}{%
\subsection{This Example in R}\label{this-example-in-r}}

Preparing the data for R is relatively difficult, so ignore those
details.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mammograms }\OtherTok{\textless{}{-}} \FunctionTok{as.table}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{500}\NormalTok{, }\DecValTok{44425}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\DecValTok{505}\NormalTok{, }\DecValTok{44405}\NormalTok{)))}
\FunctionTok{colnames}\NormalTok{(mammograms) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Died"}\NormalTok{, }\StringTok{"Survived"}\NormalTok{)}
\FunctionTok{rownames}\NormalTok{(mammograms) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Mammogram"}\NormalTok{, }\StringTok{"Control"}\NormalTok{)}
\NormalTok{mammograms}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
           Died Survived
Mammogram   500      505
Control   44425    44405
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(mammograms)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pearson's Chi-squared test with Yates' continuity correction

data:  mammograms
X-squared = 0.01748, df = 1, p-value = 0.8948
\end{verbatim}

Again, R does a better calculation using continuity correction, which is
out of the scope of this course.

For this simple example, note that this is the same as a two-sample test
for proportions (but with a different form of contnuity correction):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.test}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{500}\NormalTok{, }\DecValTok{505}\NormalTok{), }\AttributeTok{n =} \FunctionTok{c}\NormalTok{(}\DecValTok{44425}\NormalTok{, }\DecValTok{44405}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    2-sample test for equality of proportions with continuity correction

data:  c(500, 505) out of c(44425, 44405)
X-squared = 0.017976, df = 1, p-value = 0.8933
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.001531197  0.001295859
sample estimates:
    prop 1     prop 2 
0.01125492 0.01137259 
\end{verbatim}

\hypertarget{another-example-in-r}{%
\subsection{Another Example in R}\label{another-example-in-r}}

The following data come from the help file for the \texttt{chisq.test()}
function in R.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{party\_by\_gender }\OtherTok{\textless{}{-}} \FunctionTok{as.table}\NormalTok{(}\FunctionTok{rbind}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{762}\NormalTok{, }\DecValTok{327}\NormalTok{, }\DecValTok{468}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\DecValTok{484}\NormalTok{, }\DecValTok{239}\NormalTok{, }\DecValTok{477}\NormalTok{)))}
\CommentTok{\# The following line is just to make sure we get pretty output}
\CommentTok{\# It is NOT something you\textquotesingle{}d be expect to reproduce}
\FunctionTok{dimnames}\NormalTok{(party\_by\_gender) }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{gender =} \FunctionTok{c}\NormalTok{(}\StringTok{"F"}\NormalTok{, }\StringTok{"M"}\NormalTok{),}
    \AttributeTok{party =} \FunctionTok{c}\NormalTok{(}\StringTok{"Democrat"}\NormalTok{,}\StringTok{"Independent"}\NormalTok{, }\StringTok{"Republican"}\NormalTok{))}
\NormalTok{party\_by\_gender}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      party
gender Democrat Independent Republican
     F      762         327        468
     M      484         239        477
\end{verbatim}

We want to know whether the party affiliation is independent of the
gender. By eye, it looks like there are more women in the democratic
party, slightly more in the Independent party, and about the same in the
republican party. However, there are more women in general in this
study, so it's not immediately obvious that this is a difference in
party affiliation or a difference in sample sizes across groups. This is
where the \(\chi^2\) test works best!

Let's use the built-in R function to save us some work.\footnote{For
  practice try to calculate these by hand!}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(party\_by\_gender)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pearson's Chi-squared test

data:  party_by_gender
X-squared = 30.07, df = 2, p-value = 2.954e-07
\end{verbatim}

We can see that the \(\chi^2\) test statistic is 30.07, the degrees of
freedom is (2-1)*(3-1)=1*2=2, and the resultant p-value is about 3 times
ten to the negative 7. This is definitely a statistically significant
relationship, and we can conclude that there's a difference in party
affiliation across genders.

Now that we know there's a statistically significant difference, we can
see where this difference is. We can look at which observed values are
furthest from the expected values. Like in linear regression, we are
looking at the \textbf{residuals}.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Residuals for a \(\chi^2\) Test}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

For the cell in row \(i\) and column \(j\), the residual is defined as:
\[
\frac{\text{observed} - \text{expected}}{\sqrt{\text{expected}}}
\] This is just the square root of their contribution to the \(\chi^2\)
test statistic, which preserves the sign (expected counts that are too
small are still negative).

\end{tcolorbox}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Rounding the values for nicer display}
\FunctionTok{round}\NormalTok{(}\FunctionTok{chisq.test}\NormalTok{(party\_by\_gender)}\SpecialCharTok{$}\NormalTok{residuals, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      party
gender Democrat Independent Republican
     F     2.20        0.41      -2.84
     M    -2.50       -0.47       3.24
\end{verbatim}

The main thing that sticks out to me is that the count for republican
women and republican men was about the same, but this is actually way
more men than expected due to the sample size!

\hypertarget{confidence-intervals-2}{%
\section{Confidence Intervals}\label{confidence-intervals-2}}

Let's not.\footnote{There's not really a single statistic that's worth
  making a CI for. We could make one for each expected count, but that's
  silly.}

\hypertarget{chi-square-and-power}{%
\subsection{Chi-Square and Power}\label{chi-square-and-power}}

In previous lectures, we saw that \textbf{power} is our ability to
reject a false null.

\begin{itemize}
\tightlist
\item
  If we're looking for a ``small'' difference, we need a larger sample
  size.
\end{itemize}

\pspace

What's a ``small'' difference in a Chi-Square test?

\begin{itemize}
\tightlist
\item
  Not calculating a single estimate, so there's no one value to compare
  to a hypothesis.
\item
  Instead, the Chi-Square statistic is the important thing. It's an
  overall measure of the difference between observed and expected.
\end{itemize}

The \(\chi^2\) statistic is divided by \emph{expected} \(\implies\)
differences are less important when \emph{expected} is larger. Recall:

\[
\chi^2 = \sum_{\text{all cells}}\frac{(\text{observed} - \text{expected})^2}{\text{expected}}
\]

\begin{itemize}
\tightlist
\item
  A value that's 10 units away from the \emph{expected} count\ldots{}

  \begin{itemize}
  \tightlist
  \item
    Is a large difference if the \emph{expected} count is 2
  \item
    Is a small difference if the \emph{expected} count is 2,000\lspace
  \end{itemize}
\end{itemize}

In other words, the interpretation of the difference between observed
and expected depends on the size of the expected count, and with a
larger sample size we get a larger expected count.

\pspace

This is the same as with means and proportions!!! There's no ``standard
error'' for Chi-Square tests, but there's still a concept of ``larger
sample means smaller variance in the sampling distribution''!

\hypertarget{chi-square-for-goodness-of-fit}{%
\section{Chi-Square for ``Goodness of
Fit''}\label{chi-square-for-goodness-of-fit}}

In the lesson so far, the ``expected'' counts were the counts that would
be expected if the null hypothesis were true, that is, if the rows and
columns were independent. We can define the expected counts differently
and still use the \(\chi^2\) test!

In particular, we can check whether a hypothesized distribution works
for a given set of data.\footnote{The name ``Goodness of Fit'' is often
  used for this, but it's a bad name. The null hypothesis is that the
  observed data fit with the given distribution, but we never confirm
  the null so we can never say that it's a ``good'' fit.} For example,
we can check whether the demographics of a study are the same as the
demographics in the population. The following example comes from the
OpenIntro textbook, where it discusses a study called the ``FAMuSS''
study.

\begin{longtable}[]{@{}llllll@{}}
\toprule\noalign{}
& African American & Asian & Caucasian & Other & Total \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
FAMuSS & 27 & 55 & 467 & 46 & 595 \\
US Census & 0.128 & 0.01 & 0.804 & 0.058 & 1 \\
Expected & 79.16 & 5.95 & 478.38 & 34.61 & 595 \\
\end{longtable}

In this example, we know the true distribution of ethnicities in the
population, and we're testing whether the demographics in the study
follow this distribution.

The ``Expected'' counts are simply the census proportions times the
sample size. We can see visually that there's a difference, but are
these differences big compared to sampling error? A hypothesis test will
save us!

We can calculate the \(\chi^2\) statistic in the exact same way: \[
\chi^2 = \sum_{\text{all cells}}\frac{(\text{observed} - \text{expected})^2}{\text{expected}}
\] and compare this to a \(\chi^2\) distribution. As before, I'm too
lazy to do this by hand and I want R to do it for me. Let's use the
usual 5\% significance level.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{observed }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{27}\NormalTok{, }\DecValTok{55}\NormalTok{, }\DecValTok{467}\NormalTok{, }\DecValTok{46}\NormalTok{)}
\NormalTok{hypothesized }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.128}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.804}\NormalTok{, }\FloatTok{0.058}\NormalTok{)}
\FunctionTok{chisq.test}\NormalTok{(}\AttributeTok{x =}\NormalTok{ observed, }\AttributeTok{p =}\NormalTok{ hypothesized)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Chi-squared test for given probabilities

data:  observed
X-squared = 440.18, df = 3, p-value < 2.2e-16
\end{verbatim}

According to R, the demographics are significantly different!

For more examples of the goodness-of-fit test, see
\href{https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Statistics_with_Technology_2e_(Kozak)/11\%3A_Chi-Square_and_ANOVA_Tests/11.02\%3A_Chi-Square_Goodness_of_Fit}{this
free, open-source textbook}

\hypertarget{inference-for-regression}{%
\chapter{Inference for Regression}\label{inference-for-regression}}

\hypertarget{return-to-regression}{%
\section{Return to Regression}\label{return-to-regression}}

In the lessons on regression, there was a recurrent theme: if the
correlation was 0, then the slope was 0 (and \emph{vice-versa}, since
\(b = rs_y/s_x\)). However, in real data the correlation is never
exactly 0. How do we know if it's ``close enough'' to 0 to say that
there's no correlation between \(x\) and \(y\)? By comparing it to a
\textbf{standard error}, of course!

After the previous lesson (the Chi-Square test), this lesson is a return
to form. We're going back to t-tests! Hooray! But first, let's do a
quick recap on regression.

\hypertarget{regression-recap}{%
\section{Regression Recap}\label{regression-recap}}

In regression, we're trying to find parameters \(a\) and \(b\) in the
equation \(y = a + bx\) to make sure that the fitted line is as
``close'' to the observed data as possible.

To find the line of best fit, we minimize the sum of squared errors,
\(\sum(y_i - \hat y_i)^2\), where \(\hat y_i\) is the height of the line
that we get if we plug the \(x\) value into the model. The fact that we
minimize the squares is not important, but it is important that it's
based on the quantity \(y_i - \hat y_i\), called the \emph{residuals}.

For example, consider the penguins data that we looked at earlier. In
these data, we're trying to predict the body mass of a penguin based on
their flipper length. This is useful to field researchers, since
measuring flipper length is much easier than weighing a penguin and
still gives them some idea of how much that penguin might weigh.

\includegraphics{L22-Inference_for_Regression_files/figure-pdf/unnamed-chunk-2-1.pdf}

The blue line is the line of best fit, which was estimated as: \[
body\_mass_i = -6787.28 + 54.62*flipper\_length_i
\]

The slope is 54.62, meaning that the weight of the penguin increases, on
average, by 54.62 grams for each 1mm increase in the flipper length. In
other words, if we look at all pairs of penguins that had flipper
lengths that were 1mm apart, the average difference in their body masses
would be something like 54.62.\footnote{This isn't exactly how it works,
  but it's a useful analogy.}

The slope was calculated using our formulas from before. The correlation
between flipper length and body mass is 0.7027, the standard deviation
of flipper length is 6.4850, and the sd of body mass is 504.1162.
Putting these together, the slope is
\(0.7072 * 504.1162 / 6.4850 = 54.9747\). This is slightly off because
of rounding - I calculated this one by hand, but the slope in the
equation above was calculated with R.

The intercept of this model is -6787.28, which could be interpreted as
saying that a penguin with a flipper length of 0 should have a body mass
of about -7kg, but this isn't how we should interpret this
value.\footnote{Evaluating the height of the line at an x-value that is
  outside the range of our observations is called
  \textbf{extrapolation}, and should generally be avoided.} This
intercept simply exists to shift the line up or down in order to best
fit the cloud of points.

This interpretation of the intercept as a ``nuisance''
parameter\footnote{A nuisance parameter is something we must calculate
  in order for the model to work but something we're not planning on
  interpreting.} can be seen in the way we calculate it. The calculation
is \(a = \bar y - b\bar x\), i.e., the intercept is calculated to ensure
we have a line with slope \(b\) that goes through the point
\((\bar x, \bar y)\) on the plot.

The red line represents the residual for one of the penguins. This
particular penguin had a flipper length of 207, leading to a predicted
body mass of \(-6787.28 + 54.62*207 = 4519.06\). This particular penguin
had an actual body mass of 5050, giving a residual of
\(5050 - 4519.06 = 530.94\).

\hypertarget{inference-for-the-slope-parameter}{%
\section{Inference for the Slope
Parameter}\label{inference-for-the-slope-parameter}}

You may have noticed a word show up several times in that recap:
``average''. The intercept passes through the average of x and the
average of y, and the slope is the average increase in \(y\) for a
one-unit increase in \(x\). Linear regression is essentially just a 2
dimensional average!

As you might guess from this fact, we're going back to t-tests! We still
have the exact same test statistic: \[
t_{obs} = \frac{\text{Observed} - \text{Hypothesized}}{\text{Standard Error}}
\] We just have to decide on the hypotheses and calculate the standard
error!

As noted above,\footnote{And many times in previous lectures.}, the
slope is 0 when the correlation is 0. In general, we are checking the
hypotheses: \begin{align*}
H_0: \beta = 0\text{ vs. }H_a: \beta\ne 0\\
\end{align*} We are now equipped to fill out the test statistic: \[
t_{obs} = \frac{b - 0}{\text{Standard Error}}
\] We can just plug that into a calculator and get a result, right?
Wait, something might be missing.

In this class, we won't even write out the equation of the standard
error. This is the sort of thing software was designed to do for you. By
now, you should be able to explain the concept of the standard error to
a grandparent; it's a central part of everything we've done since the
midterm. You should also know why it decreases with a larger sample
size, \emph{and how this affects the test statistic and p-value}!
However, it's fine to skip over the actual value for now and simply
trust that statisticians are smart.

With the Standard Error being calculated by software, this hypothesis
test works exactly the same as the test for a mean.

\hypertarget{assumptions-1}{%
\subsection{Assumptions}\label{assumptions-1}}

As always, statistics is built on making some assumptions about the
population that allow us to make inferences from a sample. The
assumptions should be pretty obvious.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Linear Regression Assumptions}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  There is some true relationship \(y = \alpha + \beta x\)

  \begin{itemize}
  \tightlist
  \item
    That is, the model is actually a straight line relationship with no
    curves.
  \end{itemize}
\item
  The deviations above and below this line are \emph{normally
  distributed}.

  \begin{itemize}
  \tightlist
  \item
    That is, the height of the line at a given \(x\) value is normal,
    with the mean being the height of the line.
  \item
    Put another way: The residuals are normal.
  \end{itemize}
\item
  The individuals are independent of each other.
\item
  The variance above and below the line doesn't depend on the \(x\)
  value.
\end{enumerate}

\end{tcolorbox}

\hypertarget{violating-assumption-1}{%
\subsubsection{Violating Assumption 1}\label{violating-assumption-1}}

There is one way for a line to be straight, and an infinite number of
curved lines. Basically, the plot of \(y\) against \(x\) should look
linear.

\includegraphics{L22-Inference_for_Regression_files/figure-pdf/unnamed-chunk-3-1.pdf}

In the plot above, there is clearly not a linear relationship. The math
works out just fine and we can calculate a straight line that minimizes
the sum of squared error, but it doesn't tell us anything about the
population.

\hypertarget{violating-assumptions-2---4}{%
\subsubsection{Violating Assumptions 2 -
4}\label{violating-assumptions-2---4}}

Again, there are many ways to violate these assumption. A good example
might be the stock price of Apple Computers (or any stock).

\begin{itemize}
\tightlist
\item
  The price on one day is going to be close to the price the day before.

  \begin{itemize}
  \tightlist
  \item
    Not independent!
  \end{itemize}
\item
  When Apple holds a press conference, there will be a lot more
  variability in the stock price depending on what they announce.

  \begin{itemize}
  \tightlist
  \item
    The variance depends on the \(x\) value!
  \item
    This also violates the assumption of normality. Large stock price
    changes are to be expected, but the normal distribution doesn't
    allow for this!
  \end{itemize}
\end{itemize}

\hypertarget{regression-in-r}{%
\section{Regression in R}\label{regression-in-r}}

Calculating things by hand helps you conceptualize what's going on, but
it's impractical for actual practice. As a ``Statistical Programming
Language'', R has so many useful functions built in.

For this example, we'll use the \texttt{mtcars} data that is built into
R, so we don't have to worry about loading in new data. These data
include various measurements of a sample of cars in the 1970s. For our
purposes, we're going to determine the relationship between fuel
efficiency (\(y\)) as measured in miles per gallon (mpg), and weight
(\(x\)) measured in units of 1,000 lbs.

We'll start by checking a plot. I sometimes use ``base R'' plotting, and
sometimes use ``\texttt{ggplot}''. Neither will be tested on the final
exam, but I like pointing out the distinction. Base R plotting has
notation that matches the syntax of linear modelling, so it's useful to
include here.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(mtcars) }\CommentTok{\# built{-}in data in R}

\CommentTok{\# Base R plot: y \textasciitilde{} x, data = ...}
\FunctionTok{plot}\NormalTok{(mpg }\SpecialCharTok{\textasciitilde{}}\NormalTok{ wt, }\AttributeTok{data =}\NormalTok{ mtcars)}

\CommentTok{\# Linear Model (lm): y \textasciitilde{} x, data = ...}
\NormalTok{mylm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(mpg }\SpecialCharTok{\textasciitilde{}}\NormalTok{ wt, }\AttributeTok{data =}\NormalTok{ mtcars)}

\CommentTok{\# Add the line to the existing plot}
\FunctionTok{abline}\NormalTok{(mylm)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L22-Inference_for_Regression_files/figure-pdf/unnamed-chunk-4-1.pdf}

}

\end{figure}

As always: check assumptions first!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The plot above looks pretty linear.

  \begin{itemize}
  \tightlist
  \item
    There might be a slight curve to the line, though. The points at the
    left and right are mostly above the line, but the points in the
    middle are mostly below the line. This doesn't appear to be a strong
    pattern, but it's something to note when making a conclusion.

    \begin{itemize}
    \tightlist
    \item
      Extrapolation is definitely not possible, but a linear model might
      explain the data in this range.
    \end{itemize}
  \end{itemize}
\item
  There aren't any obvious outliers, but we'll need to look at a
  different plot to really check this assumption.
\item
  From the sampling strategy, I feel comfortable saying that the
  observations are independent.

  \begin{itemize}
  \tightlist
  \item
    There's no possible test for this, it's all about having a good
    sampling strategy!
  \end{itemize}
\item
  This is probably fine, but again we should check other plots before we
  make a conclusion.
\end{enumerate}

There are two assumptions that we were not able to test by looking at a
plot of mpg against weight. R has some built-in plotting methods that
help us with these assumptions.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a plotting space with 2 rows and 2 columns}
\CommentTok{\# "mfrow" = Multiple Figures, filled in ROW{-}wise}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\CommentTok{\# The basic plot function for the output of lm}
\CommentTok{\# makes 4 different plots.}
\FunctionTok{plot}\NormalTok{(mylm)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L22-Inference_for_Regression_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\end{figure}

Some notes on these plots:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Residuals versus Fitted}: This is usually better to look at
  than the \(y\) versus \(x\). When you get into more than one \(x\)
  variable, it can be difficult to look at all of the plots, and this
  tells us more information anyway.

  \begin{itemize}
  \tightlist
  \item
    For this example, we can see the pattern again: points above the
    line on the left and right, and below the line in the middle. The
    red line helps highlight this.
  \end{itemize}
\item
  \textbf{Normal Q-Q}: This plot checks whether the residuals are
  normal. We'll skip the details of how this plot is made, but it's
  useful to have an intuition about these plots. Essentially, if the
  residuals are normal then everything should fall exactly on the dotted
  line. Due to random sampling it won't, so we're mainly looking for
  systematic deviations from the line. I've added some code at the end
  of this lesson for you to check this.

  \begin{itemize}
  \tightlist
  \item
    These data look okay, but not perfect. The residuals are possibly
    heavy tailed.\footnote{You're not expected to be able to guess this
      on the exam.}
  \end{itemize}
\item
  \textbf{Scale-Location}: This is essentially the absolute value of the
  residuals, which shows whether the variance is the same for all values
  of \(x\). We want this to look like there is no pattern.

  \begin{itemize}
  \tightlist
  \item
    The red line wiggles a bit, but this is to be expected. It looks
    pretty good to me!
  \end{itemize}
\item
  \textbf{Residuals versus Leverage}: This plot is awkward to read, but
  shows us if any of the points are affecting the line by a lot.
  Essentially, we're looking for any points on the wrong side of the
  dotted lines (``Cook's Distance''). Above the 0.5 dotted line is
  something to look into, and something above 1 is bad for the model.
  Again, I've added an appendix about ``leverage''.\footnote{This
    concept will be on the exam, but not the calculations.}

  \begin{itemize}
  \tightlist
  \item
    Nothing outside of that 0.5 dotted line, so this should be good!
  \end{itemize}
\end{enumerate}

Now that we've looked at the plots to check our assumptions\footnote{Notice
  how we have to fit the model before we can check the assumptions. The
  p-values are already calculated, but you should be very careful not to
  think about them before you've checked the assumptions!}, we can look
at our estimates and our p-values.

The output of the \texttt{lm()} function isn't very user-friendly, but
the \texttt{summary()} function makes it nicer.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(mylm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = mpg ~ wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***
wt           -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10
\end{verbatim}

Let's walk through this output!

\begin{itemize}
\tightlist
\item
  The \texttt{Call:} is the R code we used to make this model.
\item
  The \texttt{Residuals} show the five number summary for the residuals.
  If they're normal with a mean of 0 as we assume, then they should have
  a minimum that is the negative of the maximum, a Q1 that is the
  negative of the Q3, and a median of 0.

  \begin{itemize}
  \tightlist
  \item
    This is a quick check to see whether the residuals are symmetric.
  \item
    For this example, these results aren't ideal but we also have a
    small data set so we can be a little forgiving.
  \end{itemize}
\item
  The \texttt{Coefficients} table is where the magic happens.

  \begin{itemize}
  \tightlist
  \item
    \texttt{(Intercept)} is our estimate of \(a\). Again, this is a
    nuisance parameter that we're not super interested in right now.
  \item
    \texttt{wt} corresponds to our estimate of \(b\). The slope is
    estimated as \(b=-5.3445\), and it provides the standard error and
    the t test statistic for us!

    \begin{itemize}
    \tightlist
    \item
      The p-value is \texttt{(Estimate\ -\ 0)/Std.\ Error}, where the
      ``\texttt{-\ 0}'' comes from the null hypothesis that
      \(\beta = 0\).
    \item
      The three stars at the end of the line show significance level.
      \texttt{***} means significant at the 0.1\% level, \texttt{**} is
      significant at the 1\% level, \texttt{*} is 5\%, and \texttt{.} is
      10\%. You should always set your significance level \emph{before}
      looking at this table, but it gives a nice quick visual check for
      significance.\footnote{Bad statisticians who violate the issues in
        the ``Inference Cautions'' lecture are accused of ``chasing
        stars''.}
    \end{itemize}
  \end{itemize}
\item
  The last block of text shows some important quantities.

  \begin{itemize}
  \tightlist
  \item
    The ``Multiple R-squared'' value is what we learned previously,
    whereas the ``Adjusted R-squared'' is something you will need to
    learn about when moving into multiple linear regression. For
    practice, try to figure out which (if any) is equal to the square of
    the correlation between \texttt{mpg} and \texttt{wt}!
  \item
    The \texttt{F-statistic} row is also going to be very important when
    you move into multiple linear regression.
  \end{itemize}
\end{itemize}

Looking at this output, we can see that the slope parameter associated
with \texttt{wt}, the weight of the car, is significantly different from
0. This means that there is statistically significant correlation
between the fuel efficiency of a car and it's weight. This isn't
surprising, but it's always nice to have a scientific confirmation of
what we hypothesized to be true.

\hypertarget{confidence-intervals-3}{%
\section{Confidence Intervals}\label{confidence-intervals-3}}

Since we know it's a t-test, we're still looking at confidence intervals
of the form: \[
\text{point estimate}\pm\text{critical value}*\text{standard error} 
\] where we use the SE given in the table. \emph{However}, we have
changed the degrees of freedom! Recall that the df can be seen as the
number of parameters we can estimate from the data\footnote{With one
  data point, we can estimate the mean but not sd. With two, we can
  calculate the mean which we need for the sd. And so on.}, and we need
to estimate the intercept. For this reason, we've lost another degree of
freedom, so the \(t\) critical value is based on \(n-2\) degrees of
freedom.

A 95\% CI for the slope in the \texttt{mtcars} example can be calculated
as follows. We know:

\begin{itemize}
\tightlist
\item
  The point estimate is -5.3445.
\item
  We're finding a 95\% CI, so we use \texttt{qt((1\ -\ 0.95)/2)}.
\item
  The SE is given from the R output as 0.5591

  \begin{itemize}
  \tightlist
  \item
    We just use this value - we don't have to divide by \(\sqrt{n}\) or
    anything like that!
  \end{itemize}
\end{itemize}

The following R code uses \texttt{+\ c(1,\ -1)} to add and subtract
(\(\pm\)).

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FloatTok{5.3445} \SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{qt}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.95}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\DecValTok{32} \SpecialCharTok{{-}} \DecValTok{2}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.5591}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -6.486335 -4.202665
\end{verbatim}

So a 95\% CI for the slope is (-6.49, -4.20). This has the
usual\footnote{Highly specific, and wrong if you miss any part of it.}
interpretation that, if we repeated this study many many times, then
95\% of the intervals that we construct this way would contain the true
population slope.

Unlike the tests for proportions, this CI is back to having the
interpretation of ``contains every hypothesized value that would
\emph{not} be rejected by a two-sided hypothesis test''. We already did
a test for \(H_0:\beta = 0\) versus \(H_a:\beta \ne 0\) in which the
null was rejected, and indeed 0 is \emph{not} in this interval.

\hypertarget{conclusion-2}{%
\section{Conclusion}\label{conclusion-2}}

So that's it! It's a t-test based on a standard error that we're not
going to calculate by hand. Other than the interpretation of the slope
and one less degree of freedom, this is basically inference for a single
mean!

You will still need to keep all of the assumptions of regression in
mind. We need a linear relationship, independence, normality of the
residuals, and constant variance across values of \(x\) for this test to
be valid. We must check these assumptions by looking at some plots and
critiquing the data collection.

For the exam, you'll be expected to know:

\begin{itemize}
\tightlist
\item
  The assumptions, and how to check them.

  \begin{itemize}
  \tightlist
  \item
    Including interpreting QQ plots to say whether they're good or bad,
    and interpreting whether a point looks like it might be high
    leverage. (In other words, the Appendices in this chapter are
    \emph{not} just optional bonus topics.)
  \end{itemize}
\item
  The interpretation of the hypothesis test and the CI

  \begin{itemize}
  \tightlist
  \item
    Stated in the context of the problem.
  \end{itemize}
\end{itemize}

A nice exam question might show you the results of \texttt{plot(mylm)}
and \texttt{summary(mylm)} and ask you to make a conclusion in the
context of the study.\footnote{Possibly with one of the assumptions
  violated, which you'll have to catch on your own!}

\hypertarget{appendix---leverage}{%
\section{Appendix - Leverage}\label{appendix---leverage}}

The word ``leverage'' comes from the word ``lever'', which is
intentional. If you think of the line of best fit as a see-saw, a high
leverage point is a point that either pushes the see-saw down or pulls
it up.

An outlier is a point that doesn't really fit into the pattern. There
isn't a single way to define what an ``outlier'' is in 2
dimensions\footnote{There's no way to do Q1 - 1.5IQR in both \(x\) and
  \(y\).}, so we have to be smart about it. Usually, we refer to an
outlier as a point that's far from the mean of x and y.

Not all outliers are high leverage, though! The following plots
demonstrate this idea. Both plots show the same data, but with an extra
outlier. The first plot has an outlier at an x value of \(\bar x - 6\)
and a y value at \(\bar y + 15\). The second plot has an outlier with
the same \(x\) value, but the \(y\) value is \(\bar y - 15\).

These two potential outliers are the exact same distance from the mean
of \(x\) and the mean of \(y\), but have very different effects on the
line! Including the red point changes the line a little, while the green
point changes the line a lot! Even though they're the same distance from
the mean, the green point has higher leverage.

The definition of leverage is much more well-defined than the definition
of an outlier. The \textbf{leverage} of a point is a measure of how much
the line of best fit would change if that point were not in the
data.\footnote{There is an exact calculation, but we're just concerned
  with the concept for now.} It is possible to have outliers with low
leverage. Outliers are points that are far from your data; leverage
provides a measure of how well a point fits into the pattern.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm0 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}

\NormalTok{x1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(x, }\FunctionTok{mean}\NormalTok{(x) }\SpecialCharTok{{-}} \DecValTok{6}\NormalTok{)}
\NormalTok{y1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(y, }\FunctionTok{mean}\NormalTok{(y) }\SpecialCharTok{+} \DecValTok{15}\NormalTok{)}
\NormalTok{lm1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y1 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1)}

\NormalTok{x2 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(x, }\FunctionTok{mean}\NormalTok{(x) }\SpecialCharTok{{-}} \DecValTok{6}\NormalTok{)}
\NormalTok{y2 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(y, }\FunctionTok{mean}\NormalTok{(y) }\SpecialCharTok{{-}} \DecValTok{15}\NormalTok{)}
\NormalTok{lm2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x2)}

\NormalTok{n1s }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, n)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(x1, y1, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(n1s, }\DecValTok{2}\NormalTok{), }
    \AttributeTok{pch =} \DecValTok{16}\NormalTok{, }\AttributeTok{cex =} \FunctionTok{c}\NormalTok{(n1s, }\DecValTok{2}\NormalTok{))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \FunctionTok{mean}\NormalTok{(y), }\AttributeTok{col =} \StringTok{"grey"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \FunctionTok{mean}\NormalTok{(x), }\AttributeTok{col =} \StringTok{"grey"}\NormalTok{)}
\FunctionTok{axis}\NormalTok{(}\DecValTok{2}\NormalTok{, }\AttributeTok{at =} \FunctionTok{mean}\NormalTok{(y), }\AttributeTok{labels =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{bar}\NormalTok{(y)), }\AttributeTok{las =} \DecValTok{1}\NormalTok{)}
\FunctionTok{axis}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{at =} \FunctionTok{mean}\NormalTok{(x), }\AttributeTok{labels =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{bar}\NormalTok{(x)), }\AttributeTok{las =} \DecValTok{1}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(lm0)}
\FunctionTok{abline}\NormalTok{(lm1, }\AttributeTok{col =} \DecValTok{2}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"Without Outlier"}\NormalTok{, }\StringTok{"With Outlier"}\NormalTok{), }\AttributeTok{col =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{lty =} \DecValTok{1}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(x2, y2, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(n1s, }\DecValTok{3}\NormalTok{), }
    \AttributeTok{pch =} \DecValTok{16}\NormalTok{, }\AttributeTok{cex =} \FunctionTok{c}\NormalTok{(n1s, }\DecValTok{2}\NormalTok{))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \FunctionTok{mean}\NormalTok{(y), }\AttributeTok{col =} \StringTok{"grey"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \FunctionTok{mean}\NormalTok{(x), }\AttributeTok{col =} \StringTok{"grey"}\NormalTok{)}
\FunctionTok{axis}\NormalTok{(}\DecValTok{2}\NormalTok{, }\AttributeTok{at =} \FunctionTok{mean}\NormalTok{(y), }\AttributeTok{labels =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{bar}\NormalTok{(y)), }\AttributeTok{las =} \DecValTok{1}\NormalTok{)}
\FunctionTok{axis}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{at =} \FunctionTok{mean}\NormalTok{(x), }\AttributeTok{labels =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{bar}\NormalTok{(x)), }\AttributeTok{las =} \DecValTok{1}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(lm0)}
\FunctionTok{abline}\NormalTok{(lm2, }\AttributeTok{col =} \DecValTok{3}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"Without Outlier"}\NormalTok{, }\StringTok{"With Outlier"}\NormalTok{), }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{), }\AttributeTok{lty =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L22-Inference_for_Regression_files/figure-pdf/unnamed-chunk-9-1.pdf}

}

\end{figure}

\hypertarget{appendix---interpreting-qq-norm}{%
\section{Appendix - Interpreting QQ
norm}\label{appendix---interpreting-qq-norm}}

Copy the following code and past it into RStudio. Run it over and over
again to get a feel for QQ plots. Change \texttt{n} as indicated.

Some things you might notice:

\begin{itemize}
\tightlist
\item
  Truly normal data is never perfectly on the line!

  \begin{itemize}
  \tightlist
  \item
    When interpreting QQ, it's okay to allow for a little bit of
    variance!
  \item
    Most methods are fairly \textbf{robust} to deviations from
    normality.
  \end{itemize}
\item
  Heavy tailed data (e.g., more variance than expected by the normal
  distribution) result in one kind of shape, right tailed data result in
  a different shape.

  \begin{itemize}
  \tightlist
  \item
    What do you expect left tailed data to look like?
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Change this to 20, 100, 500, and 10000 to see how much changes}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{500}

\NormalTok{normal\_sample1 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}
\NormalTok{normal\_sample2 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}
\NormalTok{t\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rt}\NormalTok{(n, }\AttributeTok{df =} \DecValTok{5}\NormalTok{) }\CommentTok{\# Low df to highlight difference from normal}
\NormalTok{chisq\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rchisq}\NormalTok{(n, }\AttributeTok{df =} \DecValTok{5}\NormalTok{)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{qqnorm}\NormalTok{(normal\_sample1, }\AttributeTok{main =} \StringTok{"Normal Data 1"}\NormalTok{)}
\FunctionTok{qqline}\NormalTok{(normal\_sample1)}
\FunctionTok{qqnorm}\NormalTok{(normal\_sample2, }\AttributeTok{main =} \StringTok{"Normal Data 2"}\NormalTok{)}
\FunctionTok{qqline}\NormalTok{(normal\_sample2)}
\FunctionTok{qqnorm}\NormalTok{(t\_sample, }\AttributeTok{main =} \StringTok{"t Data {-} Heavy Tailed"}\NormalTok{)}
\FunctionTok{qqline}\NormalTok{(t\_sample)}
\FunctionTok{qqnorm}\NormalTok{(chisq\_sample, }\AttributeTok{main =} \StringTok{"Chi Square {-} Right{-}Tailed"}\NormalTok{)}
\FunctionTok{qqline}\NormalTok{(chisq\_sample)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L22-Inference_for_Regression_files/figure-pdf/unnamed-chunk-10-1.pdf}

}

\end{figure}

\hypertarget{comparing-means-with-anova}{%
\chapter{Comparing means with ANOVA}\label{comparing-means-with-anova}}

This is a derivative work of Section 5.5 in Introductory Statistics for
the Life and Biomedical Sciences, First Edition by Julie Vu and David
Harrington. The initial git commit represents a copy-and-paste of the
textbook into Quarto format, and subsequent edits represent my
modfications.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

In some settings, it is useful to compare means across several groups.
It might be tempting to do pairwise comparisons between groups; for
example, if there are three groups (\(A, B, C\)), why not conduct three
separate \(t\)-tests (\(A\) vs.~\(B\), \(A\) vs.~\(C\), and \(B\)
vs.~\(C\))? As we saw in the lecture on Cautions for Inference, we
inflate the Type 1 error when we do many hypothesis tests. Even at a 5\%
level, at three hypothesis tests there is about a
\(1 - (1 - 0.05)^3 = 14.2625%
\) chance\footnote{This is 1 minus the probability of no significant
  results in three tests. The probability of a result that is \emph{not}
  significant is \(1-0.05\), so we do this three times and then do 1
  minus the result. This is similar to the probability of \emph{not}
  getting a 6 in 3 dice rolls.} that one of them is significant
\emph{assuming that the null hypothesis is true}!

Instead, the methodology behind a \(t\)-test can be generalized to a
procedure called \textbf{ANalysis Of VAriance (ANOVA)}, which uses a
single hypothesis test to assess whether all means across several groups
are equal. Strong evidence favouring the alternative hypothesis in ANOVA
is described by unusually large differences among the group means.

\begin{itemize}
\tightlist
\item
  \(H_0\): The mean outcome is the same across all \(k\) groups. In
  statistical notation, \(\mu_1 = \mu_2 = \cdots = \mu_k\) where
  \(\mu_i\) represents the mean of the outcome for observations in
  category \(i\).
\item
  \(H_A\): At least one mean is different.
\end{itemize}

There are three assumptions that must be checked before performing
ANOVA:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Observations are independent within and across groups.

  \begin{itemize}
  \tightlist
  \item
    All individuals in the study are independent of all other
    individuals.
  \end{itemize}
\item
  The data within each group are ``nearly'' normal.
\item
  the variability across the groups is about equal.
\end{enumerate}

\hypertarget{example-5.19}{%
\subsection{Example 5.19}\label{example-5.19}}

Examine Figure 5.22. Compare groups I, II, and III. Is it possible to
visually determine if the differences in the group centers is due to
chance or not? Now compare groups IV, V, and VI. Do the differences in
these group centers appear to be due to chance?\\
It is difficult to discern a difference in the centers of groups I, II,
and III, because the data within each group are quite variable relative
to any differences in the average outcome. However, there appear to be
differences in the centers of groups IV, V, and VI. For instance, group
V appears to have a higher mean than that of the other two groups. The
differences in centers for groups IV, V, and VI are noticeable because
those differences are large relative to the variability in the
individual observations within each group.

\begin{figure}

{\centering \includegraphics{L23-ANOVA-oi_files/figure-pdf/unnamed-chunk-1-1.pdf}

}

\caption{Figure 5.22: Side-by-side dotplots for the outcomes in six
groups.}

\end{figure}

\hypertarget{analysis-of-variance-anova-and-the-f-test}{%
\section{\texorpdfstring{Analysis of variance (ANOVA) and the
\(F\)-test}{Analysis of variance (ANOVA) and the F-test}}\label{analysis-of-variance-anova-and-the-f-test}}

The \texttt{famuss} dataset was introduced in Chapter 1, Section 1.2.2.
In the FAMuSS study, researchers examined the relationship between
muscle strength and genotype at a location on the ACTN3 gene. The
measure for muscle strength is percent change in strength in the
non-dominant arm (\var{ndrm.ch}). Is there a difference in muscle
strength across the three genotype categories (\texttt{CC}, \texttt{CT},
\texttt{TT})?

\hypertarget{hypotheses}{%
\subsection{Hypotheses}\label{hypotheses}}

The null hypothesis under consideration is the following:
\(\mu_{\texttt{CC}} = \mu_{\texttt{CT}} = \mu_{\texttt{TT}}\). Write the
null and corresponding alternative hypotheses in plain language.

\textbf{Solution}

\(H_0\): The average percent change in non-dominant arm strength is
equal across the three genotypes. \(H_A\): The average percent change in
non-dominant arm strength varies across some (or all) groups.{]}

\hypertarget{assumption-checking}{%
\subsection{Assumption Checking}\label{assumption-checking}}

The table below provides summary statistics for each group. A
side-by-side boxplot for the change in non-dominant arm strength is
shown in Figure 5.24; Figure 5.25 shows the Q-Q plots by each
genotype.\footnote{The previous lesson has some code to help you
  interpret Q-Q plots.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  It is reasonable to assume that the observations are independent
  within and across groups; it is unlikely that participants in the
  study were related, or that data collection was carried out in a way
  that one participant's change in arm strength could influence
  another's.
\item
  Based on the Q-Q plots, there is evidence of moderate right skew; the
  data do not follow a normal distribution very closely, but could be
  considered to `loosely' follow a normal distribution.\footnote{In a
    more advanced course, it can be shown that the ANOVA procedure still
    holds with deviations from normality when sample sizes are
    moderately large. Additionally, a more advanced course would discuss
    appropriate transformations to induce normality.}
\item
  Notice from the table that the variability appears to be approximately
  constant across groups; nearly constant variance across groups is an
  important assumption that must be satisfied for using ANOVA.
\end{enumerate}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
& \texttt{CC} & \texttt{CT} & \texttt{TT} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sample size (\(n_i\)) & 173 & 261 & 161 \\
Sample mean (\(\bar{x}_i\)) & 48.89 & 53.25 & 58.08 \\
Sample SD (\(s_i\)) & 29.96 & 33.23 & 35.69 \\
\end{longtable}

\begin{figure}

{\centering \includegraphics{L23-ANOVA-oi_files/figure-pdf/unnamed-chunk-2-1.pdf}

}

\caption{Figure 2.24: Side-by-side box plot of the change in
non-dominant arm strength for 595 participants across three groups.}

\end{figure}

\begin{figure}

{\centering \includegraphics{L23-ANOVA-oi_files/figure-pdf/unnamed-chunk-3-1.pdf}

}

\caption{Figure 5.25: Q-Q plots of the change in non-dominant arm
strength for 595 participants across three groups.}

\end{figure}

\hypertarget{difference-in-means}{%
\subsection{Difference in Means}\label{difference-in-means}}

The largest difference between the sample means is between the
\texttt{CC} and \texttt{TT} groups. Consider again the original
hypotheses:

\begin{itemize}
\tightlist
\item
  \(H_0\): \(\mu_{\texttt{CC}} = \mu_{\texttt{CT}} = \mu_{\texttt{TT}}\)
\item
  \(H_A\): The average percent change in non-dominant arm strength
  (\(\mu_i\)) varies across some (or all) groups.
\end{itemize}

Why might it be inappropriate to run the test by simply estimating
whether the difference of \(\mu_{\texttt{CC}}\) and
\(\mu_{\texttt{TT}}\) is statistically significant at a 0.05
significance level?

\textbf{Solution}

It is inappropriate to informally examine the data and decide which
groups to formally test. This is a form of **data fishing*; choosing the
groups with the largest differences for the formal test will lead to an
increased chance of incorrectly rejecting the null hypothesis (i.e., an
inflation in the Type\textasciitilde I error rate). Instead, all the
groups should be tested using a single hypothesis test.

\hypertarget{mean-squared-error---within-and-between}{%
\subsection{Mean Squared Error - Within and
Between}\label{mean-squared-error---within-and-between}}

Analysis of variance focuses on answering one question: is the
variability in the sample means large enough that it seems unlikely to
be from chance alone? The variation between groups is referred to as the
\textbf{mean square between groups (\(MSG\))}; the \(MSG\) is a measure
of how much each group mean varies from the overall mean. Let:

\begin{itemize}
\tightlist
\item
  \(\overline{x}\) represent the mean of outcomes across all groups

  \begin{itemize}
  \tightlist
  \item
    In other words, it's the mean of the data when it's \emph{not} split
    into groups.
  \end{itemize}
\item
  \(\overline{x}_i\) is the mean of outcomes in a particular group \(i\)
\item
  \(n_i\) is the sample size of group \(i\).
\end{itemize}

The mean square between groups is: \[
MSG = \frac{1}{k-1}\sum_{i=1}^{k} n_{i}\left(\overline{x}_{i} - \overline{x}\right)^{2} = \frac{1}{df_{G}}SSG,
\] where \(SSG\) is the sum of squares between groups,
\(\sum_{i=1}^{k} n_{i}\left(\overline{x}_{i} - \overline{x}\right)^{2}\),
and \(df_{G}=k-1\) is the degrees of freedom associated with the \(MSG\)
when there are \(k\) groups.

Notice what's happening here: \(MSG\) is kind of like a variance, but
not the variance of individual values.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{MSG is the variance \emph{of the means}}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

Instead of individual data, we're looking at the mean of each group.
With 3 groups, we have 3 different means. The \(MSG\) is like
calculating the variance based on these 3 values (disregarding the
variation within each group).

\end{tcolorbox}

Under the null hypothesis, there is no real difference between the
groups. In other words, the null hypothesis assumes that the groupings
are non-informative, such that all observations can be thought of as
belonging to a single group. If the null is true, then it the
variability between the group means should be equal to the variability
observed within a single group. \textbf{The mean square error (\(MSE\))}
is a pooled variance estimate with associated degrees of freedom
\(df_E=n-k\) that provides a measure of variability within the groups.
The mean square error is computed as: \[
MSE = \frac{1}{n-k}\sum_{i=1}^{k} (n_i-1)s_i^{2} = \frac{1}{df_{E}}SSE,
\] where the \(SSE\) is the \textbf{sum of squared errors}, \(n_i\) is
the sample size of group \(i\), and \(s_i\) is the standard deviation of
group \(i\).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{The MSE is the variance \emph{as if there are no groups}}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

The MSE is almost the same as the variance of the data, assuming we
lumped everything together and forgot about the groupings. The only
difference is the degrees of freedom!

\end{tcolorbox}

Under the null hypothesis that all the group means are equal, any
differences among the sample means are only due to chance; thus, the
\(MSG\) and \(MSE\) should also be equal. ANOVA is based on comparing
the \(MSG\) and \(MSE\). The test statistic for ANOVA, the
\textbf{F-statistic}, is the ratio of the between-group variability to
the within-group variability: \[
F = \frac{MSG}{MSE}
\]

This is a new distribution that we're not going to talk about too much.
The main thing to note is that i's similar to the Chi-Square
distribution: The test statistic is based on adding squared things, so
we're only interested in a \emph{right-tailed} test.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{The \(F\)-Statistic}, arc=.35mm, colframe=quarto-callout-warning-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

The F-statistic can be seen as the ratio of the variance \emph{between}
groups and the variance \emph{within} groups. A large \(F\)-stat means
that there's a lot of variance between groups compared to the variance
of the data.

Put another way, the data tells us how much variance to expect so that
we have context for the variance of the group means.

\end{tcolorbox}

\hypertarget{calculating-the-f-statistic}{%
\subsection{\texorpdfstring{Calculating the
\(F\)-statistic}{Calculating the F-statistic}}\label{calculating-the-f-statistic}}

Calculate the \(F\)-statistic for the \texttt{famuss} data summarized in
Figure 5.23. The overall mean \(\overline{x}\) across all observations
is 53.29.

\textbf{Solution}: By hand

First, calculate the \(MSG\) and \(MSE\). \vspace{0mm} \begin{align*}
MSG =& \frac{1}{k-1}\sum_{i=1}^{k} n_{i}\left(\bar{x}_{i} - \bar{x}\right)^{2} \\
=& \frac{1}{3-1} [(173)(48.89 - 53.29)^{2} \\&+ (261)(53.25 - 53.29)^{2} + (161)(58.08 - 53.29)^{2} ]\\
=& 3521.69
\end{align*}

Notice how the MSG is essentially the variance of three observations.

\begin{align*}
MSE =& \frac{1}{n-k}\sum_{i=1}^{k} (n_i-1)s_i^{2} \\
=& \frac{1}{595-3}[(173-1)(29.96^2) + (261-1)(33.23^2) \\&+ (161-1)(35.69^2)] \\
=& 1090.02
\end{align*}

The MSE is almost the same as the variance of all observations if we
were to ignore which group they were in!

The \(F\)-statistic is the ratio: \[
dfrac{MSG}{MSE} = dfrac{3521.69}{1090.02} = 3.23
\]

\textbf{Solution}: R

The following R code will save us many calculations.

As in the linear regression section, I use the \texttt{summary()}
function to get nicer output.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(oibiostat)}
\FunctionTok{data}\NormalTok{(famuss)}

\CommentTok{\# The data have uninformative names.}
\CommentTok{\# ndrm.ch is percentage change in non{-}dominant arm strength}
\CommentTok{\# actn3.r577x is the grouping variable (genotype)}
\FunctionTok{summary}\NormalTok{(}\FunctionTok{aov}\NormalTok{(ndrm.ch }\SpecialCharTok{\textasciitilde{}}\NormalTok{ actn3.r577x, }\AttributeTok{data =}\NormalTok{ famuss))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
             Df Sum Sq Mean Sq F value Pr(>F)  
actn3.r577x   2   7043    3522   3.231 0.0402 *
Residuals   592 645293    1090                 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

Notice how the R output givus us - \(df_G = 592\), \(MSG = 3522\)
(rounded from 3521.69) - \(df_E = 2\), \(MSE = 1090\) (rounded from
1090.02) - \(MSG / MSE = 3.231\)

I will not expect you to do the calculations by hand on any test or
assignment.

\hypertarget{p-values}{%
\subsection{p-values}\label{p-values}}

A \(p\)-value can be computed from the \(F\)-statistic using an
\(F\)-distribution, which has two associated parameters: \(df_{1}\) and
\(df_{2}\). For the \(F\)-statistic in ANOVA, \(df_{1} = df_{G}\) and
\(df_{2}= df_{E}\). An \(F\) distribution with 2 and 592 degrees of
freedom corresponds to the \(F\)-statistic for the genotype and muscle
strength hypothesis test,.

The larger the observed variability in the sample means (\(MSG\))
relative to the within-group variability (\(MSE\)), the larger \(F\)
will be. Larger values of \(F\) represent stronger evidence against the
null hypothesis. The upper tail of the distribution is used to compute a
\(p\)-value, which is typically done using statistical software.

\hypertarget{conclusion-3}{%
\subsection{Conclusion}\label{conclusion-3}}

From the R output, the \(p\)-value corresponding to the test statistic
is equal to about 0.04. Does this provide strong evidence against the
null hypothesis at significance level \(\alpha = 0.05\)?

\textbf{Solution}

The \(p\)-value is smaller than 0.05, indicating the evidence is strong
enough to reject the null hypothesis at a significance level of 0.05.
The data suggest that average change in strength in the non-dominant arm
varies by participant genotype.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{The \(F\)-statistic and the \(F\)-test}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

Analysis of variance (ANOVA) is used to test whether the mean outcome
differs across two or more groups. ANOVA uses a test statistic \(F\),
which represents a standardized ratio of variability in the sample means
relative to the variability within the groups. If \(H_0\) is true and
the model assumptions are satisfied, the statistic \(F\) follows an
\(F\) distribution with parameters \(df_{1}=k-1\) and \(df_{2}=n-k\).
The upper tail of the \(F\)-distribution is used to calculate the
\(p\)-value.

The null hypothesis is false if at least of the means is sufficiently
different from the others, relative to the variance in the data.

\end{tcolorbox}

\hypertarget{multiple-comparisons-and-controlling-type-1-error-rate}{%
\section{Multiple comparisons and controlling Type 1 Error
rate}\label{multiple-comparisons-and-controlling-type-1-error-rate}}

Rejecting the null hypothesis in an ANOVA analysis only allows for a
conclusion that there is evidence for a difference in group means. In
order to identify the groups with different means, it is necessary to
perform further testing. For example, in the \texttt{famuss} analysis,
there are three comparisons to make: \(\texttt{CC}\) to \(\texttt{CT}\),
\(\texttt{CC}\) to \(\texttt{TT}\), and \(\texttt{CT}\) to
\(\texttt{TT}\). While these comparisons can be made using two sample
\(t\)-tests, it is important to control the Type 1 error rate. One of
the simplest ways to reduce the overall probability of identifying a
significant difference by chance in a multiple comparisons setting is to
use the Bonferroni correction procedure.

In the Bonferroni correction procedure, the \(p\)-value from a
two-sample \(t\)-test is compared to a modified significance level,
\(\alpha^\star\); \(\alpha^\star = \alpha/K\), where \(K\) is the total
number of comparisons being considered. For \(k\) groups,
\(K=\frac{k(k-1)}{2}\). When calculating the \(t\)-statistic, use the
pooled estimate of standard deviation between groups (which equals
\(\sqrt{MSE}\)); to calculate the \(p\)-value, use a \(t\)-distribution
with \(df_2\). It is typically more convenient to do these calculations
using software.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Bonferroni correction}, arc=.35mm, colframe=quarto-callout-note-color-frame, colback=white, titlerule=0mm, left=2mm, bottomtitle=1mm, bottomrule=.15mm, breakable, opacitybacktitle=0.6, leftrule=.75mm, toptitle=1mm, coltitle=black, rightrule=.15mm, opacityback=0]

The \textbf{Bonferroni correction} suggests that a more stringent
significance level is appropriate when conducting multiple tests:
\begin{align*}
\alpha^\star = \alpha / K
\end{align*} where \(K\) is the number of comparisons being considered.
For \(k\) groups, \(K=\frac{k(k-1)}{2}\).

\end{tcolorbox}

\hypertarget{but-which-group-is-different}{%
\subsection{But which group is
different?}\label{but-which-group-is-different}}

The ANOVA conducted on the \texttt{famuss} dataset showed strong
evidence of differences in the mean strength change in the non-dominant
arm between the three genotypes. Complete the three possible pairwise
comparisons using the Bonferroni correction and report any differences.

Use a modified significance level of \(\alpha^\star = 0.05/3 = 0.0167\).
The pooled estimate of the standard deviation is
\(\sqrt{MSE} = \sqrt{1090.02} = 33.02\).

Genotype \texttt{CC} versus Genotype \texttt{CT}: \[
t = \frac{\overline{x}_1 - \overline{x}_2}{s_{\text{pooled}}\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} 
 = dfrac{48.89 - 53.25}{33.02 \sqrt{\frac{1}{173} + \frac{1}{261}}} = -1.35
\] This results in a \(p\)-value of 0.18 on \(df =592\). This
\(p\)-value is larger than \(\alpha^\star = 0.0167\), so there is not
evidence of a difference in the means of genotypes \texttt{CC} and
\texttt{CT}.

Genotype \texttt{CC} versus Genotype \texttt{TT}: \[
t = \frac{\overline{x}_1 - \overline{x}_2}{s_{\text{pooled}}\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
 = dfrac{48.89 - 58.08}{33.02 \sqrt{\frac{1}{173} + \frac{1}{161}}} = -2.54.
\]

This results in a \(p\)-value of 0.01 on \(df =592\). This \(p\)-value
is smaller than \(\alpha^\star = 0.0167\), so there is evidence of a
difference in the means of genotypes \texttt{CC} and \texttt{TT}.

Genotype \texttt{CT} versus Genotype \texttt{TT}:\\
\[
t = \frac{\overline{x}_1 - \overline{x}_2}{s_{\text{pooled}}\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
= dfrac{53.25 - 58.08}{33.02 \sqrt{\frac{1}{261} + \frac{1}{161}}} = -1.46
\]

This results in a \(p\)-value of 0.14 on \(df =592\). This \(p\)-value
is larger than \(\alpha^\star = 0.0167\), so there is not evidence of a
difference in the means of genotypes \texttt{CT} and \texttt{TT}.

In R, these can be calculated using the \texttt{pairwise.t.test()}
function as follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pairwise.t.test}\NormalTok{(famuss}\SpecialCharTok{$}\NormalTok{ndrm.ch, famuss}\SpecialCharTok{$}\NormalTok{actn3.r577x,}
    \AttributeTok{p.adjust.method =} \StringTok{"bonferroni"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pairwise comparisons using t tests with pooled SD 

data:  famuss$ndrm.ch and famuss$actn3.r577x 

   CC    CT   
CT 0.537 -    
TT 0.034 0.433

P value adjustment method: bonferroni 
\end{verbatim}

As you can guess from the command and its output:

\begin{itemize}
\tightlist
\item
  There is more than one way of adjusting p-values! There is some debate
  about the best way, but the important thing is to recognize when
  they're necessary and use them!
\item
  This test is using a \textbf{pooled standard deviation}. Thast is, it
  calculates the sd as if all of the data have the same variance.

  \begin{itemize}
  \tightlist
  \item
    For the t-test, it's easy enough to use different variances for each
    group. For multiple comparisons, using the pooled variance makes a
    little bit more sense because it will tend to be larger, and
    therefore we're adding extra variance and not being overconfident in
    our results.
  \end{itemize}
\end{itemize}

From these results, we can see that CC and TT are significantly
different from each other. CC and CT are not, and neither are CT and
TT.\footnote{Note that this is not transitive! CC and CT are not, CT and
  TT are not, but CC and TT are different!}

\hypertarget{summary-10}{%
\section{Summary}\label{summary-10}}

In summary, the mean percent strength change in the non-dominant arm for
genotype \texttt{CT} individuals is not statistically distinguishable
from those of genotype \texttt{CC} and \texttt{TT} individuals. However,
there is evidence that mean percent strength change in the non-dominant
arm differs between individuals of genotype \texttt{CC} and \texttt{TT}
are different.

\hypertarget{post-midterm-review}{%
\chapter{Post-Midterm Review}\label{post-midterm-review}}

\hypertarget{the-broad-topics}{%
\section{The Broad Topics}\label{the-broad-topics}}

The following topics have applied to almost everything since the
midterm.

\hypertarget{standard-errors}{%
\subsection{Standard Errors}\label{standard-errors}}

\begin{itemize}
\tightlist
\item
  Since our sample was random, we could have gotten different data. With
  different data, we'd get a different mean and sd.
\item
  The standard error of the mean represents uncertainty around the mean.
  With more data, we are more certain about the value.

  \begin{itemize}
  \tightlist
  \item
    Effects of outliers diminish, and the overall variation ``averages
    out''.
  \item
    The same thing happens to the sd, but it's not a normal
    distribution.
  \end{itemize}
\item
  Be ready to explain how standard errors relate to various concepts.

  \begin{itemize}
  \tightlist
  \item
    For example, could you explain why test statistics and p-values have
    a standard error (even though you don't know the formula for it)?
  \end{itemize}
\end{itemize}

\hypertarget{assumption-checking-1}{%
\subsection{Assumption Checking}\label{assumption-checking-1}}

\begin{itemize}
\tightlist
\item
  All of the methods we use require assumptions about the population.
\item
  There's always some sort of independence assumption, which can be
  satisfied by having a good sampling strategy.
\item
  There's usually either an assumption of normality, or some conditions
  for which the normal approximation applies.

  \begin{itemize}
  \tightlist
  \item
    For means, we need a big enough sample for the Central Limit Theorem
    to apply (\(n > 30\) or \(n>60\) or something like that). This
    applies to all of the groups for t-tests and ANOVA.
  \item
    For proportions, we need some form of \(np>10\) and \(n(1-p)>10\) so
    that the normal approximation applies. Be careful whether you need
    the observed proportion, hypothesized proportion, or pooled
    proportion!
  \item
    For regression, we assume that the residuals are normal, and we can
    assess this with the QQ Plot.
  \end{itemize}
\item
  There are other assumptions that may be method-specific.

  \begin{itemize}
  \tightlist
  \item
    For example, linear regression requires that the plot looks linear!
  \end{itemize}
\item
  On the exam, there will be questions that ask you to interpret the
  results of a study. You \textbf{must} check the assumptions before
  making a conclusion, regardless of whether you're explicitly told to!

  \begin{itemize}
  \tightlist
  \item
    In a job, your boss might just ask for the results, but they'll
    expect you to make sure the results are valid before sharing them!
  \end{itemize}
\end{itemize}

\hypertarget{hypothesis-testing-1}{%
\subsection{Hypothesis Testing}\label{hypothesis-testing-1}}

\begin{itemize}
\tightlist
\item
  Null and Alternative hypotheses: Convert the word problem into math.

  \begin{itemize}
  \tightlist
  \item
    Null: Nothing is going on. Very often, this means \(\mu = 0\) or
    \(p = 0.5\) or \(\mu_1 - \mu_0 = 0\). However, we could also test
    things like \(p_1 - p_2 = 0.1\), i.e., whether \(p_1\) is 10
    percentage points higher than \(p_2\).
  \item
    Alternative: generally involves a \(\ne\), \(>\), or \(<\). The
    wording of the statement will indicate whether it's a two sided
    (\(\ne\)), right-tailed (\(>\)), or left-tailed (\(<\)) p-value.
  \end{itemize}
\item
  Set the significance level.

  \begin{itemize}
  \tightlist
  \item
    This determines how ``strong'' the evidence must be in order for us
    to reject the null. \(\alpha = 0.1\) means we'll accept weak
    evidence, whereas \(\alpha = 0.001\) means we need to be very sure
    of our results before the null is rejected.
  \end{itemize}
\item
  Test statistic: measures the distance between our observed data and
  the hypothesized value, \emph{relative to the standard error}.

  \begin{itemize}
  \tightlist
  \item
    Relies on the value from the null hypothesis, as well as the sample
    size!
  \end{itemize}
\item
  p-value: \textbf{ASSUMING THE NULL HYPOTHESIS IS TRUE}, the p-value
  measures the probability of getting data at least as extreme as the
  data we got.

  \begin{itemize}
  \tightlist
  \item
    ``At least as extreme'' = this far away from the null values or
    further. The direction is determined by the alternative hypothesis.
  \item
    A small p-value is strong evidence. If \(p < \alpha\), we reject the
    null and claim that our result is ``statistically significant''.
  \item
    A small p-value does \emph{not} mean that there's a large difference
    in the observed and hypothesized! It's a large difference
    \emph{relative to the standard error}, which decreases with better
    study designs and larger sample sizes. For example, a 0.01\%
    increase in cancer risk is not something that a person really needs
    to worry about, but a large enough sample might find a statistically
    significant result!
  \end{itemize}
\end{itemize}

\hypertarget{confidence-intervals-4}{%
\subsection{Confidence Intervals}\label{confidence-intervals-4}}

\begin{itemize}
\tightlist
\item
  If we were to repeat the exact same study many, many times with new
  samples each time, \((1-\alpha)\)\% of the intervals we create will
  contain the true population parameter.
\item
  Generally, a CI has the form ``point estimate \(\pm\) critical value *
  standard error''

  \begin{itemize}
  \tightlist
  \item
    Point estimate: the mean, for example.
  \item
    Critical value: the value from the relevant distribution that makes
    it a \((1-\alpha)\)\% interval. Essentially, this controls the width
    of the interval so that the interval actually does contain the true
    parameter as often as we claim that it does.
  \item
    Standard error: see above.
  \end{itemize}
\item
  A 95\% CI is essentially the middle 95\% of the \textbf{sampling
  distribution}, if it were centered on the observed sample mean.

  \begin{itemize}
  \tightlist
  \item
    In other words, we use the standard error to determine an interval
    that we hope covers the middle 95\% of all possible mean values.
  \end{itemize}
\item
  For a 95\% CI, we want the middle 95\%. This means we want 2.5\% on
  either side, which is why we see \(\alpha/2\) a lot when dealing with
  confidence intervals.
\end{itemize}

\hypertarget{conclusion-in-the-context-of-the-problem}{%
\subsection{Conclusion in the context of the
problem}\label{conclusion-in-the-context-of-the-problem}}

The beauty of stats is that it's rigorous math with applications to the
real world - always remember that the data come from somewhere and the
results might be meaningful to real people!

\hypertarget{type-1-and-2-error}{%
\subsection{Type 1 and 2 Error}\label{type-1-and-2-error}}

\begin{itemize}
\tightlist
\item
  Type 1 Error: rejecting a null when it's true.

  \begin{itemize}
  \tightlist
  \item
    We reject if \(p < \alpha\) because our p-value is ``too unlikely''
    under the null. However, unlikely things still happen!
  \item
    If \(\alpha=0.05\), then we reject anything with a p-value less than
    5\%. However, things with a p-value of 5\% still happen 5\% of the
    time.
  \item
    P(Type 1 Error) = \(\alpha\).

    \begin{itemize}
    \tightlist
    \item
      In other words, we control P(Type 1 Error) when we choose a
      significance level.
    \end{itemize}
  \end{itemize}
\item
  Type 2 Error: Fail to reject the null when it's false

  \begin{itemize}
  \tightlist
  \item
    Even when the null is actually false, we may not have strong enough
    evidence to reject it.

    \begin{itemize}
    \tightlist
    \item
      Better evidence comes from either a better study design or a
      larger sample size.
    \end{itemize}
  \item
    \textbf{Power}: 1 - P(Type 2 Error), which is generally difficult to
    calculate.

    \begin{itemize}
    \tightlist
    \item
      It is \emph{not} \(1-\alpha\).
    \end{itemize}
  \item
    A study with low power might have p-values larger than \(\alpha\),
    but the authors would not be able to say whether the null is false.
  \end{itemize}
\end{itemize}

\hypertarget{multiple-comparisons-problem}{%
\subsection{Multiple Comparisons
Problem}\label{multiple-comparisons-problem}}

\begin{itemize}
\tightlist
\item
  Suppose the null is true. We still have a 5\% chance of rejecting a
  true null, and therefore a 95\% chance of correctly not rejecting it.
\item
  If we have two nulls, both of which are true, then the probability
  that we correctly don't reject either is 0.95*0.95 = 0.9025. This
  means we have a 9.75\% chance of rejecting at least one of them, even
  though they're both true.
\item
  The multiple comparisons problem states that, when we check a lot of
  p-values, the Type 1 Error increases.
\end{itemize}

\hypertarget{means}{%
\section{Means}\label{means}}

\hypertarget{one-sample-t-tests-and-cis-for-a-mean}{%
\subsection{One-sample t-tests and CIs for a
Mean}\label{one-sample-t-tests-and-cis-for-a-mean}}

\begin{itemize}
\tightlist
\item
  \textbf{Assumptions}: The population is normal, or that the sample is
  large enough for the CLT to apply. Independence among observations.
\item
  \textbf{Null Hypothesis}: \(H_0:\mu = \mu_0\), where \(\mu_0\) is the
  hypothesized value given in the question.
\item
  \textbf{Test Statistic}:
  \(t_{obs} = \dfrac{\bar x - \mu_0}{s/\sqrt{n}}\)
\item
  \textbf{p-value}:

  \begin{itemize}
  \tightlist
  \item
    pt(\(t_{obs}\)) for left-tailed (\(<\))
  \item
    1 - pt(\(t_{obs}\)) for right-tailed (\(>\))
  \item
    2*(1 - pt(\textbar{}\(t_{obs}\)\textbar)) for two-tailed (\(\ne\))
  \end{itemize}
\item
  \textbf{CI}: \(\bar x \pm t_{n-1}^*\dfrac{s}{\sqrt{n}}\)

  \begin{itemize}
  \tightlist
  \item
    For a \((1-\alpha)\)\% interval, \(t^*_{n-1}\) comes from
    \texttt{qt(alpha/2)}

    \begin{itemize}
    \tightlist
    \item
      E.g., for a 95\% CI, \(\alpha = 0.05\) and we would use
      \texttt{qt(0.025)}.
    \item
      This could also be written as \texttt{qt((1\ -\ 0.95)/2)}.
    \end{itemize}
  \end{itemize}
\end{itemize}

\textbf{Example}: The EPA claims that the average fuel mileage of cars
is 19 mpg. Does the \texttt{mtcars} data set support this claim?

A small difference from 19 would not be important to us, so we're only
going to reject this claim if there is strong evidence. For this reason,
we'll use a significance level of 0.01.

The plot below does not quite look normal, but for this size sample it
is potentially normal ``enough''.

\includegraphics{L24-Review_files/figure-pdf/unnamed-chunk-2-1.pdf}

The question asks whether our data support the claim, but does not ask
if the true mpg is larger than or less than. We use a two-sided
hypothesis test.

\[
H_0: \mu = 19\text{ vs. }H_A:\mu \ne 19
\]

We'll let R do the calculations for us.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{mpg, }\AttributeTok{mu =} \DecValTok{19}\NormalTok{, }
    \AttributeTok{alternative =} \StringTok{"two.sided"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  mtcars$mpg
t = 1.0237, df = 31, p-value = 0.3139
alternative hypothesis: true mean is not equal to 19
95 percent confidence interval:
 17.91768 22.26357
sample estimates:
mean of x 
 20.09062 
\end{verbatim}

Our p-value is 0.31, which is much larger than our significance level of
0.05. We conclude that we cannot reject the EPA's claim.\footnote{This
  does \emph{not} mean that 19 is the true value, we just don't have
  evidence against this value. We don't confirm the null; it's set up in
  a such a way that we seek evidence \emph{against} it, not for it.}

\textbf{Second Example}

The \texttt{ggplot2} package also loads in a data set called
\texttt{mpg}, do these data agree with our previous conclusion?

\begin{verbatim}
# A tibble: 6 x 11
  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class 
  <chr>        <chr> <dbl> <int> <int> <chr>      <chr> <int> <int> <chr> <chr> 
1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa~
2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa~
3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa~
4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa~
5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa~
6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p     compa~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(mpg}\SpecialCharTok{$}\NormalTok{overall, }\AttributeTok{mu =} \DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  mpg$overall
t = 2.528, df = 233, p-value = 0.01213
alternative hypothesis: true mean is not equal to 19
95 percent confidence interval:
 19.18104 20.45998
sample estimates:
mean of x 
 19.82051 
\end{verbatim}

The p-value for this test is 0.012, which is above our significance
level of 0.01. However, it's only slightly above!

If these are two well-collected samples from the population, then
there's a \(1 - (1 - 0.01)^2 = 0.0199\approx 2\%\) chance of at least
one of them being significant by chance.

As mentioned in class, the mtcars data set is from 1973. This data set
is from 1999-2008, so they're not exactly separate samples from the same
population!

\hypertarget{matched-pairs-t-test-for-a-mean-difference}{%
\subsection{Matched Pairs t-test for a Mean
Difference}\label{matched-pairs-t-test-for-a-mean-difference}}

A \textbf{matched pairs} study design is one where each subject is
matched with another, only one of which gets the treatment and the other
gets the control. See the oitment example from the class.

A matched pairs test is actually just a one-sample t-test for the
differences. In other words, we treat each difference as if it's the
value we're calculating. The one-sample t-test assumptions and
conclusions apply.

\hypertarget{two-sample-t-tests-1}{%
\subsection{Two-Sample t-tests}\label{two-sample-t-tests-1}}

\begin{itemize}
\tightlist
\item
  \textbf{Assumptions}: Both populations are normal, or both the samples
  are large enough for the CLT to apply. Independence among observations
  within and between groups.\footnote{There is a version of the
    two-sample t-test that also assumes equality of variances in the two
    groups, but it's generally best to avoid that assumption unless it's
    abundantly clear that it holds.}
\item
  \textbf{Null Hypothesis}: Generally, we have the null hypothesis
  \(H_0:\mu_{diff} = 0\), where \(\mu_{diff}\) is the difference in the
  means (either \(\mu-1 - \mu_2\) or \(\mu_2 - \mu_1\)\footnote{Either
    is fine, but you must be careful about using right or left-sided
    p-values}).
\item
  \textbf{Test Statistic}: \(t_{obs} = \dfrac{\bar x_1 - \bar x_2}{SE}\)

  \begin{itemize}
  \tightlist
  \item
    \(SE\) comes from the square root of the sum of their variances.

    \begin{itemize}
    \tightlist
    \item
      \(SE = \sqrt{\frac{s_1^2}{n_1} + \frac{2_s^2}{n_2}}\)
    \end{itemize}
  \end{itemize}
\item
  \textbf{p-value}: Same as 1-sample, where we use a \(t\)-distirbution.
\item
  \textbf{CI}: \(\bar x1 - \bar x_2 \pm t_{n-1}^*SE\)
\end{itemize}

\textbf{Example}: In the 1-sample procedure, I included a second example
using a different sample of cars. The first example used a dataset
called \texttt{mtcars}, which measured a sample of cars from 1973-1974,
while the second used a data set called \texttt{mpg} which measures a
sample of cars from 1999-2008. In this example, let's test whether the
fuel efficiency of cars has improved (i.e., the mpg has gone
up).\footnote{This example \emph{cannot} be seen as a matched pairs
  procedure - there's nothing to match!}

In symbols, our hypotheses are \(H_0:\mu_{mtcars} - \mu_{mpg} = 0\)
versus \(H_A: \mu_{diff} < 0\).\footnote{Take a moment to ensure that
  these make sense to you!}

\includegraphics{L24-Review_files/figure-pdf/unnamed-chunk-6-1.pdf}

From these two plots, it looks like there is a possible slight
difference.

\begin{itemize}
\tightlist
\item
  We are assuming that both data sets are based on \emph{good} samples,
  although this may not actually be appropriate and we should
  acknowledge this in our conclusions.
\item
  It is clear that there is not dependence between these two data sets -
  they were collected completely separately!
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{mpg, mpg}\SpecialCharTok{$}\NormalTok{overall, }\AttributeTok{alternative =} \StringTok{"less"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Welch Two Sample t-test

data:  mtcars$mpg and mpg$overall
t = 0.24252, df = 36.979, p-value = 0.5951
alternative hypothesis: true difference in means is less than 0
95 percent confidence interval:
     -Inf 2.149167
sample estimates:
mean of x mean of y 
 20.09062  19.82051 
\end{verbatim}

It looks like there is \emph{not} a significant difference.

I'm always a little bit skeptical when something is doing calculations
for me, so I just want to double check whether R is doing
\texttt{mtcars} minus \texttt{mpg} or the other way around.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{mpg); }\FunctionTok{mean}\NormalTok{(mpg}\SpecialCharTok{$}\NormalTok{overall)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 20.09062
\end{verbatim}

\begin{verbatim}
[1] 19.82051
\end{verbatim}

So it looks like R is labelling ``x'' as \texttt{mtcars} and ``y'' as
\texttt{mpg}, and doing mtcars minus mpg. This means that we're correct
in using ``\texttt{alernative\ =\ "less"}.

Now that we've double checked that the calculations were correct, we can
make our conclusion. It does not appear that the two data sets have
significantly different fuel efficiencies. However, this conclusion is
highly sensitive to whether the data sets have ``good'' sampling
strategies.

The \texttt{mtcars} data were sample by Motor Trend Magazine based on
what they thought their audience would like, whereas the \texttt{mpg}
data were taken from the Environmental Protection Agency without any
preference. It is very important to note that \emph{neither} data set
represents the average mpg of cars on the road. For instance, the
\texttt{mpg} data contain one row for the manual Chevrolet Corvette and
one row for the automatic Corvette, as well as one for the Honda Civic
(automatic and manual). This is not representative of cars in general,
as well as not representative of the actual cars on the road.

\hypertarget{anova-for-multiple-means}{%
\subsection{ANOVA for Multiple Means}\label{anova-for-multiple-means}}

\begin{itemize}
\tightlist
\item
  \textbf{Assumptions}: The population is normal, or that the sample is
  large enough for the CLT to apply. Independence among observations.
  Independence between groups. Groups have the same variance.
\item
  \textbf{Null}: All means are equal,
  i.e.~\(\mu_1 = \mu_2 = ... = \mu_k = 0\).

  \begin{itemize}
  \tightlist
  \item
    This is false if \emph{any} or \emph{all} of the means differ; ANOVA
    does not tell us which mean is significantly different from the
    others.
  \end{itemize}
\item
  \textbf{Test Statistic}: \(MSG/MSE\), which is interpreted as the
  variance of the group means (considering their sample sizes) divided
  by the variance in the data if we were to ignore the groups.
\item
  \textbf{p-value}: Always right-tailed, since we're only testing
  whether the variance of group means is \emph{too large} relative to
  the data varaince. The p-value is calculated from an F distribution.
\item
  \textbf{Conclusions and further steps}: If we reject the null and
  conclude that at least one group is statistically significant, we can
  then do a \textbf{post-hoc} analysis to determine which mean(s)
  is(are) statistically significantly different from the others.

  \begin{itemize}
  \tightlist
  \item
    We use special techniques to control the Type 1 error!
  \end{itemize}
\end{itemize}

\textbf{Example}: The EPA's claim of 19 mpg as the average does
\emph{not} take into account the number of cylinders. When asked, the
spokesperson said that the average mpg is the same regardless of the
number of cylinders that a car has.

Let's test this claim! Again, we want strong evidence before we reject
this claim, so we'll set the significance level to 0.01.

From the plot below, it looks like there will almost certainly be a
difference!

\includegraphics{L24-Review_files/figure-pdf/unnamed-chunk-9-1.pdf}

The table shows that one of the assumptions of ANOVA is not satisfied
(guess which before looking at the footnote\footnote{Equal variance
  within groups}), so we should be careful when interpreting the
results.

\begin{longtable}[]{@{}rrrr@{}}
\toprule\noalign{}
cyl & mean & sd & size \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
4 & 26.66 & 4.51 & 11 \\
6 & 19.74 & 1.45 & 7 \\
8 & 15.10 & 2.56 & 14 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{aov}\NormalTok{(mpg }\SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(cyl), }\AttributeTok{data =}\NormalTok{ mtcars))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            Df Sum Sq Mean Sq F value   Pr(>F)    
factor(cyl)  2  824.8   412.4    39.7 4.98e-09 ***
Residuals   29  301.3    10.4                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\hypertarget{regression-1}{%
\section{Regression}\label{regression-1}}

\begin{itemize}
\tightlist
\item
  \textbf{Assumptions}: Independence, no patterns in the residual plots

  \begin{itemize}
  \tightlist
  \item
    Residuals vs.~Fitted should be a straight line with no patterns
  \item
    QQ plot should look like a line
  \item
    Scale-location should be a straight line
  \item
    Nothing outise the dotted lines in the Leverage plot.
  \end{itemize}
\item
  \textbf{Hypothesis}: The slope is 0 (which implies that the
  correlation is 0)
\item
  \textbf{Test Statistic}: Like a test for a one-sample t-test, but with
  a more complicated standard error.

  \begin{itemize}
  \tightlist
  \item
    R will give the standard error.
  \item
    Degrees of freedom is \(n-2\).
  \end{itemize}
\item
  \textbf{p-value}: Generally two sided, but not always

  \begin{itemize}
  \tightlist
  \item
    We may be asking about a positive association,
    e.g.~\(H_A:\beta > 0\).
  \end{itemize}
\item
  \textbf{Confidence Intervals}: See one-sample t-test.
\end{itemize}

\textbf{Example}: Is there a linear relationship between the fuel
efficiency of the car and the car's weight? Test at the 5\% level.

To test the assumptions, we have to actually fit the model first! This
is a good test of self control - the p-values are just sitting there
waiting to be interpreted, but we've got a lot of work before we should
even look at them!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars\_lm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(mpg }\SpecialCharTok{\textasciitilde{}}\NormalTok{ wt, }\AttributeTok{data =}\NormalTok{ mtcars)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)) }\CommentTok{\# sets up plotting region for 4 plots}
\FunctionTok{plot}\NormalTok{(mtcars\_lm)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{L24-Review_files/figure-pdf/unnamed-chunk-12-1.pdf}

}

\end{figure}

\begin{itemize}
\tightlist
\item
  Residuals vs.~Fitted: There's a slight ``U''-shaped pattern. This is
  not good!
\item
  Normal Q-Q: Doesn't look too bad.
\item
  Scale-location: A bit of a pattern, but overall not too bad.
\item
  Residuals vs.~Leverage: One point outside the ``0.5'' dotted line,
  which should be investigated but isn't too bad.
\end{itemize}

So the assumptions are not really satisfied, mainly because of the
``U''-shaped pattern in the first plot.

We'll look at the output just for practice, but the actual pattern might
not be linear.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(mtcars\_lm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = mpg ~ wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***
wt           -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10
\end{verbatim}

According to the output, the slope \emph{is} significant. There appears
to be a significant correlation between mpg and weight of the car, but
the actual pattern might not be linear.

\hypertarget{proportions}{%
\section{Proportions}\label{proportions}}

\hypertarget{one-sample-test-for-proportions}{%
\subsection{One-Sample Test for
Proportions}\label{one-sample-test-for-proportions}}

\begin{itemize}
\tightlist
\item
  \textbf{Assumptions}: \(np > 10\) and \(n(1 - p)>10\) so that the
  normal approximation applies. Indpedence/good sampling.

  \begin{itemize}
  \tightlist
  \item
    For hypothesis tests we use \(p_0\) (the hypothesized proportion),
    for confidence intervals we use \(\hat p\) (the estimated
    proportion).
  \end{itemize}
\item
  \textbf{Hypotheses}: \(p = p_0\).
\item
  \textbf{Test Statistic}: We assume normality, and under the null we
  have a standard error of \(\sqrt{p_0(1 - p_0)/n}\). The test statistic
  is \(z = (\hat p - p_0)/SE\)
\item
  \textbf{p-value}: Since we're not estimating the standard deviation,
  we don't get a \(t\) distribution. The p-value comes from the normal
  distribution.
\item
  \textbf{Confidence Intervals}: For a CI, we don't have a hypothesis
  and so we use \(\hat p\) in the standard error.

  \begin{itemize}
  \tightlist
  \item
    \(100(1-\alpha)\%CI: \hat p \pm z^*\sqrt{\hat p(1 - \hat p)/n}\)
  \end{itemize}
\end{itemize}

\textbf{Example}: It is suggested that, if male penguins are more likely
to be the hunters, then there should be more females than males (the
hunters will get hunted by orcas). Assuming that the Palmer Penguins
data are a random sample, do we have evidence at the 5\% level that
males are the primary hunters?

\vspace{1cm}

We are told to assume it's a random sample, and we can see from the
plots that \(n\) is large enough for \(np_0>10\) and \(n(1-p_0)>10\).

Our hypothesis is that the proportion of males is less than 0.5: \[
H_0: p = 0.5\text{ vs. }p < 0.05
\]

\includegraphics{L24-Review_files/figure-pdf/unnamed-chunk-14-1.pdf}

We can look at the data as follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{sex }\SpecialCharTok{==} \StringTok{"male"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

FALSE  TRUE 
  165   168 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{sex }\SpecialCharTok{==} \StringTok{"male"}\NormalTok{), }\AttributeTok{p =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{alternative =} \StringTok{"less"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    1-sample proportions test with continuity correction

data:  table(penguins$sex == "male"), null probability 0.5
X-squared = 0.012012, df = 1, p-value = 0.4564
alternative hypothesis: true p is less than 0.5
95 percent confidence interval:
 0.0000000 0.5419071
sample estimates:
        p 
0.4954955 
\end{verbatim}

Since the p-value is 0.4564, we do not reject the null hypothesis. There
is no evidence to suggest that there are fewer males than females, which
means that males do not appear to be predated at a higher rate.

\hypertarget{two-sample-test-for-proportions}{%
\subsection{Two-Sample Test for
Proportions}\label{two-sample-test-for-proportions}}

\begin{itemize}
\tightlist
\item
  \textbf{Assumptions}: \(n_1\hat p > 10\) and \(n_1(1 - \hat p)>10\),
  similar \(n_2\), so that the normal approximation applies.
  Indpedence/good sampling.

  \begin{itemize}
  \tightlist
  \item
    For hypothesis tests, \(\hat p\) is the pooled proportion. For
    confidence intervals, we require that \(n_i\hat p_i>10\) and
    \(n_i(1-\hat p_i)>10\) for \(i=1\) and \(i=2\).
  \end{itemize}
\item
  \textbf{Hypotheses}: Generally, we're testing \(p_1 = p_2\), which
  amounts to testing \(p_{diff} = 0\), where \(p_{diff} = p_2 - p_1\) of
  \(p_1 - p_2\).

  \begin{itemize}
  \tightlist
  \item
    It is also possible to test, e.g., whether \(p_2\) is 10 percentages
    higher than \(p_1\), which would be \(H_0:p_{diff} = 0.1\).
  \end{itemize}
\item
  \textbf{Test Statistic}: Since this is based on a normal
  approximation, this works almost exactly the same as the two-sample
  t-test approach.

  \begin{itemize}
  \tightlist
  \item
    \(z = \frac{\hat p_{diff} - p_{diff}}{SE(\hat p_{diff})}\).
  \end{itemize}
\item
  \textbf{p-value}: See two-sample t-tests.
\item
  \textbf{CI}: See two-sample t-tests.
\end{itemize}

\textbf{Example}: In the penguins data, penguins are sampled from three
different islands: Biscoe, Dream, and Torgersen. For this example,
suppose a researcher is interested in whether the islands Biscoe and
Dream have the same proportion of males and females. We'll test this at
the 10\% level.

We can treat the penguins from Biscoe as one sample, find the proportion
of males, and do the same for Dream.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Code to specify the islands}
\NormalTok{db }\OtherTok{\textless{}{-}}\NormalTok{ penguins[penguins}\SpecialCharTok{$}\NormalTok{island }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"Dream"}\NormalTok{, }\StringTok{"Biscoe"}\NormalTok{),]}
\CommentTok{\# Ensure that R ignores the third island)}
\NormalTok{db}\SpecialCharTok{$}\NormalTok{island }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(db}\SpecialCharTok{$}\NormalTok{island)}
\CommentTok{\# Create a two{-}way table}
\FunctionTok{table}\NormalTok{(db}\SpecialCharTok{$}\NormalTok{island, db}\SpecialCharTok{$}\NormalTok{sex)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        
         female male
  Biscoe     80   83
  Dream      61   62
\end{verbatim}

From the two-way table, I'm guessing that we won't reject the null!
Those proportions look pretty close, and the sample size is pretty
small.

We can use \texttt{prop.test()} to do the calculations for us. If we
don't specify the \texttt{alternative} hypothesis, it will assume two
sided. This is appropriate, since we're just looking for a difference in
proportions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(db}\SpecialCharTok{$}\NormalTok{island, db}\SpecialCharTok{$}\NormalTok{sex))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    2-sample test for equality of proportions with continuity correction

data:  table(db$island, db$sex)
X-squared = 1.7776e-30, df = 1, p-value = 1
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.1273096  0.1170348
sample estimates:
   prop 1    prop 2 
0.4907975 0.4959350 
\end{verbatim}

The p-value for the two-sided alternated hypothesis is 1! This is
definitely larger than our significance level, so we absolutely cannot
reject the null. We conclude that there is no evidence of a difference
in the proportion of males to females.

Notice that the proportion estimates are 80/(80 + 83) and 61/(61 + 63),
i.e.~the proportion of female penguuins on Briscoe Island and the
proportion of female pengiuns on Dream Island (note that these are
conditional probabilities). If we had done it the other way:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(db}\SpecialCharTok{$}\NormalTok{sex, db}\SpecialCharTok{$}\NormalTok{island))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    2-sample test for equality of proportions with continuity correction

data:  table(db$sex, db$island)
X-squared = 2.8876e-30, df = 1, p-value = 1
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.1248439  0.1147680
sample estimates:
   prop 1    prop 2 
0.5673759 0.5724138 
\end{verbatim}

we get the proportion of Briscoe among females and the proportion of
Dream among females, but the exact same p-value!

\hypertarget{chi-square-test-for-two-way-tables}{%
\subsection{Chi-Square Test for Two-Way
Tables}\label{chi-square-test-for-two-way-tables}}

\begin{itemize}
\tightlist
\item
  \textbf{Assumptions}: Independence among individuals, large enough
  samples for the normal approximation to apply.
\item
  \textbf{Hypotheses}: The Column and the Row variable are independent.

  \begin{itemize}
  \tightlist
  \item
    In other words, P(A \textbar{} X) = P(A) for all rows A and columns
    X, and vice versa.
  \end{itemize}
\item
  \textbf{Test Statistic}: The squared difference between the observed
  count and the expected count.

  \begin{itemize}
  \tightlist
  \item
    The expected count is what we would get if the rows and columns were
    independent.
  \end{itemize}
\item
  \textbf{p-value}: Always right-tailed, since the test stat is a
  squared difference.
\end{itemize}

\textbf{Example}: Instead of just looking at Dream and Biscoe, let's
look at all three islands.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{island, penguins}\SpecialCharTok{$}\NormalTok{sex)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
           
            female male
  Biscoe        80   83
  Dream         61   62
  Torgersen     24   23
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{island, penguins}\SpecialCharTok{$}\NormalTok{sex))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pearson's Chi-squared test

data:  table(penguins$island, penguins$sex)
X-squared = 0.057599, df = 2, p-value = 0.9716
\end{verbatim}

As we might have expected, there's no evidence that there's a difference
in the ``sex'' variable in different islands.

One way to interpret this result is that P(Male \textbar{} Briscoe) =
P(Male), and similarly for both biological sexes and for all three
islands. That is, knowing which island the penguin was sampled from does
not give us more information about the penguin's biological sex.
Conversely, if I told you that it was a Male penguin then you would have
no more information about which island it was sampled from.

\textbf{Second Example}

What about a difference in the ``island'' variable for different sexes?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{sex, penguins}\SpecialCharTok{$}\NormalTok{island))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pearson's Chi-squared test

data:  table(penguins$sex, penguins$island)
X-squared = 0.057599, df = 2, p-value = 0.9716
\end{verbatim}

The p-value is identical! If one is independent of the other, then the
other is independent of the one!

\hypertarget{chi-square-test-for-goodness-of-fit}{%
\subsection{Chi-Square Test for Goodness of
Fit}\label{chi-square-test-for-goodness-of-fit}}

\begin{itemize}
\tightlist
\item
  \textbf{Assumptions}: Independence between individuals.
\item
  \textbf{Hypothesis}: The distribution matches the hypothesized
  distribution.
\item
  \textbf{Test Statistic}: The squared difference between observed and
  expected, where expected is defined in the hypothesis.
\item
  \textbf{p-value}: Always right-tailed.
\end{itemize}

\textbf{Example}: A researcher claimed that they saw 50\% of the
penguins on the Briscoe island, 30\% on Dream, and 20\% on Torgersen. Is
this hypothesis compatible with the data?

The penguins data looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{island)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

   Biscoe     Dream Torgersen 
      168       124        52 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{island), }\AttributeTok{p =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Chi-squared test for given probabilities

data:  table(penguins$island)
X-squared = 8.3876, df = 2, p-value = 0.01509
\end{verbatim}

It looks like the answer is no! The p-value is less than 0.05, so we
conclude that the distribution of penguins across the islands is
different from the claimed 0.5, 0.3, and 0.2. Let's see the actual
proportions to see why:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{island) }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(penguins)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

   Biscoe     Dream Torgersen 
0.4883721 0.3604651 0.1511628 
\end{verbatim}

From the data, it looks like there were more on Dream than the
researcher suggested, and fewer on Torgersen.

Notice how the goodness-of-fit test works like a one-sample Chi-Square
test. That's neat!

\hypertarget{practice-problems}{%
\section{Practice Problems}\label{practice-problems}}

\hypertarget{famuss-study}{%
\subsection{\texorpdfstring{\texttt{famuss}
Study}{famuss Study}}\label{famuss-study}}

In the famuss study, we focused on the \texttt{ndrm.ch}(non-dominant arm
percent change after 12 weeks of strength training) and the
\texttt{actn3.r577x} (genotype at a particular position on the genome).
We used this for the lecture on Chi-Square test for proportions.

Here are the other variables available in the data set:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Only need to run these lines of code *once*!}
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{)}
\NormalTok{devtools}\SpecialCharTok{::}\FunctionTok{install\_github}\NormalTok{(}\StringTok{"OI{-}Biostat/oi\_biostat\_data"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(oibiostat)}

\FunctionTok{data}\NormalTok{(famuss)}
\FunctionTok{head}\NormalTok{(famuss)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  ndrm.ch drm.ch    sex age      race height weight actn3.r577x    bmi
1      40     40 Female  27 Caucasian   65.0    199          CC 33.112
2      25      0   Male  36 Caucasian   71.7    189          CT 25.845
3      40      0 Female  24 Caucasian   65.0    134          CT 22.296
4     125      0 Female  40 Caucasian   68.0    171          CT 25.998
5      40     20 Female  32 Caucasian   61.0    118          CC 22.293
6      75      0 Female  24  Hispanic   62.2    120          CT 21.805
\end{verbatim}

These data are not necessarily a random sample of the population, so
questions like ``does weight change with age?'' won't result in
conclusions that apply to the general population. However, you can do a
couple of tests just to practice your skills.

For each example below, answer all of these questions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Test yourself on the assumptions we're making.

  \begin{itemize}
  \tightlist
  \item
    Are they satisfied in the example?
  \end{itemize}
\item
  Write the hypotheses in the appropriate symbols.

  \begin{itemize}
  \tightlist
  \item
    Do the statements in the examples make sense?
  \end{itemize}
\item
  Explain why the test is appropriate for the data.
\item
  Interpret the conclusions in the context of the problem.
\end{enumerate}

I've provided the research questions and the code to calculate the
p-value, as well as some plots to help you address the assumptions. Try
to run the code yourself so that you can play around with things (try
different hypotheses, verify that values in a confidence interval will
be rejected, etc.), but I've also included the output below.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Are 50\% of the people in this study female?

  \begin{itemize}
  \tightlist
  \item
    \texttt{sum(famuss\$sex\ ==\ "Female")}
  \item
    \texttt{nrow(famuss)}
  \item
    \texttt{prop.test(sum(famuss\$sex\ ==\ "Female"),\ nrow(famuss),\ p\ =\ 0.5)}
  \end{itemize}
\item
  Is the change in dominant arm strength larger than 0?

  \begin{itemize}
  \tightlist
  \item
    \texttt{mean(famuss\$drm.ch)}
  \item
    \texttt{t.test(famuss\$drm.ch,\ mu\ =\ 0,\ alternative\ =\ "greater")}
  \end{itemize}
\item
  The data contain a column for non-dominant and dominant arm strength.
  Are the means of these columns different?\footnote{Justify why this is
    a \textbf{matched pairs} test.}

  \begin{itemize}
  \tightlist
  \item
    \texttt{t.test(famuss\$drm.ch\ -\ famuss\$drm.ch,\ mu\ =\ 0,\ alternative\ =\ "two.sided")}
  \item
    Alternative question: is the mean of ndrm.ch larger than ndrm.ch by
    more 50? This is the same as asking if the dominant arm strength is
    50 percentage points higher than the non-dominant by over 50\%
    percentages.\footnote{Technical note: we are \emph{not} testing if
      it's double, e.g.~\(\mu_{dom} = 2*\mu_{non}\); we have not learned
      the machinery for this. in particular, there are some extra steps
      for the standard error.} This is a small change to the code, but
    it adds a lot to the interpretation!
  \item
    Interpret the confidence interval.
  \end{itemize}
\item
  Is there a difference between change in non-dominant arm strength for
  men and women in this study?

  \begin{itemize}
  \tightlist
  \item
    \texttt{t.test(ndrm.ch\ \textasciitilde{}\ sex,\ data\ =\ famuss,\ alternative\ =\ "two.sided")}
  \end{itemize}
\item
  Is there an association between race and genotype?

  \begin{itemize}
  \tightlist
  \item
    \texttt{table(famuss\$race,\ famuss\$actn3.r577x)}
  \item
    \texttt{chisq.test(table(famuss\$race,\ famuss\$actn3.r577x))}

    \begin{itemize}
    \tightlist
    \item
      Interpreting the results here must be done carefully, but is
      important!
    \end{itemize}
  \item
    If the results are significant, how might you figure out which races
    are different?
  \end{itemize}
\item
  Is the mean change in non-dominant arm strength the same across races?

  \begin{itemize}
  \tightlist
  \item
    \texttt{anova(aov(ndrm.ch\ \textasciitilde{}\ race,\ data\ =\ famuss))}
  \end{itemize}
\item
  Is there a correlation between dominant and non-dominant arm
  strength?\footnote{Definitely check the plots for this one!!!}

  \begin{itemize}
  \tightlist
  \item
    \texttt{summary(lm(drm.ch\ \textasciitilde{}\ ndrm.ch,\ data\ =\ famuss))}
  \item
    Interpret the slope in the context of the problem, being careful to
    refer to any shortcomings of the problem.

    \begin{itemize}
    \tightlist
    \item
      Also, did it matter which I used as the \(y\) variable?
    \end{itemize}
  \item
    Identify any potentially influential outliers.
  \end{itemize}
\end{enumerate}

\hypertarget{relevant-plots}{%
\subsection{Relevant Plots}\label{relevant-plots}}

\includegraphics{L24-Review_files/figure-pdf/unnamed-chunk-27-1.pdf}

\includegraphics{L24-Review_files/figure-pdf/unnamed-chunk-27-2.pdf}

\hypertarget{output-of-code}{%
\subsection{Output of Code}\label{output-of-code}}

Try these youself, changing the alternative hypothesis and hypothesized
values!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 1. Are 50\% of the people in this study female?}
\FunctionTok{sum}\NormalTok{(famuss}\SpecialCharTok{$}\NormalTok{sex }\SpecialCharTok{==} \StringTok{"Female"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 353
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nrow}\NormalTok{(famuss)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 595
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.test}\NormalTok{(}\FunctionTok{sum}\NormalTok{(famuss}\SpecialCharTok{$}\NormalTok{sex }\SpecialCharTok{==} \StringTok{"Female"}\NormalTok{), }\FunctionTok{nrow}\NormalTok{(famuss), }\AttributeTok{p =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    1-sample proportions test with continuity correction

data:  sum(famuss$sex == "Female") out of nrow(famuss), null probability 0.5
X-squared = 20.336, df = 1, p-value = 6.496e-06
alternative hypothesis: true p is not equal to 0.5
95 percent confidence interval:
 0.5524836 0.6328489
sample estimates:
        p 
0.5932773 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 2. Is the change in dominant arm strength larger than 0?}
\FunctionTok{mean}\NormalTok{(famuss}\SpecialCharTok{$}\NormalTok{drm.ch)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 10.35025
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(famuss}\SpecialCharTok{$}\NormalTok{drm.ch, }\AttributeTok{mu =} \DecValTok{0}\NormalTok{, }\AttributeTok{alternative =} \StringTok{"greater"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  famuss$drm.ch
t = 13.995, df = 594, p-value < 2.2e-16
alternative hypothesis: true mean is greater than 0
95 percent confidence interval:
 9.131896      Inf
sample estimates:
mean of x 
 10.35025 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 3. Are the means of the non{-}dominant and dominant columns different?7}
\FunctionTok{t.test}\NormalTok{(famuss}\SpecialCharTok{$}\NormalTok{drm.ch }\SpecialCharTok{{-}}\NormalTok{ famuss}\SpecialCharTok{$}\NormalTok{drm.ch, }\AttributeTok{mu =} \DecValTok{0}\NormalTok{, }\AttributeTok{alternative =} \StringTok{"two.sided"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  famuss$drm.ch - famuss$drm.ch
t = NaN, df = 594, p-value = NA
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 NaN NaN
sample estimates:
mean of x 
        0 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 4. Is there a difference between change in non{-}dominant arm strength for men and women in this study?}
\FunctionTok{t.test}\NormalTok{(ndrm.ch }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex, }\AttributeTok{data =}\NormalTok{ famuss, }\AttributeTok{alternative =} \StringTok{"two.sided"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Welch Two Sample t-test

data:  ndrm.ch by sex
t = 10.073, df = 574.01, p-value < 2.2e-16
alternative hypothesis: true difference in means between group Female and group Male is not equal to 0
95 percent confidence interval:
 19.07240 28.31175
sample estimates:
mean in group Female   mean in group Male 
            62.92720             39.23512 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 5. Is there an association between race and genotype?}
\FunctionTok{table}\NormalTok{(famuss}\SpecialCharTok{$}\NormalTok{race, famuss}\SpecialCharTok{$}\NormalTok{actn3.r577x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            
              CC  CT  TT
  African Am  16   6   5
  Asian       21  18  16
  Caucasian  125 216 126
  Hispanic     4  10   9
  Other        7  11   5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(famuss}\SpecialCharTok{$}\NormalTok{race, famuss}\SpecialCharTok{$}\NormalTok{actn3.r577x))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pearson's Chi-squared test

data:  table(famuss$race, famuss$actn3.r577x)
X-squared = 19.4, df = 8, p-value = 0.01286
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 6. Is the mean change in non{-}dominant arm strength the same across races?}
\FunctionTok{anova}\NormalTok{(}\FunctionTok{aov}\NormalTok{(ndrm.ch }\SpecialCharTok{\textasciitilde{}}\NormalTok{ race, }\AttributeTok{data =}\NormalTok{ famuss))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: ndrm.ch
           Df Sum Sq Mean Sq F value  Pr(>F)  
race        4  11524  2881.1  2.6526 0.03233 *
Residuals 590 640812  1086.1                  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 7. Is there a correlation between dominant and non{-}dominant arm strength?}
\FunctionTok{summary}\NormalTok{(}\FunctionTok{lm}\NormalTok{(drm.ch }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ndrm.ch, }\AttributeTok{data =}\NormalTok{ famuss))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = drm.ch ~ ndrm.ch, data = famuss)

Residuals:
    Min      1Q  Median      3Q     Max 
-53.004  -9.691  -1.391   7.953  86.965 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.32170    1.30415  -0.247    0.805    
ndrm.ch      0.20026    0.02079   9.634   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 16.79 on 593 degrees of freedom
Multiple R-squared:  0.1353,    Adjusted R-squared:  0.1339 
F-statistic: 92.81 on 1 and 593 DF,  p-value: < 2.2e-16
\end{verbatim}



\end{document}
